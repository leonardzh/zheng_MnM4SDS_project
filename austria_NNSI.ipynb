{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "# This ensures visualizations are plotted inside the notebook\n",
    "%matplotlib inline\n",
    "import io\n",
    "import os              # This provides several system utilities\n",
    "import pandas as pd    \n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import rtree\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "from cenpy import products\n",
    "import cenpy\n",
    "import scipy.stats  as stats # low-level stats & probability\n",
    "import statsmodels.formula.api as smf # high-level stats\n",
    "import requests\n",
    "import contextily as ctx\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Data</th>\n",
       "      <th>Oi</th>\n",
       "      <th>Dj</th>\n",
       "      <th>Dij</th>\n",
       "      <th>Offset</th>\n",
       "      <th>beta</th>\n",
       "      <th>OrigAT11</th>\n",
       "      <th>OrigAT12</th>\n",
       "      <th>...</th>\n",
       "      <th>DestAT12</th>\n",
       "      <th>DestAT13</th>\n",
       "      <th>DestAT21</th>\n",
       "      <th>DestAT22</th>\n",
       "      <th>DestAT31</th>\n",
       "      <th>DestAT32</th>\n",
       "      <th>DestAT33</th>\n",
       "      <th>DestAT34</th>\n",
       "      <th>Oi2007</th>\n",
       "      <th>Dj2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT11</td>\n",
       "      <td>0</td>\n",
       "      <td>4016</td>\n",
       "      <td>5146</td>\n",
       "      <td>1.000000e-300</td>\n",
       "      <td>1.000000e-300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>5452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT12</td>\n",
       "      <td>1131</td>\n",
       "      <td>4016</td>\n",
       "      <td>25741</td>\n",
       "      <td>1.030018e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>27169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT13</td>\n",
       "      <td>1887</td>\n",
       "      <td>4016</td>\n",
       "      <td>26980</td>\n",
       "      <td>8.420467e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>28710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT21</td>\n",
       "      <td>69</td>\n",
       "      <td>4016</td>\n",
       "      <td>4117</td>\n",
       "      <td>2.208119e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT22</td>\n",
       "      <td>738</td>\n",
       "      <td>4016</td>\n",
       "      <td>8634</td>\n",
       "      <td>1.320075e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>9069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Origin Destination  Data    Oi     Dj            Dij         Offset  beta  \\\n",
       "0   AT11        AT11     0  4016   5146  1.000000e-300  1.000000e-300     1   \n",
       "1   AT11        AT12  1131  4016  25741   1.030018e+02   1.000000e+00     1   \n",
       "2   AT11        AT13  1887  4016  26980   8.420467e+01   1.000000e+00     1   \n",
       "3   AT11        AT21    69  4016   4117   2.208119e+02   1.000000e+00     1   \n",
       "4   AT11        AT22   738  4016   8634   1.320075e+02   1.000000e+00     1   \n",
       "\n",
       "   OrigAT11  OrigAT12  ...  DestAT12  DestAT13  DestAT21  DestAT22  DestAT31  \\\n",
       "0         0         0  ...         0         0         0         0         0   \n",
       "1         0         0  ...         1         0         0         0         0   \n",
       "2         0         0  ...         0         1         0         0         0   \n",
       "3         0         0  ...         0         0         1         0         0   \n",
       "4         0         0  ...         0         0         0         1         0   \n",
       "\n",
       "   DestAT32  DestAT33  DestAT34  Oi2007  Dj2007  \n",
       "0         0         0         0    4320    5452  \n",
       "1         0         0         0    4320   27169  \n",
       "2         0         0         0    4320   28710  \n",
       "3         0         0         0    4320    4354  \n",
       "4         0         0         0    4320    9069  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reproduce paper data\n",
    "austria = pd.read_csv('AT_Austria.csv')\n",
    "austria.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "austria = austria[austria['Origin']!=austria['Destination']]\n",
    "flows = austria['Data'].values\n",
    "Oi = austria['Oi'].values\n",
    "Dj = austria['Dj'].values\n",
    "Dij = austria['Dij'].values\n",
    "Origin = austria['Origin'].values\n",
    "Destination = austria['Destination'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/pysal/spint.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spint.gravity import Gravity\n",
    "from spint.gravity import Production\n",
    "from spint.gravity import Attraction\n",
    "from spint.gravity import Doubly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity = Gravity(flows,Oi,Dj,Dij,'exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.01822841e+00  8.69316127e-01  8.91445153e-01 -6.22938370e-03]\n"
     ]
    }
   ],
   "source": [
    "print(gravity.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4016,  4016,  4016,  4016,  4016,  4016,  4016,  4016, 20080,\n",
       "       20080, 20080, 20080, 20080, 20080, 20080, 20080, 29142, 29142,\n",
       "       29142, 29142, 29142, 29142, 29142, 29142,  4897,  4897,  4897,\n",
       "        4897,  4897,  4897,  4897,  4897,  8487,  8487,  8487,  8487,\n",
       "        8487,  8487,  8487,  8487, 10638, 10638, 10638, 10638, 10638,\n",
       "       10638, 10638, 10638,  5790,  5790,  5790,  5790,  5790,  5790,\n",
       "        5790,  5790,  4341,  4341,  4341,  4341,  4341,  4341,  4341,\n",
       "        4341,  2184,  2184,  2184,  2184,  2184,  2184,  2184,  2184],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Oi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Oi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpIntDataset(Dataset):\n",
    "    def __init__(self, input_paras,target_flows):\n",
    "        '''\n",
    "        '''\n",
    "        self.in_torch = torch.from_numpy(input_paras).t().view(-1,1,3).float()\n",
    "        self.out_torch =  torch.from_numpy(target_flows).float().view(-1,1,1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.in_torch)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        in_f = self.in_torch[idx,:,:]\n",
    "        tar_flow = self.out_torch[idx,:,:]\n",
    "        sample = {'input': in_f, 'output': tar_flow}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(3,8)\n",
    "        self.fc2 = nn.Linear(8,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1131,  1887,    69,   738,    98,    31,    43,    19,  1633,\n",
       "       14055,   416,  1276,  1850,   388,   303,   159,  2301, 20164,\n",
       "        1080,  1831,  1943,   742,   674,   407,    85,   379,  1597,\n",
       "        1608,   328,   317,   469,   114,   762,  1110,  2973,  1252,\n",
       "        1081,   622,   425,   262,   196,  2027,  3498,   346,  1332,\n",
       "        2144,   821,   274,    49,   378,  1349,   310,   851,  2117,\n",
       "         630,   106,    87,   424,   978,   490,   670,   577,   546,\n",
       "         569,    33,   128,   643,   154,   328,   199,   112,   587],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4016.0000, 25741.0000,   103.0018]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = np.vstack((Oi,Dj,Dij))\n",
    "in_torch = torch.from_numpy(input_features)\n",
    "in_torch = in_torch.t()\n",
    "in_torch = in_torch.view(-1,1,3)\n",
    "in_torch = in_torch.float()\n",
    "in_torch[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4016.0000, 26980.0000,    84.2047]],\n",
       "\n",
       "        [[ 4016.0000,  4117.0000,   220.8119]],\n",
       "\n",
       "        [[ 4016.0000,  8634.0000,   132.0075]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_torch[[1,2,3],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_torch = torch.from_numpy(flows).float()\n",
    "out_torch = out_torch.view(-1,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "spint_dataset = SpIntDataset(input_features,flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(spint_dataset, batch_size=1,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 183780.013\n",
      "[1,    40] loss: 6673.160\n",
      "[1,    60] loss: 90042.732\n",
      "[2,    20] loss: 7811.993\n",
      "[2,    40] loss: 89647.225\n",
      "[2,    60] loss: 7013.658\n",
      "[3,    20] loss: 10820.226\n",
      "[3,    40] loss: 86850.269\n",
      "[3,    60] loss: 183856.629\n",
      "[4,    20] loss: 8365.182\n",
      "[4,    40] loss: 87098.809\n",
      "[4,    60] loss: 6390.959\n",
      "[5,    20] loss: 8453.620\n",
      "[5,    40] loss: 87417.210\n",
      "[5,    60] loss: 185760.985\n",
      "[6,    20] loss: 9138.998\n",
      "[6,    40] loss: 184438.154\n",
      "[6,    60] loss: 89308.667\n",
      "[7,    20] loss: 7481.894\n",
      "[7,    40] loss: 183383.550\n",
      "[7,    60] loss: 7414.908\n",
      "[8,    20] loss: 9033.652\n",
      "[8,    40] loss: 183808.432\n",
      "[8,    60] loss: 87717.354\n",
      "[9,    20] loss: 183652.235\n",
      "[9,    40] loss: 10136.458\n",
      "[9,    60] loss: 86548.831\n",
      "[10,    20] loss: 8227.132\n",
      "[10,    40] loss: 86494.611\n",
      "[10,    60] loss: 184591.225\n",
      "[11,    20] loss: 10209.967\n",
      "[11,    40] loss: 6054.517\n",
      "[11,    60] loss: 5772.297\n",
      "[12,    20] loss: 263104.463\n",
      "[12,    40] loss: 7646.138\n",
      "[12,    60] loss: 7472.574\n",
      "[13,    20] loss: 6513.701\n",
      "[13,    40] loss: 9042.067\n",
      "[13,    60] loss: 265268.460\n",
      "[14,    20] loss: 266689.382\n",
      "[14,    40] loss: 8014.552\n",
      "[14,    60] loss: 6061.795\n",
      "[15,    20] loss: 8295.712\n",
      "[15,    40] loss: 6900.479\n",
      "[15,    60] loss: 264975.718\n",
      "[16,    20] loss: 6103.841\n",
      "[16,    40] loss: 87471.179\n",
      "[16,    60] loss: 185745.284\n",
      "[17,    20] loss: 182782.575\n",
      "[17,    40] loss: 86709.113\n",
      "[17,    60] loss: 7189.356\n",
      "[18,    20] loss: 11279.503\n",
      "[18,    40] loss: 87850.045\n",
      "[18,    60] loss: 181138.381\n",
      "[19,    20] loss: 85945.828\n",
      "[19,    40] loss: 7828.285\n",
      "[19,    60] loss: 184665.054\n",
      "[20,    20] loss: 8224.930\n",
      "[20,    40] loss: 8583.924\n",
      "[20,    60] loss: 263645.412\n",
      "[21,    20] loss: 8661.299\n",
      "[21,    40] loss: 184650.338\n",
      "[21,    60] loss: 87827.967\n",
      "[22,    20] loss: 7786.627\n",
      "[22,    40] loss: 9184.937\n",
      "[22,    60] loss: 263153.132\n",
      "[23,    20] loss: 8042.170\n",
      "[23,    40] loss: 7224.695\n",
      "[23,    60] loss: 87655.889\n",
      "[24,    20] loss: 7229.743\n",
      "[24,    40] loss: 10095.765\n",
      "[24,    60] loss: 261343.654\n",
      "[25,    20] loss: 184181.138\n",
      "[25,    40] loss: 88256.468\n",
      "[25,    60] loss: 7392.606\n",
      "[26,    20] loss: 7816.084\n",
      "[26,    40] loss: 7131.702\n",
      "[26,    60] loss: 263289.555\n",
      "[27,    20] loss: 7973.337\n",
      "[27,    40] loss: 9202.454\n",
      "[27,    60] loss: 87259.537\n",
      "[28,    20] loss: 88025.406\n",
      "[28,    40] loss: 9997.829\n",
      "[28,    60] loss: 6028.675\n",
      "[29,    20] loss: 86811.164\n",
      "[29,    40] loss: 8717.476\n",
      "[29,    60] loss: 183181.369\n",
      "[30,    20] loss: 8784.725\n",
      "[30,    40] loss: 6081.016\n",
      "[30,    60] loss: 183445.992\n",
      "[31,    20] loss: 88813.146\n",
      "[31,    40] loss: 10346.527\n",
      "[31,    60] loss: 4511.505\n",
      "[32,    20] loss: 184013.874\n",
      "[32,    40] loss: 88684.708\n",
      "[32,    60] loss: 7867.661\n",
      "[33,    20] loss: 8401.102\n",
      "[33,    40] loss: 264412.188\n",
      "[33,    60] loss: 7792.947\n",
      "[34,    20] loss: 85497.619\n",
      "[34,    40] loss: 8068.866\n",
      "[34,    60] loss: 185489.146\n",
      "[35,    20] loss: 9150.319\n",
      "[35,    40] loss: 86964.061\n",
      "[35,    60] loss: 184991.337\n",
      "[36,    20] loss: 6909.278\n",
      "[36,    40] loss: 181951.909\n",
      "[36,    60] loss: 10470.402\n",
      "[37,    20] loss: 6913.464\n",
      "[37,    40] loss: 6347.884\n",
      "[37,    60] loss: 265636.206\n",
      "[38,    20] loss: 181792.146\n",
      "[38,    40] loss: 10161.845\n",
      "[38,    60] loss: 6264.156\n",
      "[39,    20] loss: 185913.520\n",
      "[39,    40] loss: 7633.560\n",
      "[39,    60] loss: 87854.400\n",
      "[40,    20] loss: 8452.067\n",
      "[40,    40] loss: 86811.038\n",
      "[40,    60] loss: 183600.050\n",
      "[41,    20] loss: 87111.385\n",
      "[41,    40] loss: 6134.755\n",
      "[41,    60] loss: 10791.991\n",
      "[42,    20] loss: 7943.955\n",
      "[42,    40] loss: 7811.715\n",
      "[42,    60] loss: 183149.067\n",
      "[43,    20] loss: 5507.324\n",
      "[43,    40] loss: 8696.951\n",
      "[43,    60] loss: 264051.854\n",
      "[44,    20] loss: 9936.721\n",
      "[44,    40] loss: 181666.843\n",
      "[44,    60] loss: 89203.606\n",
      "[45,    20] loss: 8328.543\n",
      "[45,    40] loss: 87400.276\n",
      "[45,    60] loss: 184252.998\n",
      "[46,    20] loss: 181633.697\n",
      "[46,    40] loss: 10494.791\n",
      "[46,    60] loss: 87285.133\n",
      "[47,    20] loss: 10711.031\n",
      "[47,    40] loss: 7201.088\n",
      "[47,    60] loss: 182111.047\n",
      "[48,    20] loss: 6584.044\n",
      "[48,    40] loss: 184206.535\n",
      "[48,    60] loss: 8922.941\n",
      "[49,    20] loss: 5228.213\n",
      "[49,    40] loss: 9914.348\n",
      "[49,    60] loss: 262926.535\n",
      "[50,    20] loss: 84310.185\n",
      "[50,    40] loss: 10469.860\n",
      "[50,    60] loss: 182381.614\n",
      "[51,    20] loss: 8265.922\n",
      "[51,    40] loss: 185516.116\n",
      "[51,    60] loss: 87138.543\n",
      "[52,    20] loss: 7054.841\n",
      "[52,    40] loss: 89958.058\n",
      "[52,    60] loss: 7137.347\n",
      "[53,    20] loss: 184254.728\n",
      "[53,    40] loss: 9562.083\n",
      "[53,    60] loss: 86577.419\n",
      "[54,    20] loss: 11352.527\n",
      "[54,    40] loss: 85141.785\n",
      "[54,    60] loss: 181454.567\n",
      "[55,    20] loss: 89876.213\n",
      "[55,    40] loss: 8306.914\n",
      "[55,    60] loss: 181761.352\n",
      "[56,    20] loss: 264091.180\n",
      "[56,    40] loss: 9012.892\n",
      "[56,    60] loss: 6080.570\n",
      "[57,    20] loss: 7372.108\n",
      "[57,    40] loss: 9853.688\n",
      "[57,    60] loss: 260234.005\n",
      "[58,    20] loss: 89092.551\n",
      "[58,    40] loss: 183507.442\n",
      "[58,    60] loss: 6352.805\n",
      "[59,    20] loss: 184049.253\n",
      "[59,    40] loss: 6623.933\n",
      "[59,    60] loss: 8679.094\n",
      "[60,    20] loss: 7048.890\n",
      "[60,    40] loss: 6646.960\n",
      "[60,    60] loss: 264038.883\n",
      "[61,    20] loss: 10033.990\n",
      "[61,    40] loss: 87400.453\n",
      "[61,    60] loss: 7769.680\n",
      "[62,    20] loss: 89239.801\n",
      "[62,    40] loss: 8346.069\n",
      "[62,    60] loss: 183186.122\n",
      "[63,    20] loss: 8629.844\n",
      "[63,    40] loss: 89653.233\n",
      "[63,    60] loss: 5551.587\n",
      "[64,    20] loss: 6977.412\n",
      "[64,    40] loss: 7293.924\n",
      "[64,    60] loss: 186859.552\n",
      "[65,    20] loss: 89131.468\n",
      "[65,    40] loss: 5845.697\n",
      "[65,    60] loss: 185740.932\n",
      "[66,    20] loss: 184171.849\n",
      "[66,    40] loss: 86579.376\n",
      "[66,    60] loss: 9903.058\n",
      "[67,    20] loss: 6408.326\n",
      "[67,    40] loss: 11180.246\n",
      "[67,    60] loss: 87683.044\n",
      "[68,    20] loss: 10281.584\n",
      "[68,    40] loss: 183763.233\n",
      "[68,    60] loss: 6635.929\n",
      "[69,    20] loss: 9497.852\n",
      "[69,    40] loss: 10347.997\n",
      "[69,    60] loss: 179957.577\n",
      "[70,    20] loss: 182012.477\n",
      "[70,    40] loss: 8518.882\n",
      "[70,    60] loss: 9410.674\n",
      "[71,    20] loss: 6284.555\n",
      "[71,    40] loss: 183346.007\n",
      "[71,    60] loss: 89797.017\n",
      "[72,    20] loss: 6608.277\n",
      "[72,    40] loss: 182457.743\n",
      "[72,    60] loss: 9261.416\n",
      "[73,    20] loss: 7426.024\n",
      "[73,    40] loss: 9963.959\n",
      "[73,    60] loss: 263307.985\n",
      "[74,    20] loss: 86994.794\n",
      "[74,    40] loss: 186927.353\n",
      "[74,    60] loss: 8303.845\n",
      "[75,    20] loss: 185297.615\n",
      "[75,    40] loss: 8676.515\n",
      "[75,    60] loss: 86280.331\n",
      "[76,    20] loss: 9243.757\n",
      "[76,    40] loss: 182728.487\n",
      "[76,    60] loss: 7178.102\n",
      "[77,    20] loss: 9751.585\n",
      "[77,    40] loss: 8361.186\n",
      "[77,    60] loss: 181559.785\n",
      "[78,    20] loss: 87510.511\n",
      "[78,    40] loss: 5974.222\n",
      "[78,    60] loss: 184460.053\n",
      "[79,    20] loss: 8003.176\n",
      "[79,    40] loss: 89469.623\n",
      "[79,    60] loss: 183019.537\n",
      "[80,    20] loss: 6504.681\n",
      "[80,    40] loss: 182889.573\n",
      "[80,    60] loss: 90602.736\n",
      "[81,    20] loss: 6928.625\n",
      "[81,    40] loss: 8821.349\n",
      "[81,    60] loss: 10214.671\n",
      "[82,    20] loss: 8423.765\n",
      "[82,    40] loss: 7162.421\n",
      "[82,    60] loss: 185014.866\n",
      "[83,    20] loss: 8220.585\n",
      "[83,    40] loss: 265314.266\n",
      "[83,    60] loss: 5651.059\n",
      "[84,    20] loss: 88388.892\n",
      "[84,    40] loss: 7851.986\n",
      "[84,    60] loss: 9104.641\n",
      "[85,    20] loss: 88611.562\n",
      "[85,    40] loss: 180274.504\n",
      "[85,    60] loss: 9829.912\n",
      "[86,    20] loss: 8403.186\n",
      "[86,    40] loss: 87622.769\n",
      "[86,    60] loss: 186348.538\n",
      "[87,    20] loss: 185528.014\n",
      "[87,    40] loss: 85875.765\n",
      "[87,    60] loss: 8421.810\n",
      "[88,    20] loss: 183049.964\n",
      "[88,    40] loss: 88175.954\n",
      "[88,    60] loss: 8693.967\n",
      "[89,    20] loss: 89052.370\n",
      "[89,    40] loss: 181721.128\n",
      "[89,    60] loss: 8456.991\n",
      "[90,    20] loss: 86248.777\n",
      "[90,    40] loss: 183275.836\n",
      "[90,    60] loss: 11082.577\n",
      "[91,    20] loss: 8995.641\n",
      "[91,    40] loss: 87271.942\n",
      "[91,    60] loss: 7733.578\n",
      "[92,    20] loss: 11677.378\n",
      "[92,    40] loss: 85598.357\n",
      "[92,    60] loss: 182002.806\n",
      "[93,    20] loss: 6816.455\n",
      "[93,    40] loss: 7573.774\n",
      "[93,    60] loss: 10749.489\n",
      "[94,    20] loss: 5078.216\n",
      "[94,    40] loss: 87941.261\n",
      "[94,    60] loss: 186755.448\n",
      "[95,    20] loss: 10652.573\n",
      "[95,    40] loss: 6430.241\n",
      "[95,    60] loss: 262824.086\n",
      "[96,    20] loss: 8140.740\n",
      "[96,    40] loss: 184156.126\n",
      "[96,    60] loss: 87947.451\n",
      "[97,    20] loss: 6278.905\n",
      "[97,    40] loss: 89912.345\n",
      "[97,    60] loss: 8896.773\n",
      "[98,    20] loss: 8875.983\n",
      "[98,    40] loss: 184684.307\n",
      "[98,    60] loss: 84303.789\n",
      "[99,    20] loss: 5671.058\n",
      "[99,    40] loss: 267576.631\n",
      "[99,    60] loss: 7100.867\n",
      "[100,    20] loss: 6879.548\n",
      "[100,    40] loss: 264238.271\n",
      "[100,    60] loss: 10241.424\n",
      "[101,    20] loss: 85572.471\n",
      "[101,    40] loss: 184389.617\n",
      "[101,    60] loss: 8788.609\n",
      "[102,    20] loss: 185392.835\n",
      "[102,    40] loss: 87101.636\n",
      "[102,    60] loss: 9895.282\n",
      "[103,    20] loss: 264326.418\n",
      "[103,    40] loss: 7676.274\n",
      "[103,    60] loss: 8374.157\n",
      "[104,    20] loss: 7134.227\n",
      "[104,    40] loss: 8973.424\n",
      "[104,    60] loss: 183604.506\n",
      "[105,    20] loss: 182695.507\n",
      "[105,    40] loss: 89538.909\n",
      "[105,    60] loss: 6761.721\n",
      "[106,    20] loss: 9171.841\n",
      "[106,    40] loss: 90617.448\n",
      "[106,    60] loss: 182034.981\n",
      "[107,    20] loss: 185901.334\n",
      "[107,    40] loss: 7829.428\n",
      "[107,    60] loss: 89021.067\n",
      "[108,    20] loss: 90870.600\n",
      "[108,    40] loss: 5831.279\n",
      "[108,    60] loss: 181048.252\n",
      "[109,    20] loss: 7828.009\n",
      "[109,    40] loss: 11583.284\n",
      "[109,    60] loss: 181729.369\n",
      "[110,    20] loss: 9345.171\n",
      "[110,    40] loss: 6387.351\n",
      "[110,    60] loss: 264149.014\n",
      "[111,    20] loss: 7227.381\n",
      "[111,    40] loss: 268077.326\n",
      "[111,    60] loss: 5801.772\n",
      "[112,    20] loss: 186039.743\n",
      "[112,    40] loss: 8386.072\n",
      "[112,    60] loss: 86310.502\n",
      "[113,    20] loss: 8641.640\n",
      "[113,    40] loss: 9781.767\n",
      "[113,    60] loss: 183792.606\n",
      "[114,    20] loss: 262724.810\n",
      "[114,    40] loss: 7869.582\n",
      "[114,    60] loss: 9281.950\n",
      "[115,    20] loss: 9993.033\n",
      "[115,    40] loss: 6083.617\n",
      "[115,    60] loss: 6976.076\n",
      "[116,    20] loss: 7789.870\n",
      "[116,    40] loss: 7161.905\n",
      "[116,    60] loss: 9729.521\n",
      "[117,    20] loss: 8959.223\n",
      "[117,    40] loss: 183710.247\n",
      "[117,    60] loss: 87744.302\n",
      "[118,    20] loss: 6430.619\n",
      "[118,    40] loss: 9019.409\n",
      "[118,    60] loss: 263470.355\n",
      "[119,    20] loss: 184832.877\n",
      "[119,    40] loss: 11634.206\n",
      "[119,    60] loss: 5133.253\n",
      "[120,    20] loss: 183981.717\n",
      "[120,    40] loss: 87138.996\n",
      "[120,    60] loss: 6318.324\n",
      "[121,    20] loss: 181975.674\n",
      "[121,    40] loss: 85621.192\n",
      "[121,    60] loss: 8575.606\n",
      "[122,    20] loss: 8801.774\n",
      "[122,    40] loss: 184301.976\n",
      "[122,    60] loss: 7153.130\n",
      "[123,    20] loss: 5943.877\n",
      "[123,    40] loss: 263142.357\n",
      "[123,    60] loss: 11720.001\n",
      "[124,    20] loss: 86851.668\n",
      "[124,    40] loss: 7911.749\n",
      "[124,    60] loss: 185302.138\n",
      "[125,    20] loss: 9187.550\n",
      "[125,    40] loss: 182891.828\n",
      "[125,    60] loss: 5983.142\n",
      "[126,    20] loss: 6327.238\n",
      "[126,    40] loss: 6010.715\n",
      "[126,    60] loss: 267571.998\n",
      "[127,    20] loss: 184639.320\n",
      "[127,    40] loss: 7022.663\n",
      "[127,    60] loss: 89101.657\n",
      "[128,    20] loss: 7660.234\n",
      "[128,    40] loss: 261328.989\n",
      "[128,    60] loss: 8331.309\n",
      "[129,    20] loss: 183433.534\n",
      "[129,    40] loss: 87516.297\n",
      "[129,    60] loss: 8686.801\n",
      "[130,    20] loss: 188680.909\n",
      "[130,    40] loss: 5413.188\n",
      "[130,    60] loss: 87475.176\n",
      "[131,    20] loss: 88193.291\n",
      "[131,    40] loss: 184385.205\n",
      "[131,    60] loss: 8178.962\n",
      "[132,    20] loss: 185936.019\n",
      "[132,    40] loss: 8219.378\n",
      "[132,    60] loss: 86682.790\n",
      "[133,    20] loss: 183870.240\n",
      "[133,    40] loss: 7185.544\n",
      "[133,    60] loss: 7118.322\n",
      "[134,    20] loss: 89378.222\n",
      "[134,    40] loss: 182636.468\n",
      "[134,    60] loss: 6925.953\n",
      "[135,    20] loss: 86699.807\n",
      "[135,    40] loss: 6670.032\n",
      "[135,    60] loss: 184597.237\n",
      "[136,    20] loss: 183048.600\n",
      "[136,    40] loss: 88222.734\n",
      "[136,    60] loss: 5927.059\n",
      "[137,    20] loss: 181433.944\n",
      "[137,    40] loss: 7385.425\n",
      "[137,    60] loss: 91604.739\n",
      "[138,    20] loss: 184260.793\n",
      "[138,    40] loss: 88227.296\n",
      "[138,    60] loss: 6693.430\n",
      "[139,    20] loss: 6374.926\n",
      "[139,    40] loss: 264413.981\n",
      "[139,    60] loss: 7610.970\n",
      "[140,    20] loss: 9192.411\n",
      "[140,    40] loss: 6601.164\n",
      "[140,    60] loss: 88999.666\n",
      "[141,    20] loss: 181975.981\n",
      "[141,    40] loss: 8902.958\n",
      "[141,    60] loss: 88971.794\n",
      "[142,    20] loss: 7901.506\n",
      "[142,    40] loss: 8916.529\n",
      "[142,    60] loss: 262855.153\n",
      "[143,    20] loss: 261342.986\n",
      "[143,    40] loss: 9736.700\n",
      "[143,    60] loss: 9293.511\n",
      "[144,    20] loss: 5623.287\n",
      "[144,    40] loss: 89009.409\n",
      "[144,    60] loss: 7522.873\n",
      "[145,    20] loss: 264857.160\n",
      "[145,    40] loss: 8725.574\n",
      "[145,    60] loss: 7359.259\n",
      "[146,    20] loss: 266246.964\n",
      "[146,    40] loss: 8578.639\n",
      "[146,    60] loss: 5948.420\n",
      "[147,    20] loss: 89307.628\n",
      "[147,    40] loss: 185360.785\n",
      "[147,    60] loss: 6648.053\n",
      "[148,    20] loss: 8937.178\n",
      "[148,    40] loss: 5242.299\n",
      "[148,    60] loss: 263553.964\n",
      "[149,    20] loss: 88292.511\n",
      "[149,    40] loss: 183776.396\n",
      "[149,    60] loss: 6432.639\n",
      "[150,    20] loss: 262883.455\n",
      "[150,    40] loss: 9058.180\n",
      "[150,    60] loss: 8196.694\n",
      "[151,    20] loss: 85819.022\n",
      "[151,    40] loss: 9252.862\n",
      "[151,    60] loss: 185395.734\n",
      "[152,    20] loss: 7967.430\n",
      "[152,    40] loss: 266939.353\n",
      "[152,    60] loss: 5354.997\n",
      "[153,    20] loss: 89639.701\n",
      "[153,    40] loss: 185122.490\n",
      "[153,    60] loss: 5864.630\n",
      "[154,    20] loss: 184437.354\n",
      "[154,    40] loss: 5960.484\n",
      "[154,    60] loss: 87316.846\n",
      "[155,    20] loss: 87840.203\n",
      "[155,    40] loss: 186365.790\n",
      "[155,    60] loss: 5742.332\n",
      "[156,    20] loss: 89084.374\n",
      "[156,    40] loss: 6264.174\n",
      "[156,    60] loss: 186123.815\n",
      "[157,    20] loss: 89601.734\n",
      "[157,    40] loss: 183449.062\n",
      "[157,    60] loss: 6527.807\n",
      "[158,    20] loss: 8335.162\n",
      "[158,    40] loss: 86642.963\n",
      "[158,    60] loss: 8253.117\n",
      "[159,    20] loss: 7341.366\n",
      "[159,    40] loss: 9320.133\n",
      "[159,    60] loss: 184503.145\n",
      "[160,    20] loss: 184462.684\n",
      "[160,    40] loss: 6772.636\n",
      "[160,    60] loss: 7552.407\n",
      "[161,    20] loss: 5879.508\n",
      "[161,    40] loss: 7394.940\n",
      "[161,    60] loss: 186443.366\n",
      "[162,    20] loss: 88334.885\n",
      "[162,    40] loss: 8552.058\n",
      "[162,    60] loss: 7268.080\n",
      "[163,    20] loss: 88025.669\n",
      "[163,    40] loss: 8543.125\n",
      "[163,    60] loss: 8724.319\n",
      "[164,    20] loss: 185573.851\n",
      "[164,    40] loss: 6463.296\n",
      "[164,    60] loss: 5868.844\n",
      "[165,    20] loss: 87641.362\n",
      "[165,    40] loss: 7954.171\n",
      "[165,    60] loss: 8489.055\n",
      "[166,    20] loss: 183000.939\n",
      "[166,    40] loss: 85122.810\n",
      "[166,    60] loss: 9331.969\n",
      "[167,    20] loss: 6006.372\n",
      "[167,    40] loss: 85169.393\n",
      "[167,    60] loss: 11786.287\n",
      "[168,    20] loss: 9047.006\n",
      "[168,    40] loss: 7399.339\n",
      "[168,    60] loss: 7126.240\n",
      "[169,    20] loss: 8680.893\n",
      "[169,    40] loss: 263083.622\n",
      "[169,    60] loss: 7265.838\n",
      "[170,    20] loss: 8147.947\n",
      "[170,    40] loss: 88182.000\n",
      "[170,    60] loss: 184137.147\n",
      "[171,    20] loss: 185469.825\n",
      "[171,    40] loss: 6551.012\n",
      "[171,    60] loss: 86833.333\n",
      "[172,    20] loss: 8946.364\n",
      "[172,    40] loss: 88613.225\n",
      "[172,    60] loss: 6539.600\n",
      "[173,    20] loss: 7695.396\n",
      "[173,    40] loss: 7130.787\n",
      "[173,    60] loss: 263184.099\n",
      "[174,    20] loss: 9254.590\n",
      "[174,    40] loss: 184780.667\n",
      "[174,    60] loss: 6628.425\n",
      "[175,    20] loss: 8324.503\n",
      "[175,    40] loss: 8817.227\n",
      "[175,    60] loss: 262349.631\n",
      "[176,    20] loss: 6955.072\n",
      "[176,    40] loss: 264566.840\n",
      "[176,    60] loss: 9276.723\n",
      "[177,    20] loss: 88787.408\n",
      "[177,    40] loss: 8762.759\n",
      "[177,    60] loss: 181680.628\n",
      "[178,    20] loss: 86099.674\n",
      "[178,    40] loss: 6999.574\n",
      "[178,    60] loss: 9262.879\n",
      "[179,    20] loss: 87941.070\n",
      "[179,    40] loss: 186001.731\n",
      "[179,    60] loss: 7432.388\n",
      "[180,    20] loss: 8746.455\n",
      "[180,    40] loss: 262429.733\n",
      "[180,    60] loss: 7951.664\n",
      "[181,    20] loss: 8489.698\n",
      "[181,    40] loss: 7149.946\n",
      "[181,    60] loss: 7882.211\n",
      "[182,    20] loss: 186818.560\n",
      "[182,    40] loss: 85050.613\n",
      "[182,    60] loss: 8458.054\n",
      "[183,    20] loss: 5770.126\n",
      "[183,    40] loss: 263215.405\n",
      "[183,    60] loss: 6741.028\n",
      "[184,    20] loss: 6105.627\n",
      "[184,    40] loss: 182268.657\n",
      "[184,    60] loss: 91128.786\n",
      "[185,    20] loss: 186544.308\n",
      "[185,    40] loss: 8060.020\n",
      "[185,    60] loss: 6867.909\n",
      "[186,    20] loss: 7424.039\n",
      "[186,    40] loss: 264695.995\n",
      "[186,    60] loss: 7999.657\n",
      "[187,    20] loss: 183759.320\n",
      "[187,    40] loss: 6950.338\n",
      "[187,    60] loss: 88358.673\n",
      "[188,    20] loss: 184547.634\n",
      "[188,    40] loss: 7527.194\n",
      "[188,    60] loss: 87815.722\n",
      "[189,    20] loss: 88615.529\n",
      "[189,    40] loss: 8139.849\n",
      "[189,    60] loss: 184535.589\n",
      "[190,    20] loss: 8932.633\n",
      "[190,    40] loss: 87245.592\n",
      "[190,    60] loss: 185083.994\n",
      "[191,    20] loss: 89484.598\n",
      "[191,    40] loss: 4834.436\n",
      "[191,    60] loss: 7206.901\n",
      "[192,    20] loss: 86794.498\n",
      "[192,    40] loss: 187177.349\n",
      "[192,    60] loss: 5622.226\n",
      "[193,    20] loss: 7995.998\n",
      "[193,    40] loss: 89640.568\n",
      "[193,    60] loss: 183232.550\n",
      "[194,    20] loss: 10763.471\n",
      "[194,    40] loss: 84850.535\n",
      "[194,    60] loss: 182224.188\n",
      "[195,    20] loss: 185066.032\n",
      "[195,    40] loss: 8699.901\n",
      "[195,    60] loss: 86203.842\n",
      "[196,    20] loss: 8852.928\n",
      "[196,    40] loss: 85888.006\n",
      "[196,    60] loss: 183292.467\n",
      "[197,    20] loss: 10765.258\n",
      "[197,    40] loss: 263812.929\n",
      "[197,    60] loss: 8070.843\n",
      "[198,    20] loss: 184529.234\n",
      "[198,    40] loss: 8182.455\n",
      "[198,    60] loss: 6794.550\n",
      "[199,    20] loss: 265764.908\n",
      "[199,    40] loss: 8304.930\n",
      "[199,    60] loss: 6186.688\n",
      "[200,    20] loss: 89701.813\n",
      "[200,    40] loss: 5733.272\n",
      "[200,    60] loss: 182850.327\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#train the network\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        in_f,out_f = data['input'], data['output']\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(in_f)\n",
    "        loss = criterion(outputs, out_f)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './austria_ann.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tb-nightly\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/3b/1479cccf0bdcdabc0e046eb761fdf413125cc1b5e83398e15ff00000f6ed/tb_nightly-2.1.0a20191010-py3-none-any.whl (3.8MB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tb-nightly) (1.12.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tb-nightly) (41.0.1)\n",
      "Collecting werkzeug>=0.11.15 (from tb-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tb-nightly) (0.33.4)\n",
      "Collecting absl-py>=0.4 (from tb-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
      "Collecting protobuf>=3.6.0 (from tb-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/ae/a11b9b0c8e2410b11887881990b71f54ec39b17c4de2b5d850ef66aade8c/protobuf-3.10.0-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Collecting markdown>=2.6.8 (from tb-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tb-nightly) (1.16.5)\n",
      "Collecting grpcio>=1.6.3 (from tb-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/e5/79974f0288e36be3205e71f91e0dbe2a5746ccaa84780c65c4d75fa4b269/grpcio-1.24.1-cp37-cp37m-win_amd64.whl (1.6MB)\n",
      "Building wheels for collected packages: absl-py\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.8.1-cp37-none-any.whl size=121171 sha256=73d1a131a385ce359715e9fb3bcff9c6328e680a84f8b260b12999a40a5ed8ff\n",
      "  Stored in directory: C:\\Users\\liuli\\AppData\\Local\\pip\\Cache\\wheels\\a7\\15\\a0\\0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
      "Successfully built absl-py\n",
      "Installing collected packages: werkzeug, absl-py, protobuf, markdown, grpcio, tb-nightly\n",
      "Successfully installed absl-py-0.8.1 grpcio-1.24.1 markdown-3.1.1 protobuf-3.10.0 tb-nightly-2.1.0a20191010 werkzeug-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tb-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting future\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/85/c273089eb6efa5644c0a1382ea553554bc0d40e00a46d989ec67f123f8b5/future-0.18.0.tar.gz (830kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.0-cp37-none-any.whl size=490419 sha256=f9562656e320cfd213c57e0743cb4bd538cdf78541d9d01ec12d33d024793908\n",
      "  Stored in directory: C:\\Users\\liuli\\AppData\\Local\\pip\\Cache\\wheels\\2c\\02\\af\\63eadc269fe686aa0aa9c38eee165ad5734cbf8b765cfeedaa\n",
      "Successfully built future\n",
      "Installing collected packages: future\n",
      "Successfully installed future-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tensorboard) (1.16.5)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tensorboard) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tensorboard) (3.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tensorboard) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tensorboard) (0.16.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tensorboard) (0.33.4)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tensorboard) (1.12.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tensorboard) (41.0.1)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages (from tensorboard) (1.24.1)\n",
      "Installing collected packages: tensorboard\n",
      "Successfully installed tensorboard-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\geo\\Scripts\\tensorboard.exe\\__main__.py\", line 9, in <module>\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages\\tensorboard\\main.py\", line 64, in run_main\n",
      "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages\\absl\\app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages\\tensorboard\\program.py\", line 220, in main\n",
      "    server = self._make_server()\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages\\tensorboard\\program.py\", line 299, in _make_server\n",
      "    self.assets_zip_provider)\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages\\tensorboard\\backend\\application.py\", line 157, in standard_tensorboard_wsgi\n",
      "    flags, plugin_loaders, data_provider, assets_zip_provider, multiplexer)\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages\\tensorboard\\backend\\application.py\", line 225, in TensorBoardWSGIApp\n",
      "    return TensorBoardWSGI(tbplugins, flags.path_prefix)\n",
      "  File \"c:\\programdata\\anaconda3\\envs\\geo\\lib\\site-packages\\tensorboard\\backend\\application.py\", line 277, in __init__\n",
      "    raise ValueError('Duplicate plugins for name %s' % plugin.plugin_name)\n",
      "ValueError: Duplicate plugins for name projector\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': tensor([[[29142.0000,  4117.0000,   249.9329]]]),\n",
       " 'output': tensor([[[1080.]]])}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(data['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 72])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4147]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = torch.randn(1, 1, 3)\n",
    "\n",
    "target_test = torch.randn(1,1,1)\n",
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()   # zero the gradient buffers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\geo\\lib\\site-packages\\torch\\nn\\functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[49.7355]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0690]],\n",
       "\n",
       "        [[68.0294]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]],\n",
       "\n",
       "        [[68.0691]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output = net(in_torch)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(output, out_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9391175.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the network\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(in_torch)\n",
    "        loss = criterion(outputs, out_torch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
