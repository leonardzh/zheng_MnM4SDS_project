{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "# This ensures visualizations are plotted inside the notebook\n",
    "%matplotlib inline\n",
    "import io\n",
    "import os              # This provides several system utilities\n",
    "import pandas as pd    \n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "from cenpy import products\n",
    "import cenpy\n",
    "import scipy.stats  as stats # low-level stats & probability\n",
    "import statsmodels.formula.api as smf # high-level stats\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Data</th>\n",
       "      <th>Oi</th>\n",
       "      <th>Dj</th>\n",
       "      <th>Dij</th>\n",
       "      <th>Offset</th>\n",
       "      <th>beta</th>\n",
       "      <th>OrigAT11</th>\n",
       "      <th>OrigAT12</th>\n",
       "      <th>...</th>\n",
       "      <th>DestAT12</th>\n",
       "      <th>DestAT13</th>\n",
       "      <th>DestAT21</th>\n",
       "      <th>DestAT22</th>\n",
       "      <th>DestAT31</th>\n",
       "      <th>DestAT32</th>\n",
       "      <th>DestAT33</th>\n",
       "      <th>DestAT34</th>\n",
       "      <th>Oi2007</th>\n",
       "      <th>Dj2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT11</td>\n",
       "      <td>AT11</td>\n",
       "      <td>0</td>\n",
       "      <td>4016</td>\n",
       "      <td>5146</td>\n",
       "      <td>1.000000e-300</td>\n",
       "      <td>1.000000e-300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>5452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT11</td>\n",
       "      <td>AT12</td>\n",
       "      <td>1131</td>\n",
       "      <td>4016</td>\n",
       "      <td>25741</td>\n",
       "      <td>1.030018e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>27169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT11</td>\n",
       "      <td>AT13</td>\n",
       "      <td>1887</td>\n",
       "      <td>4016</td>\n",
       "      <td>26980</td>\n",
       "      <td>8.420467e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>28710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT11</td>\n",
       "      <td>AT21</td>\n",
       "      <td>69</td>\n",
       "      <td>4016</td>\n",
       "      <td>4117</td>\n",
       "      <td>2.208119e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT11</td>\n",
       "      <td>AT22</td>\n",
       "      <td>738</td>\n",
       "      <td>4016</td>\n",
       "      <td>8634</td>\n",
       "      <td>1.320075e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320</td>\n",
       "      <td>9069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Origin Destination  Data    Oi     Dj            Dij         Offset  beta  \\\n",
       "0   AT11        AT11     0  4016   5146  1.000000e-300  1.000000e-300     1   \n",
       "1   AT11        AT12  1131  4016  25741   1.030018e+02   1.000000e+00     1   \n",
       "2   AT11        AT13  1887  4016  26980   8.420467e+01   1.000000e+00     1   \n",
       "3   AT11        AT21    69  4016   4117   2.208119e+02   1.000000e+00     1   \n",
       "4   AT11        AT22   738  4016   8634   1.320075e+02   1.000000e+00     1   \n",
       "\n",
       "   OrigAT11  OrigAT12  ...  DestAT12  DestAT13  DestAT21  DestAT22  DestAT31  \\\n",
       "0         0         0  ...         0         0         0         0         0   \n",
       "1         0         0  ...         1         0         0         0         0   \n",
       "2         0         0  ...         0         1         0         0         0   \n",
       "3         0         0  ...         0         0         1         0         0   \n",
       "4         0         0  ...         0         0         0         1         0   \n",
       "\n",
       "   DestAT32  DestAT33  DestAT34  Oi2007  Dj2007  \n",
       "0         0         0         0    4320    5452  \n",
       "1         0         0         0    4320   27169  \n",
       "2         0         0         0    4320   28710  \n",
       "3         0         0         0    4320    4354  \n",
       "4         0         0         0    4320    9069  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reproduce paper data\n",
    "austria = pd.read_csv('data/AT_Austria.csv')\n",
    "austria.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "austria = austria[austria['Origin']!=austria['Destination']]\n",
    "flows = austria['Data'].values\n",
    "Oi = austria['Oi'].values\n",
    "Dj = austria['Dj'].values\n",
    "Dij = austria['Dij'].values\n",
    "Origin = austria['Origin'].values\n",
    "Destination = austria['Destination'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/pysal/spint.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spint.gravity import Gravity\n",
    "from spint.gravity import Production\n",
    "from spint.gravity import Attraction\n",
    "from spint.gravity import Doubly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity = Gravity(flows,Oi,Dj,Dij,'exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.01822841e+00  8.69316127e-01  8.91445153e-01 -6.22938370e-03]\n"
     ]
    }
   ],
   "source": [
    "print(gravity.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103.001845,  84.204666, 220.811933, 132.00748 , 214.511814,\n",
       "       246.933305, 390.85611 , 505.089539, 103.001845,  45.796272,\n",
       "       216.994739, 129.878172, 140.706671, 201.232355, 343.50075 ,\n",
       "       453.515594,  84.204666,  45.796272, 249.932874, 158.630661,\n",
       "       186.420738, 244.108305, 387.61776 , 498.407152, 220.811933,\n",
       "       216.994739, 249.932874,  92.407958, 151.777157,  92.894408,\n",
       "       194.851669, 306.105825, 132.00748 , 129.878172, 158.630661,\n",
       "        92.407958, 124.563096, 122.433524, 261.893783, 376.34667 ,\n",
       "       214.511814, 140.706671, 186.420738, 151.777157, 124.563096,\n",
       "        81.753652, 208.456383, 314.793199, 246.933305, 201.232355,\n",
       "       244.108305,  92.894408, 122.433524,  81.753652, 145.076472,\n",
       "       258.591197, 390.85611 , 343.50075 , 387.61776 , 194.851669,\n",
       "       261.893783, 208.456383, 145.076472, 114.46325 , 505.089539,\n",
       "       453.515594, 498.407152, 306.105825, 376.34667 , 314.793199,\n",
       "       258.591197, 114.46325 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Oi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpIntDataset(Dataset):\n",
    "    def __init__(self, input_paras,target_flows):\n",
    "        '''\n",
    "        '''\n",
    "        self.in_torch = torch.from_numpy(input_paras).t().view(-1,1,3).float()\n",
    "        self.out_torch =  torch.from_numpy(target_flows).float().view(-1,1,1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.in_torch)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        in_f = self.in_torch[idx,:,:]\n",
    "        tar_flow = self.out_torch[idx,:,:]\n",
    "        sample = {'input': in_f, 'output': tar_flow}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(3,8)\n",
    "        self.fc2 = nn.Linear(8,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1131,  1887,    69,   738,    98,    31,    43,    19,  1633,\n",
       "       14055,   416,  1276,  1850,   388,   303,   159,  2301, 20164,\n",
       "        1080,  1831,  1943,   742,   674,   407,    85,   379,  1597,\n",
       "        1608,   328,   317,   469,   114,   762,  1110,  2973,  1252,\n",
       "        1081,   622,   425,   262,   196,  2027,  3498,   346,  1332,\n",
       "        2144,   821,   274,    49,   378,  1349,   310,   851,  2117,\n",
       "         630,   106,    87,   424,   978,   490,   670,   577,   546,\n",
       "         569,    33,   128,   643,   154,   328,   199,   112,   587],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4016.0000, 25741.0000,   103.0018]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = np.vstack((Oi,Dj,Dij))\n",
    "in_torch = torch.from_numpy(input_features)\n",
    "in_torch = in_torch.t()\n",
    "in_torch = in_torch.view(-1,1,3)\n",
    "in_torch = in_torch.float()\n",
    "in_torch[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.29804166, 10.15584033,  4.6347469 ],\n",
       "       [ 8.29804166, 10.20285113,  4.43325034],\n",
       "       [ 8.29804166,  8.32288002,  5.39731136],\n",
       "       [ 8.29804166,  9.06346318,  4.88285859],\n",
       "       [ 8.29804166,  9.01103541,  5.36836481],\n",
       "       [ 8.29804166,  8.49739856,  5.50911828],\n",
       "       [ 8.29804166,  8.28197706,  5.96833949],\n",
       "       [ 8.29804166,  7.55485852,  6.22473572],\n",
       "       [ 9.90747957,  8.54597499,  4.6347469 ],\n",
       "       [ 9.90747957, 10.20285113,  3.82420269],\n",
       "       [ 9.90747957,  8.32288002,  5.37987311],\n",
       "       [ 9.90747957,  9.06346318,  4.86659687],\n",
       "       [ 9.90747957,  9.01103541,  4.94667738],\n",
       "       [ 9.90747957,  8.49739856,  5.30446024],\n",
       "       [ 9.90747957,  8.28197706,  5.8391893 ],\n",
       "       [ 9.90747957,  7.55485852,  6.11702965],\n",
       "       [10.27993571,  8.54597499,  4.43325034],\n",
       "       [10.27993571, 10.15584033,  3.82420269],\n",
       "       [10.27993571,  8.32288002,  5.52119238],\n",
       "       [10.27993571,  9.06346318,  5.06657861],\n",
       "       [10.27993571,  9.01103541,  5.22800615],\n",
       "       [10.27993571,  8.49739856,  5.497612  ],\n",
       "       [10.27993571,  8.28197706,  5.9600197 ],\n",
       "       [10.27993571,  7.55485852,  6.21141732],\n",
       "       [ 8.49637805,  8.54597499,  5.39731136],\n",
       "       [ 8.49637805, 10.15584033,  5.37987311],\n",
       "       [ 8.49637805, 10.20285113,  5.52119238],\n",
       "       [ 8.49637805,  9.06346318,  4.5262131 ],\n",
       "       [ 8.49637805,  9.01103541,  5.02241337],\n",
       "       [ 8.49637805,  8.49739856,  4.53146345],\n",
       "       [ 8.49637805,  8.28197706,  5.2722386 ],\n",
       "       [ 8.49637805,  7.55485852,  5.72393088],\n",
       "       [ 9.04629086,  8.54597499,  4.88285859],\n",
       "       [ 9.04629086, 10.15584033,  4.86659687],\n",
       "       [ 9.04629086, 10.20285113,  5.06657861],\n",
       "       [ 9.04629086,  8.32288002,  4.5262131 ],\n",
       "       [ 9.04629086,  9.01103541,  4.82481238],\n",
       "       [ 9.04629086,  8.49739856,  4.80756822],\n",
       "       [ 9.04629086,  8.28197706,  5.56793901],\n",
       "       [ 9.04629086,  7.55485852,  5.93051071],\n",
       "       [ 9.27218778,  8.54597499,  5.36836481],\n",
       "       [ 9.27218778, 10.15584033,  4.94667738],\n",
       "       [ 9.27218778, 10.20285113,  5.22800615],\n",
       "       [ 9.27218778,  8.32288002,  5.02241337],\n",
       "       [ 9.27218778,  9.06346318,  4.82481238],\n",
       "       [ 9.27218778,  8.49739856,  4.40371048],\n",
       "       [ 9.27218778,  8.28197706,  5.33972983],\n",
       "       [ 9.27218778,  7.55485852,  5.75191591],\n",
       "       [ 8.66388757,  8.54597499,  5.50911828],\n",
       "       [ 8.66388757, 10.15584033,  5.30446024],\n",
       "       [ 8.66388757, 10.20285113,  5.497612  ],\n",
       "       [ 8.66388757,  8.32288002,  4.53146345],\n",
       "       [ 8.66388757,  9.06346318,  4.80756822],\n",
       "       [ 8.66388757,  9.01103541,  4.40371048],\n",
       "       [ 8.66388757,  8.28197706,  4.977261  ],\n",
       "       [ 8.66388757,  7.55485852,  5.55524842],\n",
       "       [ 8.37586002,  8.54597499,  5.96833949],\n",
       "       [ 8.37586002, 10.15584033,  5.8391893 ],\n",
       "       [ 8.37586002, 10.20285113,  5.9600197 ],\n",
       "       [ 8.37586002,  8.32288002,  5.2722386 ],\n",
       "       [ 8.37586002,  9.06346318,  5.56793901],\n",
       "       [ 8.37586002,  9.01103541,  5.33972983],\n",
       "       [ 8.37586002,  8.49739856,  4.977261  ],\n",
       "       [ 8.37586002,  7.55485852,  4.74025381],\n",
       "       [ 7.68891334,  8.54597499,  6.22473572],\n",
       "       [ 7.68891334, 10.15584033,  6.11702965],\n",
       "       [ 7.68891334, 10.20285113,  6.21141732],\n",
       "       [ 7.68891334,  8.32288002,  5.72393088],\n",
       "       [ 7.68891334,  9.06346318,  5.93051071],\n",
       "       [ 7.68891334,  9.01103541,  5.75191591],\n",
       "       [ 7.68891334,  8.49739856,  5.55524842],\n",
       "       [ 7.68891334,  8.28197706,  4.74025381]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=input_features.T\n",
    "X = np.log(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=flows.reshape(-1,1)\n",
    "Y = np.log(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   168.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 01 Dec 2019</td> <th>  Prob (F-statistic):</th>          <td>1.04e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:23:04</td>     <th>  Log-Likelihood:    </th>          <td> -159.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    72</td>      <th>  AIC:               </th>          <td>   324.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    69</td>      <th>  BIC:               </th>          <td>   330.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.0002</td> <td> 2.69e-05</td> <td>    7.571</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.0002</td> <td> 2.58e-05</td> <td>    7.346</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.0072</td> <td>    0.002</td> <td>    4.664</td> <td> 0.000</td> <td>    0.004</td> <td>    0.010</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.171</td> <th>  Durbin-Watson:     </th> <td>   0.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.124</td> <th>  Jarque-Bera (JB):  </th> <td>   2.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.093</td> <th>  Prob(JB):          </th> <td>   0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.183</td> <th>  Cond. No.          </th> <td>    94.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.880\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.875\n",
       "Method:                 Least Squares   F-statistic:                              168.9\n",
       "Date:                Sun, 01 Dec 2019   Prob (F-statistic):                    1.04e-31\n",
       "Time:                        22:23:04   Log-Likelihood:                         -159.05\n",
       "No. Observations:                  72   AIC:                                      324.1\n",
       "Df Residuals:                      69   BIC:                                      330.9\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0002   2.69e-05      7.571      0.000       0.000       0.000\n",
       "x2             0.0002   2.58e-05      7.346      0.000       0.000       0.000\n",
       "x3             0.0072      0.002      4.664      0.000       0.004       0.010\n",
       "==============================================================================\n",
       "Omnibus:                        4.171   Durbin-Watson:                   0.803\n",
       "Prob(Omnibus):                  0.124   Jarque-Bera (JB):                2.106\n",
       "Skew:                          -0.093   Prob(JB):                        0.349\n",
       "Kurtosis:                       2.183   Cond. No.                         94.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation functions and their gradient functions\n",
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def sigmoid_grad(X):\n",
    "    return sigmoid(X) * (1 - sigmoid(X))\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def tanh_grad(z):\n",
    "     return 1 - np.tanh(z) ** 2\n",
    "\n",
    "def ReLU(z):\n",
    "    return np.clip(z, 0, np.inf)\n",
    "\n",
    "def ReLU_grad(z):\n",
    "    return (z > 0).astype(int)\n",
    "\n",
    "def affine(X,slope=1,intercept=0):\n",
    "     return slope * X + intercept\n",
    "    \n",
    "def affine_grad(X,slope=1,intercept=0):\n",
    "    return slope * np.ones_like(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define neural network model\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_dim, output_dim=1,hidden_dim = 4,lr=0.005):\n",
    "        #init weights\n",
    "        self.weights1   = np.random.rand(input_dim+1,hidden_dim) \n",
    "        self.weights2   = np.random.rand(hidden_dim,output_dim)                 \n",
    "        #set learning rate\n",
    "        self.lr         = lr\n",
    "      \n",
    "    def print_w(self):\n",
    "        '''print weight to inspect the current values of network'''  \n",
    "        print('print_weights ------------>')\n",
    "        print(self.weights1)\n",
    "        print(self.weights2)\n",
    "        \n",
    "    def feedforward(self,X):\n",
    "        X = np.hstack((X,np.ones((X.shape[0],1))))\n",
    "        self.layer1 = affine(np.dot(X, self.weights1))\n",
    "        self.output = affine(np.dot(self.layer1, self.weights2))\n",
    "        \n",
    "    def backprop(self,X, Y):\n",
    "        X = np.hstack((X,np.ones((X.shape[0],1))))\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(Y - self.output) * affine_grad(np.dot(self.layer1, self.weights2))))\n",
    "        d_weights1 = np.dot(X.T,  \\\n",
    "                            (np.dot(2*(Y - self.output) * affine_grad(np.dot(self.layer1, self.weights2)), self.weights2.T)\\\n",
    "                             * affine_grad(np.dot(X, self.weights1))))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function multiply learning rate\n",
    "        self.weights1 += d_weights1*self.lr\n",
    "        self.weights2 += d_weights2*self.lr\n",
    "    \n",
    "    def test(self,X):\n",
    "        '''get predicted values for any input data'''\n",
    "        X = np.hstack((X,np.ones((X.shape[0],1))))\n",
    "        hidden_layer1 = affine(np.dot(X, self.weights1))\n",
    "        return affine(np.dot(hidden_layer1, self.weights2))\n",
    "        \n",
    "    def train(self,X,Y,num_train_iterations):\n",
    "        '''train model with X and Y for num_train_iterations times'''\n",
    "        print('training  ---------------->')\n",
    "        for iteration in range(num_train_iterations): \n",
    "            self.feedforward(X) \n",
    "            self.backprop(X,Y)\n",
    "            #print interim MSE\n",
    "            if iteration % 100 == 0:\n",
    "                mse = np.mean((self.output - Y)**2)\n",
    "                print(\"Epoch \", iteration, \"MSE: \", mse)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training  ---------------->\n",
      "Epoch  0 MSE:  309592585.0041365\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardz/.local/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in add\n",
      "/home/leonardz/.local/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n",
      "training  ---------------->\n",
      "Epoch  0 MSE:  nan\n",
      "Epoch  100 MSE:  nan\n",
      "Epoch  200 MSE:  nan\n",
      "Epoch  300 MSE:  nan\n",
      "Epoch  400 MSE:  nan\n",
      "print_weights ------------>\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "predicted data ----------->\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "real data ---------------->\n",
      "[[4.58496748]\n",
      " [6.30261898]\n",
      " [6.98471632]\n",
      " [7.03085748]\n",
      " [5.79301361]\n",
      " [7.20711886]\n",
      " [6.03068526]\n",
      " [7.99732682]\n",
      " [7.52294092]\n",
      " [6.44571982]\n",
      " [5.61312811]\n",
      " [4.73619845]\n",
      " [9.55073348]\n",
      " [7.67042852]\n",
      " [3.4339872 ]]\n",
      "MSE on test data --------->\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "#initialize network with fixed output dim of 1\n",
    "neural_network = NeuralNetwork(X_train.shape[1],1,lr=1e-3)\n",
    "\n",
    "for index in range(0,X_train.shape[0],batch_size):\n",
    "    \n",
    "    \n",
    "    #get batch X and Y\n",
    "    batch_X=X_train[index:min(index+batch_size,X_train.shape[0]),:]\n",
    "    batch_Y=y_train[index:min(index+batch_size,y_train.shape[0])]\n",
    "    \n",
    "    #train model with batch\n",
    "    neural_network.train(batch_X,batch_Y,500)\n",
    "    \n",
    "    #print final state of weights\n",
    "    neural_network.print_w()\n",
    "\n",
    "    # Test the neural network with new test data. \n",
    "    #get predicted y\n",
    "    y_pred = neural_network.test(X_test)\n",
    "    #compare predicted y and groundtruth \n",
    "    print('predicted data ----------->')\n",
    "    print(y_pred)\n",
    "    print('real data ---------------->')\n",
    "    print(y_test)\n",
    "    #calculate MSE\n",
    "    mse = np.mean((y_test - y_pred)**2)\n",
    "    print('MSE on test data --------->')\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4016.0000, 26980.0000,    84.2047]],\n",
       "\n",
       "        [[ 4016.0000,  4117.0000,   220.8119]],\n",
       "\n",
       "        [[ 4016.0000,  8634.0000,   132.0075]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_torch[[1,2,3],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_torch = torch.from_numpy(flows).float()\n",
    "out_torch = out_torch.view(-1,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "spint_dataset = SpIntDataset(input_features,flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(spint_dataset, batch_size=1,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the network\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        in_f,out_f = data['input'], data['output']\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(in_f)\n",
    "        loss = criterion(outputs, out_f)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './austria_ann.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': tensor([[[29142.0000,  4117.0000,   249.9329]]]),\n",
       " 'output': tensor([[[1080.]]])}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(data['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 72])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4147]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = torch.randn(1, 1, 3)\n",
    "\n",
    "target_test = torch.randn(1,1,1)\n",
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()   # zero the gradient buffers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = net(in_torch)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(output, out_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9391175.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the network\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(in_torch)\n",
    "        loss = criterion(outputs, out_torch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
