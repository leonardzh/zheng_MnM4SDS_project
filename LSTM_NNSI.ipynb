{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence data prediction\n",
    "**author: Zheng Liu**\n",
    "<h5 style=\"color:purple;\">Simplified problem statement (Model 1): Given a consecutive sequence of flow for time t_0 to t_k-1, predict flow at t_k.</h5>\n",
    "\n",
    "\n",
    "<h5 style=\"color:orange;\">Extended problem statement (Model 2): Given a consecutive sequence of Oi, Dj and flow for time t_0 to t_k-1, and Oi, Dj for time t_k, predict flow at t_k. (Should import (Oi,Dj) in a different way into the model)</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf # high-level stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Use NYC taxi data.\n",
    "\n",
    "<h5 style=\"color:purple;\">Data for Model 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDatasetTaxiTimeSeries(hour_range):\n",
    "    \n",
    "    X = np.load('data/simple_taxi_X_24.npy')\n",
    "    Y = np.load('data/simple_taxi_Y_24.npy')\n",
    "    X_sel = X[:,0:3*hour_range]\n",
    "    Y_sel = Y[:,0:hour_range]\n",
    "    return (X_sel,Y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 24)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = loadDatasetTaxiTimeSeries(24)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19, 0.22, 0.23, ..., 0.16, 0.19, 0.16],\n",
       "       [0.07, 0.04, 0.07, ..., 0.08, 0.08, 0.09],\n",
       "       [0.08, 0.02, 0.03, ..., 0.04, 0.06, 0.02],\n",
       "       ...,\n",
       "       [0.04, 0.01, 0.01, ..., 0.1 , 0.15, 0.07],\n",
       "       [0.19, 0.16, 0.06, ..., 0.68, 0.67, 0.53],\n",
       "       [0.01, 0.06, 0.03, ..., 0.1 , 0.13, 0.09]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = Y[:,0:23]/100\n",
    "target = Y[:,23]/100\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange;\">Data for Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Under development**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:purple;\">Load Data for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(seq, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results -- Time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple OLS Regression model\n",
    "<h5 style=\"color:purple;\">for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLSregression(X_train,y_train,X_test,y_test):\n",
    "    X_train_1 = sm.add_constant(X_train)\n",
    "    X_test_1 = sm.add_constant(X_test)\n",
    "\n",
    "    model = sm.OLS(y_train,X_train_1)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "    y_pred = np.exp(results.predict(X_test_1))\n",
    "    pear = scipy.stats.pearsonr(y_test, y_pred)\n",
    "    print('Pearson\\'s r is {:6f}'.format(pear[0]))\n",
    "    mse = np.mean((y_test - y_pred)**2)\n",
    "    print('MSE is {:6f}'.format(mse))\n",
    "\n",
    "    df = pd.DataFrame({'X_Axis': X_test[:, 1], 'y_test': y_test, 'y_pred':y_pred})\n",
    "    df_m = df.melt('X_Axis', var_name='cols',  value_name='vals')\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    sns.scatterplot(x=\"y_test\", y=\"y_pred\", data=df)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.912\n",
      "Model:                            OLS   Adj. R-squared:                  0.909\n",
      "Method:                 Least Squares   F-statistic:                     348.4\n",
      "Date:                Tue, 10 Dec 2019   Prob (F-statistic):               0.00\n",
      "Time:                        23:52:05   Log-Likelihood:                 823.17\n",
      "No. Observations:                 800   AIC:                            -1598.\n",
      "Df Residuals:                     776   BIC:                            -1486.\n",
      "Df Model:                          23                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0085      0.005      1.559      0.119      -0.002       0.019\n",
      "x1             0.5567      0.041     13.444      0.000       0.475       0.638\n",
      "x2             0.1661      0.057      2.926      0.004       0.055       0.278\n",
      "x3            -0.1680      0.068     -2.459      0.014      -0.302      -0.034\n",
      "x4            -0.0340      0.084     -0.404      0.686      -0.199       0.131\n",
      "x5             0.1405      0.089      1.586      0.113      -0.033       0.314\n",
      "x6            -0.0180      0.067     -0.269      0.788      -0.149       0.113\n",
      "x7             0.0495      0.031      1.616      0.107      -0.011       0.110\n",
      "x8            -0.0363      0.022     -1.618      0.106      -0.080       0.008\n",
      "x9             0.0453      0.024      1.914      0.056      -0.001       0.092\n",
      "x10           -0.0179      0.030     -0.587      0.558      -0.078       0.042\n",
      "x11           -0.1092      0.038     -2.910      0.004      -0.183      -0.036\n",
      "x12            0.0334      0.028      1.174      0.241      -0.022       0.089\n",
      "x13            0.0068      0.033      0.205      0.838      -0.058       0.072\n",
      "x14            0.0817      0.032      2.536      0.011       0.018       0.145\n",
      "x15            0.0100      0.028      0.360      0.719      -0.044       0.064\n",
      "x16            0.0109      0.027      0.405      0.685      -0.042       0.063\n",
      "x17           -0.0810      0.031     -2.637      0.009      -0.141      -0.021\n",
      "x18           -0.0285      0.026     -1.075      0.283      -0.080       0.023\n",
      "x19            0.0257      0.027      0.950      0.342      -0.027       0.079\n",
      "x20            0.0144      0.027      0.544      0.587      -0.038       0.067\n",
      "x21            0.0224      0.025      0.885      0.376      -0.027       0.072\n",
      "x22            0.0286      0.031      0.934      0.350      -0.031       0.089\n",
      "x23            0.3539      0.024     14.517      0.000       0.306       0.402\n",
      "==============================================================================\n",
      "Omnibus:                      112.749   Durbin-Watson:                   1.951\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              593.966\n",
      "Skew:                           0.508   Prob(JB):                    1.05e-129\n",
      "Kurtosis:                       7.097   Cond. No.                         109.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Pearson's r is 0.919028\n",
      "MSE is 1.275707\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Axis</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.279593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.373257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.909946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.154420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.274844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.101601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.195438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.120324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.176414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.142141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_Axis  y_test    y_pred\n",
       "0      0.31    0.90  2.279593\n",
       "1      0.21    0.40  1.373257\n",
       "2      0.27    0.96  1.909946\n",
       "3      0.03    0.22  1.154420\n",
       "4      0.12    0.22  1.274844\n",
       "..      ...     ...       ...\n",
       "195    0.05    0.11  1.101601\n",
       "196    0.10    0.15  1.195438\n",
       "197    0.02    0.19  1.120324\n",
       "198    0.07    0.22  1.176414\n",
       "199    0.05    0.16  1.142141\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7EAAAJNCAYAAADnBPKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdf3TkZ30f+s8z+rVa7RKLtbwhXoM5jXHrcp3AKmCzPW2AlJumDtyNnSYNtkOa+EedFvqLuD0nTm5L0lvDbbnh+mwxLmkwJgkOxgmXNFwIMTftBki0FBzHdIG2oaxL1rKQiVYrSyvNc//YldjRzOyONPOdme/o9TpnD6uZr2ae76wgeevzPJ9PyjkHAAAAlEGl1wsAAACAVgmxAAAAlIYQCwAAQGkIsQAAAJSGEAsAAEBpCLEAAACUxnCvF7Adl156ab7yyit7vQwAAAAKcOzYsWdyzlONnitliL3yyitjZmam18sAAACgACmlrzZ7znZiAAAASkOIBQAAoDSEWAAAAEqjKyE2pTSUUvrPKaWPNnhuLKX0wZTSV1JKn00pXdmNNQEAAFA+3arEviUivtjkuZ+MiPmc83dGxDsj4t4urQkAAICSKTzEppQORMTfjIh/1+SSN0TE+879/UMR8dqUUip6XQAAAJRPNyqx/1dE/ExEVJs8f3lEfC0iIue8GhHfjIh9XVgXAAAAJVNoiE0p3RART+ecj13osgaP5QavdXtKaSalNDM7O9uxNQIAAFAeRVdiD0XE61NKfxoRvx4Rr0kpPbTpmhMRcUVEREppOCK+LSK+sfmFcs7vyTlP55ynp6amil01AAAAfanQEJtz/mc55wM55ysj4kcj4vdyzjdvuuwjEfHj5/5+07lr6iqxAAAAMNyLN00p/YuImMk5fyQi3hsR708pfSXOVmB/tBdrAgAAoP91LcTmnD8VEZ869/efO+/x5yLih7u1DgAAAMqrW3NiAQAAoG1CLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAaw71eAAAAAMWpVnPMLa7EyupajA4Pxb6J0ahUUq+XtW1CLAAAwICqVnMcP7kQtz04Eyfml+LA5Hg8cOt0XL1/b2mDrO3EAAAAA2pucWUjwEZEnJhfitsenIm5xZUer2z7hFgAAIABtbK6thFg152YX4qV1bUerah9QiwAAMCAGh0eigOT4zWPHZgcj9HhoR6tqH1CLAAAwIDaNzEaD9w6vRFk18/E7psY7fHKtk9jJwAAgAFVqaS4ev/eePSuQ7oTAwAA0P8qlRRTe8d6vYyOsZ0YAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKA0hFgAAgNIQYgEAACgNIRYAAIDSEGIBAAAojUJDbEppV0rpD1NKX0gp/UlK6Z83uOZNKaXZlNLnz/35qSLXBAAAQHkNF/z6yxHxmpzzqZTSSET8p5TS7+ScP7Ppug/mnP9ewWsBAACg5AoNsTnnHBGnzn05cu5PLvI9AQAAGFyFn4lNKQ2llD4fEU9HxCdyzp9tcNmNKaXHU0ofSildUfSaAAAAKKfCQ2zOeS3n/N0RcSAiXpFSeummS/6fiLgy53xtRPxuRLyv0euklG5PKc2klGZmZ2eLXTQAAAB9qWvdiXPOz0bEpyLi+zc9PpdzXj735QMRcbDJ978n5zydc56empoqdK0AAAD0p6K7E0+llC459/fxiPi+iPgvm655wXlfvj4ivljkmgAAACivorsTvyAi3pdSGoqzgfnhnPNHU0r/IiJmcs4fiYg3p5ReHxGrEfGNiHhTwWsCAACgpNLZBsLlMj09nWdmZnq9DAAAAAqQUjqWc55u9FzXzsQCAABAu4RYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hnu9AAAA6LZqNcfc4kqsrK7F6PBQ7JsYjUol9XpZQAuEWAAAdpRqNcfxkwtx24MzcWJ+KQ5MjscDt07H1fv3CrJQArYTAwCwo8wtrmwE2IiIE/NLcduDMzG3uNLjlQGtEGIBANhRVlbXNgLsuhPzS7GyutajFQFbIcQCALCjjA4PxYHJ8ZrHDkyOx+jwUI9WBGyFEAsAwI6yb2I0Hrh1eiPIrp+J3Tcx2uOVAa3Q2AkAgB2lUklx9f698ehdh3QnhhISYgEA2HEqlRRTe8d6vQxgG2wnBgAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKQ4gFAACgNIRYAAAASkOIBQAAoDSEWAAAAEpDiAUAAKA0hFgAAABKo9AQm1LalVL6w5TSF1JKf5JS+ucNrhlLKX0wpfSVlNJnU0pXFrkmAAAAyqvoSuxyRLwm5/xdEfHdEfH9KaXrNl3zkxExn3P+zoh4Z0TcW/CaAAAAKKlCQ2w+69S5L0fO/cmbLntDRLzv3N8/FBGvTSmlItcFAABAORV+JjalNJRS+nxEPB0Rn8g5f3bTJZdHxNciInLOqxHxzYjYV/S6AAAAKJ/CQ2zOeS3n/N0RcSAiXpFSeummSxpVXTdXayOldHtKaSalNDM7O1vEUgEAAOhzXetOnHN+NiI+FRHfv+mpExFxRURESmk4Ir4tIr7R4Pvfk3OezjlPT01NFbxaAAAA+lHR3YmnUkqXnPv7eER8X0T8l02XfSQifvzc32+KiN/LOddVYgEAAGC44Nd/QUS8L6U0FGcD88M554+mlP5FRMzknD8SEe+NiPenlL4SZyuwP1rwmgAAACipQkNszvnxiHhZg8d/7ry/PxcRP1zkOgAAABgMXTsTCwAAAO0SYgEAACgNIRYAAIDSEGIBAAAoDSEWAACA0hBiAQAAKI2i58QCALAF1WqOucWVWFldi9Hhodg3MRqVSur1sgD6hhALANAnqtUcx08uxG0PzsSJ+aU4MDkeD9w6HVfv3yvIApxjOzEAQJ+YW1zZCLARESfml+K2B2dibnGlxysD6B9CLABAn1hZXdsIsOtOzC/Fyupaj1YE0H+EWACAPjE6PBQHJsdrHjswOR6jw0M9WhFA/xFiAYCWVas5ZheW46n50zG7sBzVau71kgbKvonReODW6Y0gu34mdt/EaI9XBtA/NHYCAFqi6VDxKpUUV+/fG4/edUh3YoAmVGIBgJZoOtQdlUqKqb1jcfnk7pjaOybAAmwixAIALdF0CIB+IMQCAC3RdAiAfiDEAgAt0XQIgH6gsRMA0BJNhwDoB0IsANCy9aZDANArthMDAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBpCLAAAAKUhxAIAAFAawxd6MqX0xxGRmz2fc7624ysCAPpWtZpjbnElVlbXYnR4KPZNjEalknq9LAB2kAuG2Ii44dx//vS5/3z/uf98Y0ScLmRFAEBfqlZzHD+5ELc9OBMn5pfiwOR4PHDrdFy9f68gC0DXXHA7cc75qznnr0bEoZzzz+Sc//jcn38aEf9rd5YIAPSDucWVjQAbEXFifilue3Am5hZXerwyAHaSVs/ETqSU/sr6FymlV0XERDFLAgD60crq2kaAXXdifilWVtd6tCIAdqKLbSde95MR8csppW+Ls2dkvxkRf6ewVQEAfWd0eCgOTI7XBNkDk+MxOjzUw1XBzuNsOjtdS5XYnPOxnPN3RcS1EfHdOefvzjl/7mLfl1K6IqX0WErpiymlP0kpvaXBNd+bUvpmSunz5/783NZvAwAo2r6J0Xjg1uk4MDkeEbFxJnbfxGiPVwY7x/rZ9MNHjsahex+Lw0eOxvGTC1GtNu3FCgMn5XzxH/iU0v6I+JcR8R0557+RUromIq7POb/3It/3goh4Qc75cymlvRFxLCL+t5zzk+dd870R8U9yzjc0eZk609PTeWZmptXLAYAOUQGC3ppdWI7DR47W7Yh49K5DMbV3rIcrg85KKR3LOU83eq7VM7G/EhH/b0R8x7mvvxQR/+Bi35Rz/vp6xTbnvBARX4yIy1t8TwCgz1QqKab2jsXlk7tjau+YAAtd5mw6tB5iL805PxwR1YiInPNqRGzpvykppSsj4mUR8dkGT1+fUvpCSul3Ukp/ucn3355SmkkpzczOzm7lrQEAYCCsn00/n7Pp7DSthtjFlNK+ONvUKVJK18XZ5k4tSSntiYhHIuIf5Jz/fNPTn4uIF507c/t/R8RvNnqNnPN7cs7TOefpqampVt8aAAAGhrPp0Hp34n8UER+JiL+QUjoaEVMRcVMr35hSGomzAfYDOecPb37+/FCbc/4PKaUjKaVLc87PtLg2AOgLzosCRatUUly9f288etch/1vDjnXREJtSqkTEroj4axFxdUSkiDiecz7TwvemiHhvRHwx5/xvmlzz7RFxMuecU0qviLPV4bnWbwEAem+9Y+htD87EifmljerI1fv3+n8ugY5aP5sOO9VFtxPnnKsR8a9zzqs55z/JOT/RSoA951BE3BIRrzlvhM4PpJTuTCndee6amyLiiZTSFyLiXRHxo7mVlskA0EfmFlc2AmzE2UYrtz04E3OLKz1eGQAMlla3E388pXRjRHx4KwEz5/yf4mzl9kLX3BcR97X6mgDQj3QMBYDu2MqZ2ImIWEspLcXZYJpzzs8rbGUAUCLrHUM3z27UMRQAOqul7sQ5570550rOeSTn/LxzXwuwAHCOjqEA0B2tVmIjpfRDEfFX4uyYnf+Yc244CgcAdiIdQwGgO1oKsSmlIxHxnRHxa+ceujOl9Ndzzj9d2MoAoGR0DAWA4rVaif1rEfHS9aZOKaX3RcQfF7YqAAAAaKClM7ERcTwiXnje11dExOOdXw4AAAA012oldl9EfDGl9Ifnvv6eiPh0SukjERE559cXsTgAAAA4X6sh9ucKXQUAAAC0oKUQm3P+/y70fErp0znn6zuzJAAAAGis1TOxF7OrQ68DAAAATXUqxOYOvQ4AAAA01akQCwAAAIVrKcSmlP5eSmnyQpd0aD0AAADQVKuV2G+PiD9KKT2cUvr+lNLm0HpLh9cFAAAAdVoKsTnnn42IqyLivRHxpoj4ckrpX6aU/sK5558obIUAAABwTstnYnPOOSL+7Nyf1YiYjIgPpZTeXtDaAAAAoEZLc2JTSm+OiB+PiGci4t9FxFtzzmdSSpWI+HJE/ExxSwQAAICzWgqxEXFpRPxQzvmr5z+Yc66mlG7o/LIAAACgXkshNuf8cxd47oudWw4AAAA0Z04sAAAApSHEAgAAUBqtnokFAApUreaYW1yJldW1GB0ein0To1GpbB7LDgAIsQDQY9VqjuMnF+K2B2fixPxSHJgcjwdunY6r9+8VZAFgE9uJAaDH5hZXNgJsRMSJ+aW47cGZmFtc6fHKAKD/CLEA0GMrq2sbAXbdifmlWFld69GKAKB/CbEA0GOjw0NxYHK85rEDk+MxOjzUoxUBQP8SYgGgx/ZNjMYDt05vBNn1M7H7JkZ7vDIA6D8aOwFAj1UqKa7evzceveuQ7sQAcBFCLAD0gUolxdTesV4vAwD6nhALAPSUGbkAbIUQCwD0jBm5AGyVxk4AQM+YkQvAVgmxAEDPmJELwFYJsQBAz5iRC8BWCbEAQM+YkQvAVmnsBAD0TCdm5OpuDLCzCLEAQE+1MyNXd2OAncd2YgCgtHQ3Bth5hFgAoLR0NwbYeYRYAKC0dDcG2HmEWACgtHQ3Bth5NHYCAEqrE92NASgXIRYAKLV2uhsDUD62EwMAAFAaQiwAAAClIcQCAABQGkIsAAAApSHEAgAAUBq6EwNAH6hWc8wtrhgTAwAXIcQCQI9VqzmOn1yI2x6ciRPzS3FgcjweuHU6rt6/V5AFgE1sJwaAHptbXNkIsBERJ+aX4rYHZ2JucaXHKwOA/qMSCwAdst0twSuraxsBdt2J+aVYWV0raqkAUFpCLAB0QDtbgkeHh+LA5HhNkD0wOR6jw0NFLxsASsd2YgDogHa2BO+bGI0Hbp2OA5PjEREbAXjfxGihawaAMlKJBegzutSWUztbgiuVFFfv3xuP3nXIvzsAXIQQC9BHdKktr3a3BFcqKab2jhW1PAAYGLYTA/QRXWrLqyxbgqvVHLMLy/HU/OmYXViOajX3ekkAsCUqsQB9RJfa8irDlmCVfgAGgUosQB9Z35J6vkHoUrtTqn/rW4Ivn9wdU3vH+i4YqvQDMAiEWGAglTU0XWhLalnvab36d/jI0Th072Nx+MjROH5yoTTrHyQq/QAMAtuJgYFT5i2TzbakRkRp76lZ9e/Ruw5pZNRl5tECMAhUYoGBU/Ytk422pJb5nlT/+kdZmk8BwIWoxAIDZxBDU5nvSfWvf5Sh+RQAXIxKLDBwBrE5UpnvqRPVv7KeB+5H/d58CgAuJuVcvv9HYHp6Os/MzPR6GUCfKvOZ2GbKfk/Vao65xZVtVf/Kfu8AwNallI7lnKcbPifEAoOondDUrwbxnloxu7Ach48crduO3K3GUDv1cweAXrpQiHUmFhhI61smB8kg3lMrenkeWBUYAPqPM7EA9LVengcuc1doABhUQiwAfa2XY2HK3BUaAAaV7cQA9LVejoUxHggA+o9KLAB9r1djYXpZBQYAGlOJBYAmelkFBgAaE2IB4AJ2aldoAOhXQiwAA82cVwAYLEIsAAPLnFcAGDwaOwEwsMx5BYDBoxILwMDa6pxXW48BoP8VWolNKV2RUnospfTFlNKfpJTe0uCalFJ6V0rpKymlx1NKLy9yTQDsHOtzXs/XbM7r+tbjw0eOxqF7H4vDR47G8ZMLUa3mbi0XAGhB0duJVyPiH+ec/1JEXBcRP51SumbTNX8jIq469+f2iPi3Ba8JgB1iK3NebT0GgHIodDtxzvnrEfH1c39fSCl9MSIuj4gnz7vsDRHxYM45R8RnUkqXpJRecO57AWDbtjLndWV1Lab2jMU9N1wTl4yPxLNLZ+Ldn/qvTbceAwC90bUzsSmlKyPiZRHx2U1PXR4RXzvv6xPnHqsJsSml2+NspTZe+MIXFrVMAAZMq3Nex0eH4me+/+p464ce3+hk/I6bro3x0fqtxwBA73SlO3FKaU9EPBIR/yDn/Oebn27wLXUHkHLO78k5T+ecp6empopYJgA72Go1bwTYiLPbid/6ocdjdcDOxFarOWYXluOp+dMxu7DszC8ApVN4JTalNBJnA+wHcs4fbnDJiYi44ryvD0TE/yx6XQBwvjOr1YadjM+sVnu0os4zNxeAQVB0d+IUEe+NiC/mnP9Nk8s+EhG3nutSfF1EfNN5WAC6bWS40rCT8cjw4IxU17wKgEFQ9P9lPhQRt0TEa1JKnz/35wdSSnemlO48d81/iIj/FhFfiYgHIuKugtcEAHWGKynecdO1NZ2M33HTtTE8QBXKrc7NBYB+VHR34v8Ujc+8nn9NjoifLnIdAHAxSytr8faPHa/pTvz2jx2P+37sZRETvV5dZ6zPzT0/yDabmwsA/apr3YkB2Lmq1RxziysXHXPTS6PDQzF7ajnueP+xjccGLeCtz83dfCa20dxcAOhX6WwhtFymp6fzzMxMr5cBQAvK0kyoWs3xp3OL8dW507F7dChOr6zFi/btjiv3TfTVOttVhl8oAEBK6VjOebrRcyqxABSqWTOhR+861NL81maKCGPLq9W457eeqAnbg6bVubkA0K8Gp+UiwIAYtDmeF2omtN37XK/uHj5yNA7d+1gcPnI0jp9caOuzKlPn3kH7GQGArVCJBegjZdl6uxXNmgmtVXMcPnJ0W/dZRHW3LJ17B/FnBAC2QiUWoI+UqRrYqvVmQuePrrn/loPxC7/95Lbvs4jAuR62z9ePjZ0G8WcEALZCJRagj5SlGrgVlUqKq/fvjUfvOrRxfrVarcbHn3y65rqt3GcRo2LK0rl3EH9GAGArhFiAPjKoczw3NxOaXVhu6z6LCJyNwnY/du4d1J+RXtKxGaBcjNgB6CM75bxjJ+5zpwaPnfIz0i0+T4D+dKERO0IsQJ/ZKeFsp9xnEXx2nTO7sLzRYGzdgcnxtkdAAdAec2IBSmSnzPHcKfdZBJ9d5zhjDFA+uhMDADtWWbpSA/AtQiwAsGM1GgHVj12pAfgW24kBgB2rm12pnWUG6AwhFgDY0bpxxlgXZIDOsZ0YAKBgc4srGwE24mzzqNsenIm5xZUerwygfIRYAICC6YIM0DlCLABAwXRBBugcIRYAoGC6IAN0jsZOAHCO7rEUpZtdkAEGnRALAKF7LMXrRhdkgJ3AdmKAkqhWc8wuLMdT86djdmE5qtXc6yUNFN1jAaAcVGIB2tCt7aeqhMXTPRYAykElFmCb1oPl4SNH49C9j8XhI0fj+MmFQiqkqoTF0z0WAMpBiAXYpm4GS1XC4ukeCwDlYDsxwDZ1M1iuVwnPfz9Vws7SPRYAykElFmCburn9VJWwO9a7x14+uTum9o4JsADQh1LO5etuOT09nWdmZnq9DGCH63azJTNMAYCdIqV0LOc83eg524kBWtQoRDbbflpE4DRjEgBAiAVoyYWqrpuDpXE4AADFcSYWoAVb6URcpnE41WqO2YXleGr+dMwuLBcyHggAoJNUYgFasJVOxGUZh6NiDACUkUosQAu20om4m12L21GminGrVJYBYPAJsQAt2MqIm7KMwylLxbhV65Xlw0eOxqF7H4vDR47G8ZMLgiwADBjbiQFaUKmkpp2I27l2Kzrd8Xi9Ynx+kO3HinGrmlWWH73rkK7OBTP+CYBuEmIBWrSVETedHodTxPnV9Yrx5tfst4pxqwatslwWzlYD0G1CLLDjlaGKVESVsaiKca8UVVkuw89HL6mAA9BtQiywo5WlilRUlbHTFeNeKqKyXJafj15SAQeg24RYYEdrVkX68F2vihSpb6pvg3Z+tQhFVJZVGS/OzyYA3aY7MbCjNasinV5e66sut2XpeNxr65Xlyyd3x9TesbZ/8aDKeHF+NgHoNpVYoKmdcBawWRXpvz+z2FfVt0E7v1oWqowX52cTgG5TiQUa2ikzNxtVke6/+WC865NfrrmuH6pvna4yDqJqNcfswnI8NX86ZheW2/55VWVsjZ9NALpJJRZoaKecBWxURRqqRMyeWq65TvWt/xXRhEmVEQD6j0os0NBOOgu4uYp0ybjqWxk1+8XL3OJKW6+ryggA/UUlFmhoJ58FVH0rp530ixcA2MlUYoGGdvpZQNW38ln/xcv5dsovXgBgJ0k5l69Jy/T0dJ6Zmen1MmDg7YTuxGxfv/18FHEmFgDojZTSsZzzdKPnbCcGmlqvRnZSvwWffl1Tv+vHwGgbOADsDEIs0DW9Dj6NwmpE9F0YK4N+7V5dxC9eAID+4kws0DWd6B673TmgzebePrtUTEfbQaeJEgDQK0Is0DXtBp9mQbSVINssQC+tCGPboYkSANArQizQNe0Gn3Yquc0C9FoOYWwbdnr3agCgd4RYoGvaDT7tVHKbBehdIxVhbBvOb6J09O5Xx6N3HXKOGADoCo2dgK5pt3vsehA9P8i2WjVdD9CbGzhdOjEWl06M6Wi7DZooAQC9YE4s9AljXi6u3e7Gg/gZD+I9AQCYEwt9rtejZ8qi3Upuu5XDfguMfm4AgJ3ImVjoA50YPdOu7Y6u6bb1IHr55O6Y2jvWtbDWTmfkovTDzw0AQLcJsdAHej1zsx8DWr/px8DY658bAIBeEGKhD/R65mY/BrR+04+Bsdc/NwAAvSDEQh/o9czNfgxo/aYfA2Ovf24AAHpBYyfoA+02LGqm1UZE7Yyu2SmajejpZWAs6ucGAKCfGbEDA2ornWt1uW1Nv3UnBgAYVBcasSPEwoCaXViOw0eO1lVXH73rUMMxM8LiNOEAACAASURBVAIaAAD9wpxY2IG2es613RmqjQxaMB60+wEAKCMhFgZUr8+5DtoW5UG7HwCAstKdGAZUrzvXPrO43HBszzOLy115/04zhggAoD+oxMKA6nXn2ufONN7O/NyZalfev9OMIQIA6A8qsTDA1s+5Xj65O6b2jnV12+twSg3nqg6XdOdtP86JBQDYiYRYoBDDQ5V4x03X1mxnfsdN18bwUO/+Z6dazTG7sBxPzZ+O2YXlqFZb787e6+3ZAACcZTsxUIgza9V4+8eOxz03XBOXjI/Es0tn4u0fOx73/djLerKedhsz9Xp7NgAAZwmxQCFGh4di9tRy3PH+YxuP9XL7bbPGTM3m5jZSxBgiAAC2xnZiKKF2tsV2S79tv9WYCQBgMKjEQsmUZV5pv22/7fXcXAAAOkMlFkqmTPNKe9kdebN+qwwDALA9KrFQMrbFbk+/VYYvpFrNMbe40vfrBADoBSEWeqCdkNLNbbGDFqbK0JipLNvFAQB6pdDtxCmlX04pPZ1SeqLJ89+bUvpmSunz5/78XJHrgX6wHlIOHzkah+59LA4fORrHTy603JypW9ti211nmfRTo6wybRcHAOiFoiuxvxIR90XEgxe45j/mnG8oeB3QN9od9dKtbbGdGElTBv1W+bRdHADgwgqtxOacfz8ivlHke0DZdCKkdKNh0k4JU/1W+VzfLn4+XZQBAL6lH7oTX59S+kJK6XdSSn+514uBopUlpJRlne3qt7CuizIAwIX1urHT5yLiRTnnUymlH4iI34yIqxpdmFK6PSJuj4h44Qtf2L0VQoeth5TN21f7LaT06zo73Wyq3+bHlqmLMgBAL6Sci21gklK6MiI+mnN+aQvX/mlETOecn7nQddPT03lmZqYj64Ne6GXX36289+pqNZ4+tRxn1qoxMlSJy/aMxfBw7zZwFHF+td/OxAIAEJFSOpZznm70XE8rsSmlb4+IkznnnFJ6RZzd3jzXyzVBN/Rq1MtWAlu1muPLs6f6KtwV0WxK5RMAoFyKHrHzaxHx6Yi4OqV0IqX0kymlO1NKd5675KaIeCKl9IWIeFdE/GguujQMO9hWmhj1W8OjiOLOr3ajURYAAJ1RaCU25/y3L/L8fXF2BA/QBVsJgZ0IjIN+fhUAgO7rh+7EQJdspeNwu92J17cuHz5yNA7d+1gcPnI0jp9ciGp1+5stdkrn3mo1x+zCcjw1fzpmF5Y3PrNmj/dyTQAA3VZ4Y6ciaOzETrfdCudWz8S20/BodmE5Dh85Wlc1bef86vq6etUUqxuafe5XTe3p2Rllza8AgG67UGMnIRZKpt1AsZUQ2E5gfGr+dBy697G6x4/e/eq4fHJ3S6+xEzUL/w/fcX38rfs/3fFfCrSzpm68NwCwM10oxNpODCXTbsOlZk2MGm0XbafhUbvbkbdikLa6NjuLfGatWkhTq3bW1I33BgDYTIiFkikiUJT5/GoRa++lZuF/ZKjStV8KtLomDbUAgF4QYqFkiggURYzTOX/+6tG7Xx2P3nWokDOUzdb+zOJyKauzzcL/ZXvGetbUaqc01AIAyqHQETtA560His1nYtsJFEXPXy1Ss7WfXl6Lm9/72ZbODbdz9rfTjabOD/+bX7PZ40Xr5XsDAGwmxELBuhlytqvM81ebrX12YTnuueGauGR8JJ5dOhPv/MTx+MXD19aF6nYaZRXVtbdZ+O/GLwWa6eV7AwCcz3ZiKFBR5zUbNVxqp7nR5PhIvPvmgzXbRd9988GYHB9peE/9tE230VbXX/mJ74lqzvG2jz4ZP/Kez8TbPvpk/PirXhzVarXu+9vZSl3ENmwAAC5MJRYK1CzkdHo0SbsVwfmlM/GuT36ppnL5rk9+qa5y2Y/zQhtVplfXqvGm3/ijms/97kcej4fvuL7u+9vZSq1rLwBA9wmx0EGbtw53K+S0G5ZXVtfi408+HR9/8umax3/+B2vX2a1QvlWbt7o+NX+64eee89kq8vnbsNvZSl3mbdgAAGUlxEKHNKpS/upPvbIrIWcrYbnRGd3R4aF43TWXxY0Hr9ioxD5y7Gt16yxL5bFZuFyr5jh85GhNFfmqqT3bbpRVRJMtAAAuTIiFDmlUpfyF334y7r/lYNzx/mOFhpxWK4LNtgN/56UT8ebXviTufOhb62x0JrYslcdG4fL+Ww7GL/z2kw2ryNttlKVrLwBA96WcyzE78XzT09N5Zmam18uAGk/Nn45D9z5W9/hn/9lrolKpFBpyWj2rOruwvFGJXHdgcjwevuP6+Fv3f7ru8c3bhDtxJrbT3ZpbfZ9qtRqv/D9+r+66o3e/Oi6f3N3x9wcAYPtSSsdyztONnlOJhQ5pVqWsVCqFnxdttSLYbDvw6lq1pW3C7VYei2oM1SwYn/+5zy4sl6KKDADAhRmxAx3SaNRLN89HNhq7s9l60D7fgcnxGB6qNHy8UcBr5X2aeWZxuWFjqGcWl1t+jc1aHWPU638fAAA6w3ZiuIitbH/t1lbZ7WpWCb1qak98efZU4aNz/sc3FuOvvv1TdY///s+8Ol74/O1t6W22RbpRx+R+//cBAOAs24lhmy4U+uaXztSFoc1bWDvx/p0MXZVKiqum9sTDd1wfq2vVGB6qxGV7xmJ4uNKVBkVDKTXc0jvUxttspWNyp/99AADoPiEWLqBRx+F3fuJ4vOX7XlLXcfjq/Xs3vqcTQbCI86PVao7/MX86vjp3OnaPDsXplbV4bt9aXLlvoisBb2JsKI688eVx1wc+t3FPR9748pgY2/651LJ0TAYAoDOciYULaFTlu/HgFRsBNuJb5zqfXVpp6WxmqxoF6NsenIm5xZVt38+zSysxd2o57vmtJ+JH3vOZuOe3noi5U8vx7NL2X3MrVtZy3Pd7X457brgmPnj7dXHPDdfEfb/35VhZ2/6xBmddAQB2FpVYBl47W3IbVfn2TYw23L66tLLWMHQ2OpvZiq1sk23Vcytr8Q8f/kLNGv/hw1+Ih2+/LmJi2y/bsjOr1fj4k0/Hx598uubxn//B6rZf06xWAICdRYhloLW7JXe9ynf+91+2d6zh9tW1nDsaOovYJnum2niNq9usFm/V6PBQvO6ay+LGg1fEJeMj8ezSmXjk2Nfa3vrrrCsAwM4hxFIK262mNtuS22p1tFGVb3J8pC7YPnDrdOxqEjpHhre3a79RgG53m+xwpUljpS51W54cH4k3v/YlcedD3zpP/O6bD8bk+Mi2XxMAgJ3FiB36XjvV1KfmT8ehex+re/zo3a+Oyye3N9IlImJ1tRpPn1qOM2vVGDnX4ffPl8/E8T9biLd+6PGNdb7jpmvjL71gb5xZi20FwU6HyG8sLjdc49XfvjeeP1E/jqbTjaW2Mg4HAICdy4gd+lKrAa2damoRW3Kr1dxwpurzd4/E2z92PO654ZqNrbKPfu6peN6rrow7HqrvZLz5Xpt9Hp0Md5eMj8b+5+2Kt73hpRvdifc/b1dcMl5f3W23it3IVs75mukKAEAjQiw9sZUqXzsNjorYktss3D18x/Uxe2o57nj/sY1r//2bvmcjwJ5/7eYgWETVs5FKJcWV+yZi766Ri4bDIhpLtfpLhW59HgAAlI8RO/TEVsbHrAef87VaTT3/TOvRu18dj951qO0g1Czc5ZzrRr28+NKJloJgEeN0mlmv7l4+uTum9o41/Sza+dybaXUcTjc/DwAAykUllp7YSpWv3Wpqp7fkjgxXmjZw2twEKkduqfJYRNWzXUVUsVsdh9OPnwcAAP1BiKUnLhQEN+u3OaDDlRTvuOnauuZIw5VUF5ir1dxSECzi7G67ivrcW/mlQj9+HgAA9AfdiemKzU16KpUcX/qzUy11ye21zZ2IR4dS3Pbgsbjze//CRgOnd3/qv8Z9P/ayhh2PW2lQ1OwM6FVTe2J+6UxfhPduciYWAGBn052Yrtoc2ibHR+q6+T70k6+s6+T79o8dj/t+7GURE72+g29ZXa3Gfzm5UDPX9N/efDBeceUlNQ2c2q0SNptH26gL8k4Icv1WfQcAoH8IsXRUowra/bccjF/63S/VNOn5788s1nXy7fZ20VYqpE+fWt4IsOtr/7sPHYtfv/26+O0nTl70rOhWKoqbt9nOLix3fMTNVvVyzE2nzzIDADAYhFjqtBNcGnWVveP9x+Jf/dD/EjcevGKj6vo7f/z1uP/mg3XzU9tpGrQVrYbLM2vVhg2GqtXcUpWwnVmrF2pu1I1waUsvAAD9SIilRrvBpVnw+o5LxuPWX/7DmvOvl0/uqguCEWcrkK2Es06H7UbhcmSocQOq4aFKwxC6eU3tdNlt1txoZLjSlXDZTgAHAICimBNLjXbnczabLfrVudM1r/nWDz0eK2u5Zl5pRMTxkwtx+MjROHTvY3H4yNE4fnIhqtX65mPrYbuVaxtpNVzuHq3EkTe+vGau6ZE3vjx2j9b/V6fRmtaqeduzVpvNVB2qRMN/o2cWl1u691Z1YsxNtZpjdmE5npo/HbMLyy3/+wAAQDMqsdRoN7g0mi16/80H42d/84m61zyzWq15bG5xJd75idpmT+/8xPH4xcPXxr6J0ZoKZ7Mg12qVsNURLovLa/HQp78a//5N3xNDlRRr1RwP/P5/i7d831VxyaZGxI1+AfALv/1k3H/Lwbjj/VvfNt2sudGJZ083/Dd67ky1ySttT7tjbmxHBgCgCEIsNdoNLo2CV6WSY/ZUbZWw0UzYarUaP/6qF8fdj3xr7M69N14bKRo0i7r5YEztGatZZ7thu9n81j/4b3Px8LETNWt/6/BfrHvNRr8A+PiTT8fb3vDSbXfZbdTcaCilhv9GQx3Oha1+Rs3YjgwAQBGEWGq0G1wi6oPXNxaX4x03XVs3E3Z4U5Bby7ERYCPOhp67H3k8Pnj7dfXNoh46Fm97w0vjJ37ljza+v92w3ehM7uT4SMufx8hwJV53zWU1DaweOfa1SB3usjs+OtTw8xwf7Wxn53bH3HRiOzIAAGwmxFKjiPmcSytrLc2EzTk3DD2r1caPv/jSiY2KZCfCdrWa40/nFuOrc6dj9+hQnF5Zixft2x1XTe1p6fMYHUrx919zVfzdD3zuWzNl3/jyGO1wifSS8dHY/7xd8bY3vHRjnfuftysuGe98Z+d2xty0W9UHAIBGhFjqdHo+5+jwUEszYZuFnuFK4+2zYyOVePiO6+PMWjVGhipx2Z6xtsL2s0srcfLPn4t7fuuJmgrnJbtH6j6PRp2RTy+vbQTYiHMzZT/wuXj49uvqzs+2o1JJceW+idi7a6Qn81tb1YmqPgAAbJZyLl+30Onp6TwzM9PrZdCiVhv8NLtuas9oHD95quas7L/+4e+KfXtG403//o861jToqfnT8SPv+UxdWH7kzuujUqnUbDH+8uypunVOjA7FX33Hp+pe9/ff+r3xwn0TdY/vBN2YZwsAwOBJKR3LOU83ek4llsK1ukW52XVziyvxvj/47zXbkSspbQTYiM40DVprsJ15as9YzJ5aiTsf+lZ34ftvORi/9LtfqnvvD95+XeOGSzs4tHW6qg8AAObE0lfWQ8/67NhKJcW+idH4h3/96njbR5+MH3nPZ+JtH30ypvaOdbxp0K6R+hm3b37tVRsBdv097nj/sbjx4BV1712ppHjHTdfWzHUtouESAADsZCqxFK7deaGNKrQ5csebBl06MVZ3hvPFl040DMubz3WuV1y71XAJAAB2KiGWws0trsQ7P1Hbnfidnzgev3j42pa3mjbqJNzppkFbCcuX7R2r64x86cRYXDox1vcNlwAAoMw0dqJwJ7+5FF+ZXaxpzHTvjdfGd05NxP5vG7/4C0TjBkHVao6nTy3H6lo1hs91Jx4e7uwO+WZV5Kum9sT80pmOhlVNkAAA4KwLNXYSYinc/3x2Kf7W/Z+uq2Y+fMf18R2XXDzENguSY8OVuPWX/7Bj3Ykv9P6thsvtBtF2t1wDAMAg0Z2Ynlb5coOuvyfml6LVX6DMLa5shLv1773twZn4P3/4u1raotzuvbfaYbedINrsHtvptgwAAINIiN0Bel3lGx0eaqsJ08rqWsMQfNnesfgnv/GFmtmx1Wq15roL3XtEdDTYtxNEm91jO92WAQBgEBmxswM0C1dziyttvW61mmN2YTmemj8dswvLUa3mho9Pjo/EA7dO14ye2UoTpvUQfL4Dk+Px1bnTNff0j3/jC1HdVNxtdu/PLq3E8ZMLcfjI0Th072Nx+MjROH5yYeMetqOdINrsHtvptgwAAINIJXYAbd4+W0SVr1rN8adzi/HVudMb42RetG93vHByd3x59lRd5fM7L52Ih++4vqYJU6OqZ6Otv/smRus6Eb/75oNxz28+UXdPZzZVYpvd+9LKWse37zarOI8MV2J2YfmCFd/J8ZF4980HN2bSrt/j5PjIttYCAACDSogdMI22z/7qT72y4zNVn11aiZN//lzc81tPbLzPO266NvaMDTcMh7/6U6+MH/t3n73gduYLbf3dPPqmWq3G7KnlmjUdmByPoVQbDpsFy7Um53TbCfaNwvYDt07HqedWL9qAan7pTLzrk1+qOeP7rk9+aUtjiAAAYCfQnXjAzC4sx+EjR2sC2uuuuSze8n0viTvef6wuSK2PqTmzVo2RLYypeWr+dPzIez5TFw5//fbr4q/c+1jd9R+68/q46d2frrn2I3/vUKxV41szWXOOH/q3f1D3mh++61Vx2d5dNa/3jcXlOP5nC/HWDz1eE6Kv/va98fyJ2nmyjSrGe8aGW36vrdhcSR6qRLz+vqN177O54vvU/Ok41OBzO3r3q+Pyyd3bXg8AAJSR7sQ7SKPtsx9/8un4+R/8y/G2N7x0I8iNDVdiba0ax58+VbeF9erL9sSzz61ecPtrs0pmtZobVj6fO7MW999ycKPK+MknT8Y3Flfia99Y2ljTVfsnGr7mc2dqtwhHRFwyPhr7n7er5p72P29XXDJef852ebVaUzF+4NbpeP5EinfcdG1dCB5us9HV5k7GT82fbqni227zKwAA2CmE2AHTLAx96eSp+Ilf+aOaxz54+3UbATbibLh61ye/FG957Uvijofqq7bnB9ldI43fZ9fIUN2W2vtvORira9X4px/+443Hfu22V8aJ+aWacHnkjS+P111zWXz8yadrXnOoQa6sVFJcuW8i9u4auWDYbtbY6YO3Xxdv/9jxmu27b//Y8bjvx14WMdHev8H5Wg2nzbYit9r8CgAAdgohtuQ2b19d7wRcEyJvPhg/26AJ0mq1vpp648ErNgLs+nWNGh49f3y0aSOiU8urNRXSfROjcdO7P13zmqvVvFEFXX/srg98Lj7wU6+MJ7++UFMdHR8dajrrdbuja9ZyxOyp5bjj/cc2Hi+i8tlqOK1UUt25327O8gUAgLIQYkusWSOkq6b21IShoUo0bII0XEl1VcJ9E6MtbX9t1ojof3/9SzeaGK373X/01+pec61BgD4xvxQpom6L8PPGRrY957ZZJXTXSKUrlc+thNNWQjkAAOx0QmyJNdsqu7lqWq3mhoHtsj1jddXUqb1j8bprLosbD16xEU4fOfa1ugrlyupafPzJp2u2/kZE/OzfrNaF06EUdUHymVMrTbcjv/Tyb6sJfM3uc3NjqEbhsFkl9NKJsbh0YqwrlU/hFAAAOkeI7bFm22Rb0er81wtVA//i/r0181sv3T0Sb37tSy46r7RZhXN4qNIwsG5uojQ+Uon33HIwbt/UMfn5u0djfunMRe9zas9YfP3Z5y56dvdilVDhEgAAykWI7aELzUVtJch2oqNtpZJiZKgSOecYGarEs8urdc2e7nzoWHz4rldFinTBs7fr1d3Nj+/bc3aL7vnbhPfuGokXTu6uCZeT4yPx5dlTda+5/3ljdff55tde1dLZ3fV7FFYBAGAwCLEFaaXC2up24GaabZWdHB+J2YXli4bDq6b21D3+0E++Mqb2jNWcdX33p/5rnF5ei5vf+9kLnr1dv8dGlc9qNceukaG6ebTn3+fswnLDz+PDd72q7j5ffGnjcTybq9AAAMBgEWIL0GqFtdXtwM00CoyNAuuv/tQrG4bDh++4vu7x2YXl+Jnvv7pufurswnLLYXtz5bNazQ1DdKufx5nVat195mg8j9ZcVQAAGGyVXi9gEDWrsM4trtRct74d+HwXCmLVao7ZheV4av50zC4sR7WaNwLj5ZO7Y2rvWMwvnal776fPC6DrTswvxZm1+iZMy6trdaNv3vqhx2N5U7DeStjuxOex+T4vnTi7bXn9enNVAQBgZ1CJLUCrFdZWZ4hGtFfdnVts3Am40YidXSNDDde+a6Q2WB+YHI+U2m9AtXnbc6ufh7mqAACwMwmxBdhKw6Wx4UpNw6Ox4cbF8VbPzzZ670eOfS2OvPHlcdcHPlezRXhibKguNE7trW+idGByPJ4/Mbrx+IHJ8bj3xmtjqMW82OzzWKvmOHzkaEvnbBvRsAkAAHaelHPu9Rq2bHp6Os/MzPR6GU21WjV9euG5+KEjf1AX7j5816visr27al7zqfnTcejex+re6+jdr47LJ3df9L33jA3FV55e3AjLL9q3O67cNxERUdOA6pJdw3H86VM1I3buv/lgfOTzJ+LlV+6rmR37i4evbSlENlrT/bccjF/63S/VzJk9MDneclMrAABgcKWUjuWcpxs9pxJbgFa3uj53pvE227VzZ1/P/95m1cyR4UrdtY3eOyJi18jwRWelVqs5do8O1VSHx0eG4kde8aK49Zf/8KLbfFv9PKrVak2AXb933YUBAIALEWIL0spW16FUfyb1dddcFt84tbIxA/X8bbaNzoueem61LlxevX9vw/dupcI5t7iy8Xrr1qvD7Zw/3fx5zC4s6y4MAABsme3EPfSNxeU4/mcLNeNsHvw7r4h/9TtfjBsPXlG3dXffxGjN1t+hSsTr7ztaFwTb2ZLb6rbldrW65RoAANh5bCfuU5eMj8b+5+2qbew0Uokff9WL4+5HHq9polStVuuqmU/Nn25rzmwjW2lK1Q7dhQEAgO0QYnuoUknxwsndsWtkKM6sVWNkqBLDlbQRYCPOhtK7H3k8Hr7j+rrvHx0eitddc1ld1badwLmVsT/t0l0YAADYKiG2h6rVHF+ePVXbtffmgzG1Z6ymEnpifikabfueHB+JN7/2JTWdhN9988GYHB/Z9ppUSAEAgH7WeCgpbaue6zD81PzpmF1Yjmq1PoQ2mv16x0PH4s2vvarmumbbeeeXzmwE2PXvv/OhYzG/dKatta9XSC+f3B1Te8cEWAAAoG+oxBag1aZFK6uNR+xceenExrnUC1VXm32/MTUAAMCgUoktQKMK620PzsTc4krNdetNlM53YHI8Tv75c3HPDdfEB2+/Lu654Zp41ye/1LC62uz7jakBAAAGlUpsAVqtkDZqonT/zQfjZ3/zifjPX3u25tqf/8H66mo3mzABAAD0AyG2AK2OqWnURGmoEjF7arnmumbVVU2YAACAnabQ7cQppV9OKT2dUnqiyfMppfSulNJXUkqPp5ReXuR6umW9Qrq+1fdCFdLNTZQuGW/9ext9vwALAAAMstRodEvHXjylvxoRpyLiwZzzSxs8/wMR8fcj4gci4pUR8Us551de7HWnp6fzzMxMp5fbUdVqjrnFlW1VSNv5XgAAgLJLKR3LOU83eq7Q7cQ5599PKV15gUveEGcDbo6Iz6SULkkpvSDn/PUi19UN6xXSbn8vAADAIOt1d+LLI+Jr53194txjAAAAUKfXIbbRHtmG+5tTSrenlGZSSjOzs7MFLwsAAIB+1OsQeyIirjjv6wMR8T8bXZhzfk/OeTrnPD01NdWVxQEAANBfeh1iPxIRt57rUnxdRHxzEM7DAgAAUIxCGzullH4tIr43Ii5NKZ2IiJ+PiJGIiJzzuyPiP8TZzsRfiYjTEfETRa4HAACAciu6O/HfvsjzOSJ+usg1AAAAMDh6vZ0YAAAAWibEAgAAUBpCLAAAAKUhxAIAAFAaQiwAAAClIcQCAABQGkIsAAD/f3t3HjNHXcdx/P2hRQ5BMFaFcJXENhERAhbQKFKCIYAG1BTDJWKIGI2gqMQzakQSjhiPBESOpkJUVERsjNo/EMQAJUXAhiNIA4qNJhwC4YhAy9c/dqoPT59jgO7sLvt+JU12dn777Hf7yezOd+c3s5I0MmxiJUmSJEkjwyZWkiRJkjQybGIlSZIkSSPDJlaSJEmSNDJsYiVJkiRJI8MmVpIkSZI0MmxiJUmSJEkjI1U16BpetCQPAX8fYAnzgIcH+PyanRkNPzMafmY0/Mxo+JnR8DOj4WY+w69fGe1WVa+fasVINrGDluSWqlo06Do0PTMafmY0/Mxo+JnR8DOj4WdGw818ht8gMnI6sSRJkiRpZNjESpIkSZJGhk3sS3PRoAvQrMxo+JnR8DOj4WdGw8+Mhp8ZDTfzGX6dZ+Q5sZIkSZKkkeGRWEmSJEnSyLCJlSRJkiSNDJvYGSQ5LMk9SdYk+eIU67dI8rNm/c1J5ndf5XhrkdFnk9yVZHWSa5LsNog6x9lsGU0YtyRJJfEy+h1rk1GSDzXb0p1JftJ1jeOuxXvdrkmuTXJb8353xCDqHFdJliZ5MMkd06xPku83+a1Osm/XNY67Fhkd32SzOsmNSfbuusZxN1tGE8btl2R9kiVd1aZ2+SRZnOT2Zl/hj/2sxyZ2GknmAOcDhwN7AMcm2WPSsJOBR6vqTcB3gHO6rXK8tczoNmBRVe0FXAmc222V461lRiTZFjgNuLnbCtUmoyQLgC8B76yqtwCf6bzQMdZyO/oq8POq2gc4Brig2yrH3jLgsBnWHw4saP6dAvygg5r0QsuYOaP7gYOa/YUz8WJCg7CMmTPa8H54DrCii4L0AsuYIZ8k29P77Dmy2Vc4up/F2MROb39gTVXdV1XPAlcAR00acxTwo+b2lcAhSdJhjeNu1oyq6tqqFnW7dAAABXhJREFUerpZXAns3HGN467NdgS9HYZzgf90WZyAdhl9DDi/qh4FqKoHO65x3LXJqIDXNLe3A/7ZYX1jr6quB/49w5CjgMuqZyWwfZIdu6lOMHtGVXXjhvc43F8YiBbbEcCpwC8BP4c61iKf44CrquqBZnxfM7KJnd5OwD8mLK9t7ptyTFWtAx4HXtdJdYJ2GU10MvC7vlakyWbNKMk+wC5V9ZsuC9P/tNmOFgILk9yQZGWSGb8p1ybXJqNvACckWQv8lt6OnobHi/280mC5vzCEkuwEfAC4cNC1aEoLgdcmuS7Jn5Oc2M8nm9vPPz7ipjqiOvn3iNqMUf+0/v9PcgKwCDiorxVpshkzSrIZvan4J3VVkDbSZjuaS28a5GJ6Ryf+lGTPqnqsz7Wpp01GxwLLqurbSd4BXN5k9Hz/y1ML7i+MiCQH02ti3zXoWrSR7wJfqKr1TnwcSnOBtwGHAFsBNyVZWVV/7deTaWprgV0mLO/MxtOzNoxZm2QuvSlcs02D0KbTJiOSvAf4Cr1zXZ7pqDb1zJbRtsCewHXNB9IOwPIkR1bVLZ1VOd7avtetrKrngPuT3EOvqV3VTYljr01GJ9Ocq1RVNyXZEpiHU+6GRavPKw1Wkr2AS4DDq+qRQdejjSwCrmj2F+YBRyRZV1VXD7YsNdYCD1fVU8BTSa4H9gb60sQ6nXh6q4AFSXZP8ip6F8pYPmnMcuAjze0lwB+qym9WuzNrRs1U1R/SO8ncnbnuzZhRVT1eVfOqan5Vzad3HpINbLfavNddDRwMkGQevSlD93Va5Xhrk9ED9L79JsmbgS2BhzqtUjNZDpzYXKX47cDjVfWvQRel/0uyK3AV8OF+HTnSy1NVu0/YX7gS+KQN7FD5NXBgkrlJtgYOAO7u15N5JHYaVbUuyafoXf1sDrC0qu5M8k3glqpaDlxKb8rWGnpHYI8ZXMXjp2VG5wHbAL9ovrl7oKqOHFjRY6ZlRhqglhmtAA5NchewHjjDoxTdaZnR54CLk5xOb5rqSX6p2p0kP6U33X5ec17y14HNAarqQnrnKR8BrAGeBj46mErHV4uMvkbvuiYXNPsL66rKn3zrUIuMNECz5VNVdyf5PbAaeB64pKpm/Lmkl1WPn3GSJEmSpFHhdGJJkiRJ0siwiZUkSZIkjQybWEmSJEnSyLCJlSRJkiSNDJtYSZKGTJL5SY57GY//8qasR5KkYWITK0nS8JkPvOQmFrCJlSS9YtnESpLUkSRnJvn0hOWzkpw2xdCz6f1o/O1JTk8yJ8l5SVYlWZ3k483jd0xyfTPujiQHJjkb2Kq578cdvTRJkjrj78RKktSRJPOBq6pq3ySbAfcC+1fVI5PGLQY+X1Xva5ZPAd5QVd9KsgVwA3A08EFgy6o6K8kcYOuqeiLJk1W1TWcvTJKkDs0ddAGSJI2LqvpbkkeS7AO8EbhtcgM7jUOBvZIsaZa3AxYAq4ClSTYHrq6q2/tSuCRJQ8QmVpKkbl0CnATsACxt+ZgAp1bVio1WJO8G3gtcnuS8qrpsUxUqSdIw8pxYSZK69SvgMGA/YKOmtPEEsO2E5RXAJ5ojriRZmOTVSXYDHqyqi4FLgX2b8c9tGCtJ0iuNR2IlSepQVT2b5FrgsapaP82w1cC6JH8BlgHfo3fF4luTBHgIeD+wGDgjyXPAk8CJzeMvAlYnubWqju/Xa5EkaRC8sJMkSR1qLuh0K3B0Vd076HokSRo1TieWJKkjSfYA1gDX2MBKkvTSeCRWkqQBSfJW4PJJdz9TVQcMoh5JkkaBTawkSZIkaWQ4nViSJEmSNDJsYiVJkiRJI8MmVpIkSZI0MmxiJUmSJEkjwyZWkiRJkjQybGIlSZIkSSPjvyp9F62gW2PXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "OLSregression(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN SI model\n",
    "<h5 style=\"color:purple;\">for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation functions and their gradient functions\n",
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def sigmoid_grad(X):\n",
    "    return sigmoid(X) * (1 - sigmoid(X))\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def tanh_grad(z):\n",
    "     return 1 - np.tanh(z) ** 2\n",
    "\n",
    "def ReLU(z):\n",
    "    return np.clip(z, 0, np.inf)\n",
    "\n",
    "def ReLU_grad(z):\n",
    "    return (z > 0).astype(int)\n",
    "\n",
    "def affine(X,slope=1,intercept=0):\n",
    "     return slope * X + intercept\n",
    "    \n",
    "def affine_grad(X,slope=1,intercept=0):\n",
    "    return slope * np.ones_like(X)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_dim, output_dim=1,hidden_dim = 4,lr=0.005,\n",
    "                 act1 = sigmoid,\n",
    "                 act2 = affine,\n",
    "                 grad1 = sigmoid_grad,\n",
    "                 grad2 = affine_grad):\n",
    "        #init weights\n",
    "        self.weights1   = np.random.rand(input_dim+1,hidden_dim) \n",
    "        self.weights2   = np.random.rand(hidden_dim,output_dim)                 \n",
    "        #set learning rate\n",
    "        self.lr         = lr\n",
    "        self.activation1 = act1\n",
    "        self.activation2 = act2\n",
    "        self.grad1 = grad1\n",
    "        self.grad2 = grad2\n",
    "      \n",
    "    def print_w(self):\n",
    "        '''print weight to inspect the current values of network'''  \n",
    "        print('print_weights ------------>')\n",
    "        print(self.weights1)\n",
    "        print(self.weights2)\n",
    "        \n",
    "    def feedforward(self,X):\n",
    "        X = np.hstack((X,np.ones((X.shape[0],1))))\n",
    "        self.layer1 = self.activation1(np.dot(X, self.weights1))\n",
    "        self.output = self.activation2(np.dot(self.layer1, self.weights2))\n",
    "        return self.output\n",
    "    def backprop(self,X, Y):\n",
    "        X = np.hstack((X,np.ones((X.shape[0],1))))\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(Y - self.output) * affine_grad(np.dot(self.layer1, self.weights2))))\n",
    "        d_weights1 = np.dot(X.T,  \\\n",
    "                            (np.dot(2*(Y - self.output) * self.grad2(np.dot(self.layer1, self.weights2)), self.weights2.T)\\\n",
    "                             * self.grad1(np.dot(X, self.weights1))))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function multiply learning rate\n",
    "        self.weights1 += d_weights1*self.lr\n",
    "        self.weights2 += d_weights2*self.lr\n",
    "    \n",
    "    def test(self,X):\n",
    "        '''get predicted values for any input data'''\n",
    "        X = np.hstack((X,np.ones((X.shape[0],1))))\n",
    "        hidden_layer1 = self.activation1(np.dot(X, self.weights1))\n",
    "        return self.activation2(np.dot(hidden_layer1, self.weights2))\n",
    "        \n",
    "    def train(self,X,Y,epoch):\n",
    "        '''train model with X and Y for num_train_iterations times'''\n",
    "        #print('training  ---------------->')\n",
    "        for iteration in range(epoch): \n",
    "            self.feedforward(X) \n",
    "            self.backprop(X,Y)\n",
    "            #print interim MSE\n",
    "#             if iteration == epoch -1 :\n",
    "#                 mse = np.mean((self.output - Y)**2)\n",
    "#                 print(\"Epoch \", iteration, \"MSE: \", mse)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNregression(X_train, X_test, y_train, y_test,\n",
    "                 hidden_layer = 4,\n",
    "                 batch_size = 4,\n",
    "                 epoch = 500,\n",
    "                 lr=0.008\n",
    "                ):\n",
    "\n",
    "    #initialize network with fixed output dim of 1\n",
    "    neural_network = NeuralNetwork(X_train.shape[1],1,hidden_dim = hidden_layer,lr=lr)\n",
    "\n",
    "    for index in range(0,X_train.shape[0],batch_size):\n",
    "\n",
    "        #get batch X and Y\n",
    "        batch_X=X_train[index:min(index+batch_size,X_train.shape[0]),:]\n",
    "        batch_Y=y_train[index:min(index+batch_size,y_train.shape[0])].reshape(-1,1)\n",
    "        #train model with batch\n",
    "        neural_network.train(batch_X,batch_Y,epoch)\n",
    "    y_pred_train = neural_network.feedforward(X_train)[:,0]\n",
    "    pear_train = scipy.stats.pearsonr(y_train, y_pred_train)\n",
    "\n",
    "    print('Training Pearson\\'s r is {:6f}'.format(pear_train[0]))\n",
    "\n",
    "    mse_train = np.mean((y_train - y_pred_train)**2)\n",
    "    print('Training MSE is {:6f}'.format(mse_train))\n",
    "    \n",
    "    y_pred = neural_network.feedforward(X_test)[:,0]\n",
    "    pear = scipy.stats.pearsonr(y_test, y_pred)\n",
    "\n",
    "    print('Pearson\\'s r is {:6f}'.format(pear[0]))\n",
    "\n",
    "    mse = np.mean((y_test - y_pred)**2)\n",
    "    print('MSE is {:6f}'.format(mse))\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({'X_Axis': X_test[:, 0], 'y_test': y_test, 'y_pred':y_pred})\n",
    "\n",
    "    df_m = df.melt('X_Axis', var_name='cols',  value_name='vals')\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    sns.scatterplot(x=\"y_test\", y=\"y_pred\", data=df)\n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pearson's r is 0.906645\n",
      "Training MSE is 0.015702\n",
      "Pearson's r is 0.902520\n",
      "MSE is 0.013917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNetwork at 0x108982af1c8>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NNregression(X_train, X_test, y_train, y_test,hidden_layer = 4, batch_size = 4,epoch=500,lr=0.008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN SI model\n",
    "\n",
    "use vanilla RNN architechture\n",
    "<h5 style=\"color:purple;\">for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.parameters = list()\n",
    "        \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "\n",
    "    \n",
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super().__init__()\n",
    "        W = np.random.randn(n_inputs, n_outputs) * np.sqrt(2.0/(n_inputs))\n",
    "        self.weight = Tensor(W, autograd=True)\n",
    "        self.bias = Tensor(np.zeros(n_outputs), autograd=True)\n",
    "        \n",
    "        self.parameters.append(self.weight)\n",
    "        self.parameters.append(self.bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.mm(self.weight)+self.bias.expand(0,len(input.data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor (object):\n",
    "    \n",
    "    def __init__(self,data,\n",
    "                 autograd=False,\n",
    "                 creators=None,\n",
    "                 creation_op=None,\n",
    "                 id=None):\n",
    "        \n",
    "        self.data = np.asarray(data)\n",
    "        self.autograd = autograd\n",
    "        self.grad = None\n",
    "        if(id is None):\n",
    "            self.id = np.random.randint(0,100000)\n",
    "        else:\n",
    "            self.id = id\n",
    "        \n",
    "        self.creators = creators\n",
    "        self.creation_op = creation_op\n",
    "        self.children = {}\n",
    "        \n",
    "        if(creators is not None):\n",
    "            for c in creators:\n",
    "                if(self.id not in c.children):\n",
    "                    c.children[self.id] = 1\n",
    "                else:\n",
    "                    c.children[self.id] += 1\n",
    "\n",
    "    def all_children_grads_accounted_for(self):\n",
    "        for id,cnt in self.children.items():\n",
    "            if(cnt != 0):\n",
    "                return False\n",
    "        return True \n",
    "        \n",
    "    def backward(self,grad=None, grad_origin=None):\n",
    "        if(self.autograd):\n",
    " \n",
    "            if(grad is None):\n",
    "                grad = Tensor(np.ones_like(self.data))\n",
    "\n",
    "            if(grad_origin is not None):\n",
    "                if(self.children[grad_origin.id] == 0):\n",
    "                    raise Exception(\"cannot backprop more than once\")\n",
    "                else:\n",
    "                    self.children[grad_origin.id] -= 1\n",
    "\n",
    "            if(self.grad is None):\n",
    "                self.grad = grad\n",
    "            else:\n",
    "                self.grad += grad\n",
    "            \n",
    "            # grads must not have grads of their own\n",
    "            assert grad.autograd == False\n",
    "            \n",
    "            # only continue backpropping if there's something to\n",
    "            # backprop into and if all gradients (from children)\n",
    "            # are accounted for override waiting for children if\n",
    "            # \"backprop\" was called on this variable directly\n",
    "            if(self.creators is not None and \n",
    "               (self.all_children_grads_accounted_for() or \n",
    "                grad_origin is None)):\n",
    "\n",
    "                if(self.creation_op == \"add\"):\n",
    "                    self.creators[0].backward(self.grad, self)\n",
    "                    self.creators[1].backward(self.grad, self)\n",
    "                    \n",
    "                if(self.creation_op == \"sub\"):\n",
    "                    self.creators[0].backward(Tensor(self.grad.data), self)\n",
    "                    self.creators[1].backward(Tensor(self.grad.__neg__().data), self)\n",
    "\n",
    "                if(self.creation_op == \"mul\"):\n",
    "                    new = self.grad * self.creators[1]\n",
    "                    self.creators[0].backward(new , self)\n",
    "                    new = self.grad * self.creators[0]\n",
    "                    self.creators[1].backward(new, self)                    \n",
    "                    \n",
    "                if(self.creation_op == \"mm\"):\n",
    "                    c0 = self.creators[0]\n",
    "                    c1 = self.creators[1]\n",
    "                    new = self.grad.mm(c1.transpose())\n",
    "                    c0.backward(new)\n",
    "                    new = self.grad.transpose().mm(c0).transpose()\n",
    "                    c1.backward(new)\n",
    "                    \n",
    "                if(self.creation_op == \"transpose\"):\n",
    "                    self.creators[0].backward(self.grad.transpose())\n",
    "\n",
    "                if(\"sum\" in self.creation_op):\n",
    "                    dim = int(self.creation_op.split(\"_\")[1])\n",
    "                    self.creators[0].backward(self.grad.expand(dim,\n",
    "                                                               self.creators[0].data.shape[dim]))\n",
    "\n",
    "                if(\"expand\" in self.creation_op):\n",
    "                    dim = int(self.creation_op.split(\"_\")[1])\n",
    "                    self.creators[0].backward(self.grad.sum(dim))\n",
    "                    \n",
    "                if(self.creation_op == \"neg\"):\n",
    "                    self.creators[0].backward(self.grad.__neg__())\n",
    "                    \n",
    "                if(self.creation_op == \"sigmoid\"):\n",
    "                    ones = Tensor(np.ones_like(self.grad.data))\n",
    "                    self.creators[0].backward(self.grad * (self * (ones - self)))\n",
    "                \n",
    "                if(self.creation_op == \"tanh\"):\n",
    "                    ones = Tensor(np.ones_like(self.grad.data))\n",
    "                    self.creators[0].backward(self.grad * (ones - (self * self)))\n",
    "                \n",
    "                if(self.creation_op == \"index_select\"):\n",
    "                    new_grad = np.zeros_like(self.creators[0].data)\n",
    "                    indices_ = self.index_select_indices.data.flatten()\n",
    "                    grad_ = grad.data.reshape(len(indices_), -1)\n",
    "                    for i in range(len(indices_)):\n",
    "                        new_grad[indices_[i]] += grad_[i]\n",
    "                    self.creators[0].backward(Tensor(new_grad))\n",
    "                    \n",
    "                if(self.creation_op == \"cross_entropy\"):\n",
    "                    dx = self.softmax_output - self.target_dist\n",
    "                    self.creators[0].backward(Tensor(dx))\n",
    "                    \n",
    "    def __add__(self, other):\n",
    "        if(self.autograd and other.autograd):\n",
    "            return Tensor(self.data + other.data,\n",
    "                          autograd=True,\n",
    "                          creators=[self,other],\n",
    "                          creation_op=\"add\")\n",
    "        return Tensor(self.data + other.data)\n",
    "\n",
    "    def __neg__(self):\n",
    "        if(self.autograd):\n",
    "            return Tensor(self.data * -1,\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"neg\")\n",
    "        return Tensor(self.data * -1)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if(self.autograd and other.autograd):\n",
    "            return Tensor(self.data - other.data,\n",
    "                          autograd=True,\n",
    "                          creators=[self,other],\n",
    "                          creation_op=\"sub\")\n",
    "        return Tensor(self.data - other.data)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if(self.autograd and other.autograd):\n",
    "            return Tensor(self.data * other.data,\n",
    "                          autograd=True,\n",
    "                          creators=[self,other],\n",
    "                          creation_op=\"mul\")\n",
    "        return Tensor(self.data * other.data)    \n",
    "\n",
    "    def sum(self, dim):\n",
    "        if(self.autograd):\n",
    "            return Tensor(self.data.sum(dim),\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"sum_\"+str(dim))\n",
    "        return Tensor(self.data.sum(dim))\n",
    "    \n",
    "    def expand(self, dim,copies):\n",
    "\n",
    "        trans_cmd = list(range(0,len(self.data.shape)))\n",
    "        trans_cmd.insert(dim,len(self.data.shape))\n",
    "        new_data = self.data.repeat(copies).reshape(list(self.data.shape) + [copies]).transpose(trans_cmd)\n",
    "        \n",
    "        if(self.autograd):\n",
    "            return Tensor(new_data,\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"expand_\"+str(dim))\n",
    "        return Tensor(new_data)\n",
    "    \n",
    "    def transpose(self):\n",
    "        if(self.autograd):\n",
    "            return Tensor(self.data.transpose(),\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"transpose\")\n",
    "        \n",
    "        return Tensor(self.data.transpose())\n",
    "    \n",
    "    def mm(self, x):\n",
    "        if(self.autograd):\n",
    "            return Tensor(self.data.dot(x.data),\n",
    "                          autograd=True,\n",
    "                          creators=[self,x],\n",
    "                          creation_op=\"mm\")\n",
    "        return Tensor(self.data.dot(x.data))\n",
    "    \n",
    "    def sigmoid(self):\n",
    "        if(self.autograd):\n",
    "            return Tensor(1 / (1 + np.exp(-self.data)),\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"sigmoid\")\n",
    "        return Tensor(1 / (1 + np.exp(-self.data)))\n",
    "\n",
    "    def tanh(self):\n",
    "        if(self.autograd):\n",
    "            return Tensor(np.tanh(self.data),\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"tanh\")\n",
    "        return Tensor(np.tanh(self.data))\n",
    "    \n",
    "    def index_select(self, indices):\n",
    "\n",
    "        if(self.autograd):\n",
    "            new = Tensor(self.data[indices.data],\n",
    "                         autograd=True,\n",
    "                         creators=[self],\n",
    "                         creation_op=\"index_select\")\n",
    "            new.index_select_indices = indices\n",
    "            return new\n",
    "        return Tensor(self.data[indices.data])\n",
    "    \n",
    "    def cross_entropy(self, target_indices):\n",
    "\n",
    "        temp = np.exp(self.data)\n",
    "        softmax_output = temp / np.sum(temp,\n",
    "                                       axis=len(self.data.shape)-1,\n",
    "                                       keepdims=True)\n",
    "        \n",
    "        t = target_indices.data.flatten()\n",
    "        p = softmax_output.reshape(len(t),-1)\n",
    "        target_dist = np.eye(p.shape[1])[t]\n",
    "        loss = -(np.log(p) * (target_dist)).sum(1).mean()\n",
    "    \n",
    "        if(self.autograd):\n",
    "            out = Tensor(loss,\n",
    "                         autograd=True,\n",
    "                         creators=[self],\n",
    "                         creation_op=\"cross_entropy\")\n",
    "            out.softmax_output = softmax_output\n",
    "            out.target_dist = target_dist\n",
    "            return out\n",
    "\n",
    "        return Tensor(loss)\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.data.__repr__())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.data.__str__())  \n",
    "    \n",
    "class Tanh(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input.tanh()\n",
    "    \n",
    "class Sigmoid(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss(Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        return ((pred - target)*(pred - target)).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        return input.cross_entropy(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(object):\n",
    "    \n",
    "    def __init__(self, parameters, alpha=0.1):\n",
    "        self.parameters = parameters\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def zero(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad.data *= 0\n",
    "        \n",
    "    def step(self, zero=True):\n",
    "        \n",
    "        for p in self.parameters:\n",
    "            \n",
    "            p.data -= p.grad.data * self.alpha\n",
    "            \n",
    "            if(zero):\n",
    "                p.grad.data *= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(Layer):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_hidden, n_output, activation='sigmoid'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        if(activation == 'sigmoid'):\n",
    "            self.activation = Sigmoid()\n",
    "        elif(activation == 'tanh'):\n",
    "            self.activation == Tanh()\n",
    "        else:\n",
    "            raise Exception(\"Non-linearity not found\")\n",
    "\n",
    "        self.w_ih = Linear(n_inputs, n_hidden)\n",
    "        self.w_hh = Linear(n_hidden, n_hidden)\n",
    "        self.w_ho = Linear(n_hidden, n_output)\n",
    "        \n",
    "        self.parameters += self.w_ih.get_parameters()\n",
    "        self.parameters += self.w_hh.get_parameters()\n",
    "        self.parameters += self.w_ho.get_parameters()        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        from_prev_hidden = self.w_hh.forward(hidden)\n",
    "        combined = self.w_ih.forward(input) + from_prev_hidden\n",
    "        new_hidden = self.activation.forward(combined)\n",
    "        output = self.w_ho.forward(new_hidden)\n",
    "        return output, new_hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return Tensor(np.zeros((batch_size,self.n_hidden)), autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RNNCell(n_inputs=1, n_hidden=16, n_output=1)\n",
    "\n",
    "criterion = MSELoss()\n",
    "optim = SGD(parameters=model.get_parameters(), alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: [0.01863214] % Pearson's R: 0.9204139894511625\n",
      "Loss: [0.0022798] % Pearson's R: 0.9171613621324479\n",
      "Loss: [0.00422458] % Pearson's R: 0.9198153283500061\n",
      "Loss: [0.00310029] % Pearson's R: 0.9282137948895315\n",
      "Loss: [0.00077754] % Pearson's R: 0.9716991225532667\n",
      "Loss: [0.00232195] % Pearson's R: 0.8530206334009877\n",
      "Loss: [0.00784294] % Pearson's R: 0.9422775001150369\n",
      "Loss: [0.00392673] % Pearson's R: 0.8559037362127762\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "for index in range(0,800,batch_size):\n",
    "\n",
    "    total_loss = 0\n",
    "    \n",
    "    hidden = model.init_hidden(batch_size=batch_size)\n",
    "    for t in range(23):\n",
    "        #print('t={}'.format(t))\n",
    "        rnn_input= Tensor(X_train[index:min(index+batch_size,X_train.shape[0]),t].reshape(-1,1), autograd=True)        \n",
    "        output, hidden = model.forward(input=rnn_input, hidden=hidden)\n",
    "        #print(output)\n",
    "    target = Tensor(y_train[index:min(index+batch_size,X_train.shape[0])].reshape(-1,1), autograd=True)    \n",
    "    loss = criterion.forward(output, target)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    total_loss += loss.data\n",
    "    \n",
    "    if(index % 100 == 0):\n",
    "\n",
    "#         p_correct = (target.data == np.argmax(output.data,axis=1)).mean()\n",
    "        pear = scipy.stats.pearsonr(target.data.ravel(),output.data.ravel())\n",
    "        print(\"Loss:\",total_loss / (len(X_train)/batch_size),\"% Pearson's R:\",pear[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.11789607]\n",
      "Pearson's R: 0.8788666095342177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x108941cd1c8>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "hidden = model.init_hidden(batch_size=200)\n",
    "for t in range(23):\n",
    "    #print('t={}'.format(t))\n",
    "    rnn_input= Tensor(X_test[:,t].reshape(-1,1), autograd=True)        \n",
    "    output, hidden = model.forward(input=rnn_input, hidden=hidden)\n",
    "target = Tensor(y_test.reshape(-1,1), autograd=True)    \n",
    "loss = criterion.forward(output, target)    \n",
    "print(loss)\n",
    "pear = scipy.stats.pearsonr(target.data.ravel(),output.data.ravel())\n",
    "print(\"Pearson's R:\",pear[0])\n",
    "df = pd.DataFrame({'X_Axis': X_test[:, 0], 'y_test': target.data.ravel(), 'y_pred':output.data.ravel()})\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.scatterplot(x=\"y_test\", y=\"y_pred\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM SI model\n",
    "use LSTM architechture\n",
    "<h5 style=\"color:purple;\">for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Tensor (object):\n",
    "    \n",
    "    def __init__(self,data,\n",
    "                 autograd=False,\n",
    "                 creators=None,\n",
    "                 creation_op=None,\n",
    "                 id=None):\n",
    "        \n",
    "        self.data = np.array(data)\n",
    "        self.autograd = autograd\n",
    "        self.grad = None\n",
    "\n",
    "        if(id is None):\n",
    "            self.id = np.random.randint(0,1000000000)\n",
    "        else:\n",
    "            self.id = id\n",
    "        \n",
    "        self.creators = creators\n",
    "        self.creation_op = creation_op\n",
    "        self.children = {}\n",
    "        \n",
    "        if(creators is not None):\n",
    "            for c in creators:\n",
    "                if(self.id not in c.children):\n",
    "                    c.children[self.id] = 1\n",
    "                else:\n",
    "                    c.children[self.id] += 1\n",
    "\n",
    "    def all_children_grads_accounted_for(self):\n",
    "        for id,cnt in self.children.items():\n",
    "            if(cnt != 0):\n",
    "                return False\n",
    "        return True \n",
    "        \n",
    "    def backward(self,grad=None, grad_origin=None):\n",
    "        if(self.autograd):\n",
    " \n",
    "            if(grad is None):\n",
    "                grad = Tensor(np.ones_like(self.data))\n",
    "\n",
    "            if(grad_origin is not None):\n",
    "                if(self.children[grad_origin.id] == 0):\n",
    "                    return\n",
    "                    print(self.id)\n",
    "                    print(self.creation_op)\n",
    "                    print(len(self.creators))\n",
    "                    for c in self.creators:\n",
    "                        print(c.creation_op)\n",
    "                    raise Exception(\"cannot backprop more than once\")\n",
    "                else:\n",
    "                    self.children[grad_origin.id] -= 1\n",
    "\n",
    "            if(self.grad is None):\n",
    "                self.grad = grad\n",
    "            else:\n",
    "                self.grad += grad\n",
    "            \n",
    "            # grads must not have grads of their own\n",
    "            assert grad.autograd == False\n",
    "            \n",
    "            # only continue backpropping if there's something to\n",
    "            # backprop into and if all gradients (from children)\n",
    "            # are accounted for override waiting for children if\n",
    "            # \"backprop\" was called on this variable directly\n",
    "            if(self.creators is not None and \n",
    "               (self.all_children_grads_accounted_for() or \n",
    "                grad_origin is None)):\n",
    "\n",
    "                if(self.creation_op == \"add\"):\n",
    "                    self.creators[0].backward(self.grad, self)\n",
    "                    self.creators[1].backward(self.grad, self)\n",
    "                    \n",
    "                if(self.creation_op == \"sub\"):\n",
    "                    self.creators[0].backward(Tensor(self.grad.data), self)\n",
    "                    self.creators[1].backward(Tensor(self.grad.__neg__().data), self)\n",
    "\n",
    "                if(self.creation_op == \"mul\"):\n",
    "                    new = self.grad * self.creators[1]\n",
    "                    self.creators[0].backward(new , self)\n",
    "                    new = self.grad * self.creators[0]\n",
    "                    self.creators[1].backward(new, self)                    \n",
    "                    \n",
    "                if(self.creation_op == \"mm\"):\n",
    "                    c0 = self.creators[0]\n",
    "                    c1 = self.creators[1]\n",
    "                    new = self.grad.mm(c1.transpose())\n",
    "                    c0.backward(new)\n",
    "                    new = self.grad.transpose().mm(c0).transpose()\n",
    "                    c1.backward(new)\n",
    "                    \n",
    "                if(self.creation_op == \"transpose\"):\n",
    "                    self.creators[0].backward(self.grad.transpose())\n",
    "\n",
    "                if(\"sum\" in self.creation_op):\n",
    "                    dim = int(self.creation_op.split(\"_\")[1])\n",
    "                    self.creators[0].backward(self.grad.expand(dim,\n",
    "                                                               self.creators[0].data.shape[dim]))\n",
    "\n",
    "                if(\"expand\" in self.creation_op):\n",
    "                    dim = int(self.creation_op.split(\"_\")[1])\n",
    "                    self.creators[0].backward(self.grad.sum(dim))\n",
    "                    \n",
    "                if(self.creation_op == \"neg\"):\n",
    "                    self.creators[0].backward(self.grad.__neg__())\n",
    "                    \n",
    "                if(self.creation_op == \"sigmoid\"):\n",
    "                    ones = Tensor(np.ones_like(self.grad.data))\n",
    "                    self.creators[0].backward(self.grad * (self * (ones - self)))\n",
    "                \n",
    "                if(self.creation_op == \"tanh\"):\n",
    "                    ones = Tensor(np.ones_like(self.grad.data))\n",
    "                    self.creators[0].backward(self.grad * (ones - (self * self)))\n",
    "                \n",
    "                if(self.creation_op == \"index_select\"):\n",
    "                    new_grad = np.zeros_like(self.creators[0].data)\n",
    "                    indices_ = self.index_select_indices.data.flatten()\n",
    "                    grad_ = grad.data.reshape(len(indices_), -1)\n",
    "                    for i in range(len(indices_)):\n",
    "                        new_grad[indices_[i]] += grad_[i]\n",
    "                    self.creators[0].backward(Tensor(new_grad))\n",
    "                    \n",
    "                if(self.creation_op == \"cross_entropy\"):\n",
    "                    dx = self.softmax_output - self.target_dist\n",
    "                    self.creators[0].backward(Tensor(dx))\n",
    "                    \n",
    "    def __add__(self, other):\n",
    "        if(self.autograd and other.autograd):\n",
    "            return Tensor(self.data + other.data,\n",
    "                          autograd=True,\n",
    "                          creators=[self,other],\n",
    "                          creation_op=\"add\")\n",
    "        return Tensor(self.data + other.data)\n",
    "\n",
    "    def __neg__(self):\n",
    "        if(self.autograd):\n",
    "            return Tensor(self.data * -1,\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"neg\")\n",
    "        return Tensor(self.data * -1)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if(self.autograd and other.autograd):\n",
    "            return Tensor(self.data - other.data,\n",
    "                          autograd=True,\n",
    "                          creators=[self,other],\n",
    "                          creation_op=\"sub\")\n",
    "        return Tensor(self.data - other.data)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if(self.autograd and other.autograd):\n",
    "            return Tensor(self.data * other.data,\n",
    "                          autograd=True,\n",
    "                          creators=[self,other],\n",
    "                          creation_op=\"mul\")\n",
    "        return Tensor(self.data * other.data)    \n",
    "\n",
    "    def sum(self, dim):\n",
    "        if(self.autograd):\n",
    "            return Tensor(self.data.sum(dim),\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"sum_\"+str(dim))\n",
    "        return Tensor(self.data.sum(dim))\n",
    "    \n",
    "    def expand(self, dim,copies):\n",
    "\n",
    "        trans_cmd = list(range(0,len(self.data.shape)))\n",
    "        trans_cmd.insert(dim,len(self.data.shape))\n",
    "        new_data = self.data.repeat(copies).reshape(list(self.data.shape) + [copies]).transpose(trans_cmd)\n",
    "        \n",
    "        if(self.autograd):\n",
    "            return Tensor(new_data,\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"expand_\"+str(dim))\n",
    "        return Tensor(new_data)\n",
    "    \n",
    "    def transpose(self):\n",
    "        if(self.autograd):\n",
    "            return Tensor(self.data.transpose(),\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"transpose\")\n",
    "        \n",
    "        return Tensor(self.data.transpose())\n",
    "    \n",
    "    def mm(self, x):\n",
    "        if(self.autograd):\n",
    "            return Tensor(self.data.dot(x.data),\n",
    "                          autograd=True,\n",
    "                          creators=[self,x],\n",
    "                          creation_op=\"mm\")\n",
    "        return Tensor(self.data.dot(x.data))\n",
    "    \n",
    "    def sigmoid(self):\n",
    "        if(self.autograd):\n",
    "            return Tensor(1 / (1 + np.exp(-self.data)),\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"sigmoid\")\n",
    "        return Tensor(1 / (1 + np.exp(-self.data)))\n",
    "\n",
    "    def tanh(self):\n",
    "        if(self.autograd):\n",
    "            return Tensor(np.tanh(self.data),\n",
    "                          autograd=True,\n",
    "                          creators=[self],\n",
    "                          creation_op=\"tanh\")\n",
    "        return Tensor(np.tanh(self.data))\n",
    "    \n",
    "    def index_select(self, indices):\n",
    "\n",
    "        if(self.autograd):\n",
    "            new = Tensor(self.data[indices.data],\n",
    "                         autograd=True,\n",
    "                         creators=[self],\n",
    "                         creation_op=\"index_select\")\n",
    "            new.index_select_indices = indices\n",
    "            return new\n",
    "        return Tensor(self.data[indices.data])\n",
    "    \n",
    "    def softmax(self):\n",
    "        temp = np.exp(self.data)\n",
    "        softmax_output = temp / np.sum(temp,\n",
    "                                       axis=len(self.data.shape)-1,\n",
    "                                       keepdims=True)\n",
    "        return softmax_output\n",
    "    \n",
    "    def cross_entropy(self, target_indices):\n",
    "\n",
    "        temp = np.exp(self.data)\n",
    "        softmax_output = temp / np.sum(temp,\n",
    "                                       axis=len(self.data.shape)-1,\n",
    "                                       keepdims=True)\n",
    "        \n",
    "        t = target_indices.data.flatten()\n",
    "        p = softmax_output.reshape(len(t),-1)\n",
    "        target_dist = np.eye(p.shape[1])[t]\n",
    "        loss = -(np.log(p) * (target_dist)).sum(1).mean()\n",
    "    \n",
    "        if(self.autograd):\n",
    "            out = Tensor(loss,\n",
    "                         autograd=True,\n",
    "                         creators=[self],\n",
    "                         creation_op=\"cross_entropy\")\n",
    "            out.softmax_output = softmax_output\n",
    "            out.target_dist = target_dist\n",
    "            return out\n",
    "\n",
    "        return Tensor(loss)\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.data.__repr__())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.data.__str__())  \n",
    "\n",
    "class Layer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.parameters = list()\n",
    "        \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "\n",
    "    \n",
    "class SGD(object):\n",
    "    \n",
    "    def __init__(self, parameters, alpha=0.1):\n",
    "        self.parameters = parameters\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def zero(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad.data *= 0\n",
    "        \n",
    "    def step(self, zero=True):\n",
    "        \n",
    "        for p in self.parameters:\n",
    "            \n",
    "            p.data -= p.grad.data * self.alpha\n",
    "            \n",
    "            if(zero):\n",
    "                p.grad.data *= 0\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, bias=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_bias = bias\n",
    "        \n",
    "        W = np.random.randn(n_inputs, n_outputs) * np.sqrt(2.0/(n_inputs))\n",
    "        self.weight = Tensor(W, autograd=True)\n",
    "        if(self.use_bias):\n",
    "            self.bias = Tensor(np.zeros(n_outputs), autograd=True)\n",
    "        \n",
    "        self.parameters.append(self.weight)\n",
    "        \n",
    "        if(self.use_bias):        \n",
    "            self.parameters.append(self.bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if(self.use_bias):\n",
    "            return input.mm(self.weight)+self.bias.expand(0,len(input.data))\n",
    "        return input.mm(self.weight)\n",
    "\n",
    "\n",
    "class Sequential(Layer):\n",
    "    \n",
    "    def __init__(self, layers=list()):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = layers\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        for layer in self.layers:\n",
    "            input = layer.forward(input)\n",
    "        return input\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        params = list()\n",
    "        for l in self.layers:\n",
    "            params += l.get_parameters()\n",
    "        return params\n",
    "\n",
    "\n",
    "class Embedding(Layer):\n",
    "    \n",
    "    def __init__(self, vocab_size, dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.dim = dim\n",
    "        \n",
    "        # this random initialiation style is just a convention from word2vec\n",
    "        self.weight = Tensor((np.random.rand(vocab_size, dim) - 0.5) / dim, autograd=True)\n",
    "        \n",
    "        self.parameters.append(self.weight)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.weight.index_select(input)\n",
    "\n",
    "\n",
    "class Tanh(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input.tanh()\n",
    "\n",
    "\n",
    "class Sigmoid(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input.sigmoid()\n",
    "    \n",
    "\n",
    "class CrossEntropyLoss(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        return input.cross_entropy(target)\n",
    "\n",
    "    \n",
    "class RNNCell(Layer):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_hidden, n_output, activation='sigmoid'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        if(activation == 'sigmoid'):\n",
    "            self.activation = Sigmoid()\n",
    "        elif(activation == 'tanh'):\n",
    "            self.activation == Tanh()\n",
    "        else:\n",
    "            raise Exception(\"Non-linearity not found\")\n",
    "\n",
    "        self.w_ih = Linear(n_inputs, n_hidden)\n",
    "        self.w_hh = Linear(n_hidden, n_hidden)\n",
    "        self.w_ho = Linear(n_hidden, n_output)\n",
    "        \n",
    "        self.parameters += self.w_ih.get_parameters()\n",
    "        self.parameters += self.w_hh.get_parameters()\n",
    "        self.parameters += self.w_ho.get_parameters()        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        from_prev_hidden = self.w_hh.forward(hidden)\n",
    "        combined = self.w_ih.forward(input) + from_prev_hidden\n",
    "        new_hidden = self.activation.forward(combined)\n",
    "        output = self.w_ho.forward(new_hidden)\n",
    "        return output, new_hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return Tensor(np.zeros((batch_size,self.n_hidden)), autograd=True)\n",
    "    \n",
    "class LSTMCell(Layer):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_hidden, n_output):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "\n",
    "        self.xf = Linear(n_inputs, n_hidden)\n",
    "        self.xi = Linear(n_inputs, n_hidden)\n",
    "        self.xo = Linear(n_inputs, n_hidden)        \n",
    "        self.xc = Linear(n_inputs, n_hidden)        \n",
    "        \n",
    "        self.hf = Linear(n_hidden, n_hidden, bias=False)\n",
    "        self.hi = Linear(n_hidden, n_hidden, bias=False)\n",
    "        self.ho = Linear(n_hidden, n_hidden, bias=False)\n",
    "        self.hc = Linear(n_hidden, n_hidden, bias=False)        \n",
    "        \n",
    "        self.w_ho = Linear(n_hidden, n_output, bias=False)\n",
    "        \n",
    "        self.parameters += self.xf.get_parameters()\n",
    "        self.parameters += self.xi.get_parameters()\n",
    "        self.parameters += self.xo.get_parameters()\n",
    "        self.parameters += self.xc.get_parameters()\n",
    "\n",
    "        self.parameters += self.hf.get_parameters()\n",
    "        self.parameters += self.hi.get_parameters()        \n",
    "        self.parameters += self.ho.get_parameters()        \n",
    "        self.parameters += self.hc.get_parameters()                \n",
    "        \n",
    "        self.parameters += self.w_ho.get_parameters()        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        prev_hidden = hidden[0]        \n",
    "        prev_cell = hidden[1]\n",
    "        \n",
    "        f = (self.xf.forward(input) + self.hf.forward(prev_hidden)).sigmoid()\n",
    "        i = (self.xi.forward(input) + self.hi.forward(prev_hidden)).sigmoid()\n",
    "        o = (self.xo.forward(input) + self.ho.forward(prev_hidden)).sigmoid()        \n",
    "        g = (self.xc.forward(input) + self.hc.forward(prev_hidden)).tanh()        \n",
    "        c = (f * prev_cell) + (i * g)\n",
    "\n",
    "        h = o * c.tanh()\n",
    "        \n",
    "        output = self.w_ho.forward(h)\n",
    "        return output, (h, c)\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        init_hidden = Tensor(np.zeros((batch_size,self.n_hidden)), autograd=True)\n",
    "        init_cell = Tensor(np.zeros((batch_size,self.n_hidden)), autograd=True)\n",
    "        init_hidden.data[:,0] += 1\n",
    "        init_cell.data[:,0] += 1\n",
    "        return (init_hidden, init_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(Layer):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_hidden, n_output):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "\n",
    "        self.xf = Linear(n_inputs, n_hidden)\n",
    "        self.xi = Linear(n_inputs, n_hidden)\n",
    "        self.xo = Linear(n_inputs, n_hidden)        \n",
    "        self.xc = Linear(n_inputs, n_hidden)        \n",
    "        \n",
    "        self.hf = Linear(n_hidden, n_hidden, bias=False)\n",
    "        self.hi = Linear(n_hidden, n_hidden, bias=False)\n",
    "        self.ho = Linear(n_hidden, n_hidden, bias=False)\n",
    "        self.hc = Linear(n_hidden, n_hidden, bias=False)        \n",
    "        \n",
    "        self.w_ho = Linear(n_hidden, n_output, bias=False)\n",
    "        \n",
    "        self.parameters += self.xf.get_parameters()\n",
    "        self.parameters += self.xi.get_parameters()\n",
    "        self.parameters += self.xo.get_parameters()\n",
    "        self.parameters += self.xc.get_parameters()\n",
    "\n",
    "        self.parameters += self.hf.get_parameters()\n",
    "        self.parameters += self.hi.get_parameters()        \n",
    "        self.parameters += self.ho.get_parameters()        \n",
    "        self.parameters += self.hc.get_parameters()                \n",
    "        \n",
    "        self.parameters += self.w_ho.get_parameters()        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        prev_hidden = hidden[0]        \n",
    "        prev_cell = hidden[1]\n",
    "        \n",
    "        f = (self.xf.forward(input) + self.hf.forward(prev_hidden)).sigmoid()\n",
    "        i = (self.xi.forward(input) + self.hi.forward(prev_hidden)).sigmoid()\n",
    "        o = (self.xo.forward(input) + self.ho.forward(prev_hidden)).sigmoid()        \n",
    "        g = (self.xc.forward(input) + self.hc.forward(prev_hidden)).tanh()        \n",
    "        c = (f * prev_cell) + (i * g)\n",
    "\n",
    "        h = o * c.tanh()\n",
    "        \n",
    "        output = self.w_ho.forward(h)\n",
    "        return output, (h, c)\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        init_hidden = Tensor(np.zeros((batch_size,self.n_hidden)), autograd=True)\n",
    "        init_cell = Tensor(np.zeros((batch_size,self.n_hidden)), autograd=True)\n",
    "        init_hidden.data[:,0] += 1\n",
    "        init_cell.data[:,0] += 1\n",
    "        return (init_hidden, init_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMCell(n_inputs=1, n_hidden=16, n_output=1)\n",
    "model.w_ho.weight.data *= 0\n",
    "criterion = MSELoss()\n",
    "optim = SGD(parameters=model.get_parameters(), alpha=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 1.0/50.0 - Min Loss:[514. - Loss:[514.01946736]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 2.0/50.0 - Min Loss:[86.7 - Loss:[86.71922061]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 3.0/50.0 - Min Loss:[33.3 - Loss:[33.36065042]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 4.0/50.0 - Min Loss:[26.9 - Loss:[26.97694912]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 5.0/50.0 - Min Loss:[17.6 - Loss:[17.66739961]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 6.0/50.0 - Min Loss:[13.2 - Loss:[13.22444456]\n",
      " Epoch:0 - Alpha:0.047 - Batch 7.0/50.0 - Min Loss:[13.2 - Loss:[13.26983199]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 8.0/50.0 - Min Loss:[12.6 - Loss:[12.63571141]\n",
      " Epoch:0 - Alpha:0.047 - Batch 9.0/50.0 - Min Loss:[12.6 - Loss:[12.94545946]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 10.0/50.0 - Min Loss:[11.3 - Loss:[11.35877059]\n",
      " Epoch:0 - Alpha:0.047 - Batch 11.0/50.0 - Min Loss:[11.3 - Loss:[12.14693376]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 12.0/50.0 - Min Loss:[10.8 - Loss:[10.82657958]\n",
      " Epoch:0 - Alpha:0.047 - Batch 13.0/50.0 - Min Loss:[10.8 - Loss:[12.53182792]\n",
      " Epoch:0 - Alpha:0.047 - Batch 14.0/50.0 - Min Loss:[10.8 - Loss:[12.51434379]\n",
      " Epoch:0 - Alpha:0.047 - Batch 15.0/50.0 - Min Loss:[10.8 - Loss:[11.1542384]\n",
      " Epoch:0 - Alpha:0.047 - Batch 16.0/50.0 - Min Loss:[10.8 - Loss:[10.87443166]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 17.0/50.0 - Min Loss:[10.2 - Loss:[10.26719598]\n",
      "\n",
      " Epoch:0 - Alpha:0.047 - Batch 18.0/50.0 - Min Loss:[10.1 - Loss:[10.10927301]\n",
      " Epoch:0 - Alpha:0.047 - Batch 19.0/50.0 - Min Loss:[10.1 - Loss:[10.63221389]\n",
      " Epoch:0 - Alpha:0.047 - Batch 20.0/50.0 - Min Loss:[10.1 - Loss:[11.98173381]\n",
      " Epoch:0 - Alpha:0.047 - Batch 21.0/50.0 - Min Loss:[10.1 - Loss:[12.18334392]\n",
      " Epoch:0 - Alpha:0.047 - Batch 22.0/50.0 - Min Loss:[10.1 - Loss:[11.64133485]\n",
      " Epoch:0 - Alpha:0.047 - Batch 23.0/50.0 - Min Loss:[10.1 - Loss:[11.86177124]\n",
      " Epoch:0 - Alpha:0.047 - Batch 24.0/50.0 - Min Loss:[10.1 - Loss:[11.54455972]\n",
      " Epoch:0 - Alpha:0.047 - Batch 25.0/50.0 - Min Loss:[10.1 - Loss:[13.19310982]\n",
      " Epoch:0 - Alpha:0.047 - Batch 26.0/50.0 - Min Loss:[10.1 - Loss:[13.14077399]\n",
      " Epoch:0 - Alpha:0.047 - Batch 27.0/50.0 - Min Loss:[10.1 - Loss:[12.31463626]\n",
      " Epoch:0 - Alpha:0.047 - Batch 28.0/50.0 - Min Loss:[10.1 - Loss:[11.87055833]\n",
      " Epoch:0 - Alpha:0.047 - Batch 29.0/50.0 - Min Loss:[10.1 - Loss:[11.66779319]\n",
      " Epoch:0 - Alpha:0.047 - Batch 30.0/50.0 - Min Loss:[10.1 - Loss:[11.42747405]\n",
      " Epoch:0 - Alpha:0.047 - Batch 31.0/50.0 - Min Loss:[10.1 - Loss:[12.22130802]\n",
      " Epoch:0 - Alpha:0.047 - Batch 32.0/50.0 - Min Loss:[10.1 - Loss:[13.33346492]\n",
      " Epoch:0 - Alpha:0.047 - Batch 33.0/50.0 - Min Loss:[10.1 - Loss:[12.60635985]\n",
      " Epoch:0 - Alpha:0.047 - Batch 34.0/50.0 - Min Loss:[10.1 - Loss:[13.04321177]\n",
      " Epoch:0 - Alpha:0.047 - Batch 35.0/50.0 - Min Loss:[10.1 - Loss:[14.25679202]\n",
      " Epoch:0 - Alpha:0.047 - Batch 36.0/50.0 - Min Loss:[10.1 - Loss:[13.60152307]\n",
      " Epoch:0 - Alpha:0.047 - Batch 37.0/50.0 - Min Loss:[10.1 - Loss:[13.51076769]\n",
      " Epoch:0 - Alpha:0.047 - Batch 38.0/50.0 - Min Loss:[10.1 - Loss:[13.38409711]\n",
      " Epoch:0 - Alpha:0.047 - Batch 39.0/50.0 - Min Loss:[10.1 - Loss:[13.1372501]\n",
      " Epoch:0 - Alpha:0.047 - Batch 40.0/50.0 - Min Loss:[10.1 - Loss:[12.85595236]\n",
      " Epoch:0 - Alpha:0.047 - Batch 41.0/50.0 - Min Loss:[10.1 - Loss:[14.07051101]\n",
      " Epoch:0 - Alpha:0.047 - Batch 42.0/50.0 - Min Loss:[10.1 - Loss:[14.66973685]\n",
      " Epoch:0 - Alpha:0.047 - Batch 43.0/50.0 - Min Loss:[10.1 - Loss:[14.22330417]\n",
      " Epoch:0 - Alpha:0.047 - Batch 44.0/50.0 - Min Loss:[10.1 - Loss:[14.05617947]\n",
      " Epoch:0 - Alpha:0.047 - Batch 45.0/50.0 - Min Loss:[10.1 - Loss:[13.60250395]\n",
      " Epoch:0 - Alpha:0.047 - Batch 46.0/50.0 - Min Loss:[10.1 - Loss:[13.5258352]\n",
      " Epoch:0 - Alpha:0.047 - Batch 47.0/50.0 - Min Loss:[10.1 - Loss:[13.6327374]\n",
      " Epoch:0 - Alpha:0.047 - Batch 48.0/50.0 - Min Loss:[10.1 - Loss:[13.38013537]\n",
      " Epoch:0 - Alpha:0.047 - Batch 49.0/50.0 - Min Loss:[10.1 - Loss:[13.04897171]\n",
      " Epoch:0 - Alpha:0.047 - Batch 50.0/50.0 - Min Loss:[10.1 - Loss:[12.71937973]\n",
      " Epoch:1 - Alpha:0.047 - Batch 1.0/50.0 - Min Loss:[10.1 - Loss:[327.30122132]\n",
      " Epoch:1 - Alpha:0.047 - Batch 2.0/50.0 - Min Loss:[10.1 - Loss:[67.34801027]\n",
      " Epoch:1 - Alpha:0.047 - Batch 3.0/50.0 - Min Loss:[10.1 - Loss:[27.33677369]\n",
      " Epoch:1 - Alpha:0.047 - Batch 4.0/50.0 - Min Loss:[10.1 - Loss:[22.18234761]\n",
      " Epoch:1 - Alpha:0.047 - Batch 5.0/50.0 - Min Loss:[10.1 - Loss:[14.94943989]\n",
      " Epoch:1 - Alpha:0.047 - Batch 6.0/50.0 - Min Loss:[10.1 - Loss:[11.15883125]\n",
      " Epoch:1 - Alpha:0.047 - Batch 7.0/50.0 - Min Loss:[10.1 - Loss:[11.10232935]\n",
      " Epoch:1 - Alpha:0.047 - Batch 8.0/50.0 - Min Loss:[10.1 - Loss:[10.54190243]\n",
      " Epoch:1 - Alpha:0.047 - Batch 9.0/50.0 - Min Loss:[10.1 - Loss:[10.72940701]\n",
      "\n",
      " Epoch:1 - Alpha:0.047 - Batch 10.0/50.0 - Min Loss:[9.41 - Loss:[9.41370379]\n",
      " Epoch:1 - Alpha:0.047 - Batch 11.0/50.0 - Min Loss:[9.41 - Loss:[9.97755306]\n",
      "\n",
      " Epoch:1 - Alpha:0.047 - Batch 12.0/50.0 - Min Loss:[8.94 - Loss:[8.94326374]\n",
      " Epoch:1 - Alpha:0.047 - Batch 13.0/50.0 - Min Loss:[8.94 - Loss:[10.12501791]\n",
      " Epoch:1 - Alpha:0.047 - Batch 14.0/50.0 - Min Loss:[8.94 - Loss:[10.08644929]\n",
      " Epoch:1 - Alpha:0.047 - Batch 15.0/50.0 - Min Loss:[8.94 - Loss:[9.06940774]\n",
      "\n",
      " Epoch:1 - Alpha:0.047 - Batch 16.0/50.0 - Min Loss:[8.80 - Loss:[8.80099088]\n",
      "\n",
      " Epoch:1 - Alpha:0.047 - Batch 17.0/50.0 - Min Loss:[8.22 - Loss:[8.22559957]\n",
      "\n",
      " Epoch:1 - Alpha:0.047 - Batch 18.0/50.0 - Min Loss:[8.17 - Loss:[8.17957942]\n",
      " Epoch:1 - Alpha:0.047 - Batch 19.0/50.0 - Min Loss:[8.17 - Loss:[8.55219882]\n",
      " Epoch:1 - Alpha:0.047 - Batch 20.0/50.0 - Min Loss:[8.17 - Loss:[9.55057192]\n",
      " Epoch:1 - Alpha:0.047 - Batch 21.0/50.0 - Min Loss:[8.17 - Loss:[9.65831722]\n",
      " Epoch:1 - Alpha:0.047 - Batch 22.0/50.0 - Min Loss:[8.17 - Loss:[9.24685439]\n",
      " Epoch:1 - Alpha:0.047 - Batch 23.0/50.0 - Min Loss:[8.17 - Loss:[9.3371707]\n",
      " Epoch:1 - Alpha:0.047 - Batch 24.0/50.0 - Min Loss:[8.17 - Loss:[9.02146427]\n",
      " Epoch:1 - Alpha:0.047 - Batch 25.0/50.0 - Min Loss:[8.17 - Loss:[10.08611333]\n",
      " Epoch:1 - Alpha:0.047 - Batch 26.0/50.0 - Min Loss:[8.17 - Loss:[9.95363334]\n",
      " Epoch:1 - Alpha:0.047 - Batch 27.0/50.0 - Min Loss:[8.17 - Loss:[9.37452125]\n",
      " Epoch:1 - Alpha:0.047 - Batch 28.0/50.0 - Min Loss:[8.17 - Loss:[9.01877076]\n",
      " Epoch:1 - Alpha:0.047 - Batch 29.0/50.0 - Min Loss:[8.17 - Loss:[8.79787832]\n",
      " Epoch:1 - Alpha:0.047 - Batch 30.0/50.0 - Min Loss:[8.17 - Loss:[8.52842028]\n",
      " Epoch:1 - Alpha:0.047 - Batch 31.0/50.0 - Min Loss:[8.17 - Loss:[8.96976271]\n",
      " Epoch:1 - Alpha:0.047 - Batch 32.0/50.0 - Min Loss:[8.17 - Loss:[9.57193324]\n",
      " Epoch:1 - Alpha:0.047 - Batch 33.0/50.0 - Min Loss:[8.17 - Loss:[9.13737095]\n",
      " Epoch:1 - Alpha:0.047 - Batch 34.0/50.0 - Min Loss:[8.17 - Loss:[9.34153215]\n",
      " Epoch:1 - Alpha:0.047 - Batch 35.0/50.0 - Min Loss:[8.17 - Loss:[9.94122311]\n",
      " Epoch:1 - Alpha:0.047 - Batch 36.0/50.0 - Min Loss:[8.17 - Loss:[9.52746949]\n",
      " Epoch:1 - Alpha:0.047 - Batch 37.0/50.0 - Min Loss:[8.17 - Loss:[9.43887726]\n",
      " Epoch:1 - Alpha:0.047 - Batch 38.0/50.0 - Min Loss:[8.17 - Loss:[9.35539697]\n",
      " Epoch:1 - Alpha:0.047 - Batch 39.0/50.0 - Min Loss:[8.17 - Loss:[9.14135468]\n",
      " Epoch:1 - Alpha:0.047 - Batch 40.0/50.0 - Min Loss:[8.17 - Loss:[8.89452316]\n",
      " Epoch:1 - Alpha:0.047 - Batch 41.0/50.0 - Min Loss:[8.17 - Loss:[9.42048858]\n",
      " Epoch:1 - Alpha:0.047 - Batch 42.0/50.0 - Min Loss:[8.17 - Loss:[9.79638344]\n",
      " Epoch:1 - Alpha:0.047 - Batch 43.0/50.0 - Min Loss:[8.17 - Loss:[9.4089033]\n",
      " Epoch:1 - Alpha:0.047 - Batch 44.0/50.0 - Min Loss:[8.17 - Loss:[9.20304025]\n",
      " Epoch:1 - Alpha:0.047 - Batch 45.0/50.0 - Min Loss:[8.17 - Loss:[8.90365313]\n",
      " Epoch:1 - Alpha:0.047 - Batch 46.0/50.0 - Min Loss:[8.17 - Loss:[8.77084776]\n",
      " Epoch:1 - Alpha:0.047 - Batch 47.0/50.0 - Min Loss:[8.17 - Loss:[8.59295851]\n",
      " Epoch:1 - Alpha:0.047 - Batch 48.0/50.0 - Min Loss:[8.17 - Loss:[8.37612832]\n",
      "\n",
      " Epoch:1 - Alpha:0.047 - Batch 49.0/50.0 - Min Loss:[8.15 - Loss:[8.15503559]\n",
      "\n",
      " Epoch:1 - Alpha:0.047 - Batch 50.0/50.0 - Min Loss:[7.93 - Loss:[7.93232285]\n",
      " Epoch:2 - Alpha:0.046 - Batch 1.0/50.0 - Min Loss:[7.93 - Loss:[22.12041111]\n",
      " Epoch:2 - Alpha:0.046 - Batch 2.0/50.0 - Min Loss:[7.93 - Loss:[9.03496915]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 3.0/50.0 - Min Loss:[5.36 - Loss:[5.361092]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 4.0/50.0 - Min Loss:[4.49 - Loss:[4.49454875]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 5.0/50.0 - Min Loss:[3.75 - Loss:[3.75607737]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 6.0/50.0 - Min Loss:[3.26 - Loss:[3.2644]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 7.0/50.0 - Min Loss:[3.12 - Loss:[3.12437649]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 8.0/50.0 - Min Loss:[3.09 - Loss:[3.09358622]\n",
      " Epoch:2 - Alpha:0.046 - Batch 9.0/50.0 - Min Loss:[3.09 - Loss:[3.24771211]\n",
      " Epoch:2 - Alpha:0.046 - Batch 10.0/50.0 - Min Loss:[3.09 - Loss:[3.15216333]\n",
      " Epoch:2 - Alpha:0.046 - Batch 11.0/50.0 - Min Loss:[3.09 - Loss:[3.14986239]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 12.0/50.0 - Min Loss:[2.95 - Loss:[2.95581379]\n",
      " Epoch:2 - Alpha:0.046 - Batch 13.0/50.0 - Min Loss:[2.95 - Loss:[3.09380752]\n",
      " Epoch:2 - Alpha:0.046 - Batch 14.0/50.0 - Min Loss:[2.95 - Loss:[3.08639702]\n",
      " Epoch:2 - Alpha:0.046 - Batch 15.0/50.0 - Min Loss:[2.95 - Loss:[2.98415909]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 16.0/50.0 - Min Loss:[2.93 - Loss:[2.93132581]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 17.0/50.0 - Min Loss:[2.87 - Loss:[2.87299721]\n",
      "\n",
      " Epoch:2 - Alpha:0.046 - Batch 18.0/50.0 - Min Loss:[2.84 - Loss:[2.84244956]\n",
      " Epoch:2 - Alpha:0.046 - Batch 19.0/50.0 - Min Loss:[2.84 - Loss:[2.89294611]\n",
      " Epoch:2 - Alpha:0.046 - Batch 20.0/50.0 - Min Loss:[2.84 - Loss:[3.14321722]\n",
      " Epoch:2 - Alpha:0.046 - Batch 21.0/50.0 - Min Loss:[2.84 - Loss:[3.27140681]\n",
      " Epoch:2 - Alpha:0.046 - Batch 22.0/50.0 - Min Loss:[2.84 - Loss:[3.16855004]\n",
      " Epoch:2 - Alpha:0.046 - Batch 23.0/50.0 - Min Loss:[2.84 - Loss:[3.17508374]\n",
      " Epoch:2 - Alpha:0.046 - Batch 24.0/50.0 - Min Loss:[2.84 - Loss:[3.14077833]\n",
      " Epoch:2 - Alpha:0.046 - Batch 25.0/50.0 - Min Loss:[2.84 - Loss:[3.29142132]\n",
      " Epoch:2 - Alpha:0.046 - Batch 26.0/50.0 - Min Loss:[2.84 - Loss:[3.31669942]\n",
      " Epoch:2 - Alpha:0.046 - Batch 27.0/50.0 - Min Loss:[2.84 - Loss:[3.27105591]\n",
      " Epoch:2 - Alpha:0.046 - Batch 28.0/50.0 - Min Loss:[2.84 - Loss:[3.23180295]\n",
      " Epoch:2 - Alpha:0.046 - Batch 29.0/50.0 - Min Loss:[2.84 - Loss:[3.25918345]\n",
      " Epoch:2 - Alpha:0.046 - Batch 30.0/50.0 - Min Loss:[2.84 - Loss:[3.22308934]\n",
      " Epoch:2 - Alpha:0.046 - Batch 31.0/50.0 - Min Loss:[2.84 - Loss:[3.38440515]\n",
      " Epoch:2 - Alpha:0.046 - Batch 32.0/50.0 - Min Loss:[2.84 - Loss:[3.48141452]\n",
      " Epoch:2 - Alpha:0.046 - Batch 33.0/50.0 - Min Loss:[2.84 - Loss:[3.4761624]\n",
      " Epoch:2 - Alpha:0.046 - Batch 34.0/50.0 - Min Loss:[2.84 - Loss:[3.51157852]\n",
      " Epoch:2 - Alpha:0.046 - Batch 35.0/50.0 - Min Loss:[2.84 - Loss:[3.57430619]\n",
      " Epoch:2 - Alpha:0.046 - Batch 36.0/50.0 - Min Loss:[2.84 - Loss:[3.49389119]\n",
      " Epoch:2 - Alpha:0.046 - Batch 37.0/50.0 - Min Loss:[2.84 - Loss:[3.49093806]\n",
      " Epoch:2 - Alpha:0.046 - Batch 38.0/50.0 - Min Loss:[2.84 - Loss:[3.57126744]\n",
      " Epoch:2 - Alpha:0.046 - Batch 39.0/50.0 - Min Loss:[2.84 - Loss:[3.59799499]\n",
      " Epoch:2 - Alpha:0.046 - Batch 40.0/50.0 - Min Loss:[2.84 - Loss:[3.58844448]\n",
      " Epoch:2 - Alpha:0.046 - Batch 41.0/50.0 - Min Loss:[2.84 - Loss:[3.79157972]\n",
      " Epoch:2 - Alpha:0.046 - Batch 42.0/50.0 - Min Loss:[2.84 - Loss:[3.93452768]\n",
      " Epoch:2 - Alpha:0.046 - Batch 43.0/50.0 - Min Loss:[2.84 - Loss:[3.88671803]\n",
      " Epoch:2 - Alpha:0.046 - Batch 44.0/50.0 - Min Loss:[2.84 - Loss:[4.27375792]\n",
      " Epoch:2 - Alpha:0.046 - Batch 45.0/50.0 - Min Loss:[2.84 - Loss:[4.20053933]\n",
      " Epoch:2 - Alpha:0.046 - Batch 46.0/50.0 - Min Loss:[2.84 - Loss:[4.25541698]\n",
      " Epoch:2 - Alpha:0.046 - Batch 47.0/50.0 - Min Loss:[2.84 - Loss:[4.30926992]\n",
      " Epoch:2 - Alpha:0.046 - Batch 48.0/50.0 - Min Loss:[2.84 - Loss:[4.33480675]\n",
      " Epoch:2 - Alpha:0.046 - Batch 49.0/50.0 - Min Loss:[2.84 - Loss:[4.28367428]\n",
      " Epoch:2 - Alpha:0.046 - Batch 50.0/50.0 - Min Loss:[2.84 - Loss:[4.21851608]\n",
      " Epoch:3 - Alpha:0.046 - Batch 1.0/50.0 - Min Loss:[2.84 - Loss:[65.20689277]\n",
      " Epoch:3 - Alpha:0.046 - Batch 2.0/50.0 - Min Loss:[2.84 - Loss:[133.52616845]\n",
      " Epoch:3 - Alpha:0.046 - Batch 3.0/50.0 - Min Loss:[2.84 - Loss:[109.00235806]\n",
      " Epoch:3 - Alpha:0.046 - Batch 4.0/50.0 - Min Loss:[2.84 - Loss:[42.20884142]\n",
      " Epoch:3 - Alpha:0.046 - Batch 5.0/50.0 - Min Loss:[2.84 - Loss:[21.79286468]\n",
      " Epoch:3 - Alpha:0.046 - Batch 6.0/50.0 - Min Loss:[2.84 - Loss:[14.17986312]\n",
      " Epoch:3 - Alpha:0.046 - Batch 7.0/50.0 - Min Loss:[2.84 - Loss:[14.13837955]\n",
      " Epoch:3 - Alpha:0.046 - Batch 8.0/50.0 - Min Loss:[2.84 - Loss:[12.00918669]\n",
      " Epoch:3 - Alpha:0.046 - Batch 9.0/50.0 - Min Loss:[2.84 - Loss:[12.25097103]\n",
      " Epoch:3 - Alpha:0.046 - Batch 10.0/50.0 - Min Loss:[2.84 - Loss:[10.44956568]\n",
      " Epoch:3 - Alpha:0.046 - Batch 11.0/50.0 - Min Loss:[2.84 - Loss:[9.93283108]\n",
      " Epoch:3 - Alpha:0.046 - Batch 12.0/50.0 - Min Loss:[2.84 - Loss:[8.40086338]\n",
      " Epoch:3 - Alpha:0.046 - Batch 13.0/50.0 - Min Loss:[2.84 - Loss:[8.63106758]\n",
      " Epoch:3 - Alpha:0.046 - Batch 14.0/50.0 - Min Loss:[2.84 - Loss:[8.45880176]\n",
      " Epoch:3 - Alpha:0.046 - Batch 15.0/50.0 - Min Loss:[2.84 - Loss:[7.67860782]\n",
      " Epoch:3 - Alpha:0.046 - Batch 16.0/50.0 - Min Loss:[2.84 - Loss:[8.01029877]\n",
      " Epoch:3 - Alpha:0.046 - Batch 17.0/50.0 - Min Loss:[2.84 - Loss:[7.69829839]\n",
      " Epoch:3 - Alpha:0.046 - Batch 18.0/50.0 - Min Loss:[2.84 - Loss:[7.55064112]\n",
      " Epoch:3 - Alpha:0.046 - Batch 19.0/50.0 - Min Loss:[2.84 - Loss:[7.65919396]\n",
      " Epoch:3 - Alpha:0.046 - Batch 20.0/50.0 - Min Loss:[2.84 - Loss:[8.47945749]\n",
      " Epoch:3 - Alpha:0.046 - Batch 21.0/50.0 - Min Loss:[2.84 - Loss:[8.29021835]\n",
      " Epoch:3 - Alpha:0.046 - Batch 22.0/50.0 - Min Loss:[2.84 - Loss:[7.69292186]\n",
      " Epoch:3 - Alpha:0.046 - Batch 23.0/50.0 - Min Loss:[2.84 - Loss:[7.63437619]\n",
      " Epoch:3 - Alpha:0.046 - Batch 24.0/50.0 - Min Loss:[2.84 - Loss:[7.32889894]\n",
      " Epoch:3 - Alpha:0.046 - Batch 25.0/50.0 - Min Loss:[2.84 - Loss:[7.50481938]\n",
      " Epoch:3 - Alpha:0.046 - Batch 26.0/50.0 - Min Loss:[2.84 - Loss:[7.31660381]\n",
      " Epoch:3 - Alpha:0.046 - Batch 27.0/50.0 - Min Loss:[2.84 - Loss:[7.06584874]\n",
      " Epoch:3 - Alpha:0.046 - Batch 28.0/50.0 - Min Loss:[2.84 - Loss:[6.80646058]\n",
      " Epoch:3 - Alpha:0.046 - Batch 29.0/50.0 - Min Loss:[2.84 - Loss:[6.89101296]\n",
      " Epoch:3 - Alpha:0.046 - Batch 30.0/50.0 - Min Loss:[2.84 - Loss:[6.64147881]\n",
      " Epoch:3 - Alpha:0.046 - Batch 31.0/50.0 - Min Loss:[2.84 - Loss:[6.81134585]\n",
      " Epoch:3 - Alpha:0.046 - Batch 32.0/50.0 - Min Loss:[2.84 - Loss:[6.87642296]\n",
      " Epoch:3 - Alpha:0.046 - Batch 33.0/50.0 - Min Loss:[2.84 - Loss:[6.74577247]\n",
      " Epoch:3 - Alpha:0.046 - Batch 34.0/50.0 - Min Loss:[2.84 - Loss:[6.6827229]\n",
      " Epoch:3 - Alpha:0.046 - Batch 35.0/50.0 - Min Loss:[2.84 - Loss:[6.71079005]\n",
      " Epoch:3 - Alpha:0.046 - Batch 36.0/50.0 - Min Loss:[2.84 - Loss:[6.45068051]\n",
      " Epoch:3 - Alpha:0.046 - Batch 37.0/50.0 - Min Loss:[2.84 - Loss:[6.33956394]\n",
      " Epoch:3 - Alpha:0.046 - Batch 38.0/50.0 - Min Loss:[2.84 - Loss:[6.43114742]\n",
      " Epoch:3 - Alpha:0.046 - Batch 39.0/50.0 - Min Loss:[2.84 - Loss:[6.39656642]\n",
      " Epoch:3 - Alpha:0.046 - Batch 40.0/50.0 - Min Loss:[2.84 - Loss:[6.30658108]\n",
      " Epoch:3 - Alpha:0.046 - Batch 41.0/50.0 - Min Loss:[2.84 - Loss:[6.59868209]\n",
      " Epoch:3 - Alpha:0.046 - Batch 42.0/50.0 - Min Loss:[2.84 - Loss:[6.7256056]\n",
      " Epoch:3 - Alpha:0.046 - Batch 43.0/50.0 - Min Loss:[2.84 - Loss:[6.55069136]\n",
      " Epoch:3 - Alpha:0.046 - Batch 44.0/50.0 - Min Loss:[2.84 - Loss:[7.0656632]\n",
      " Epoch:3 - Alpha:0.046 - Batch 45.0/50.0 - Min Loss:[2.84 - Loss:[6.87079711]\n",
      " Epoch:3 - Alpha:0.046 - Batch 46.0/50.0 - Min Loss:[2.84 - Loss:[6.90964644]\n",
      " Epoch:3 - Alpha:0.046 - Batch 47.0/50.0 - Min Loss:[2.84 - Loss:[6.93401639]\n",
      " Epoch:3 - Alpha:0.046 - Batch 48.0/50.0 - Min Loss:[2.84 - Loss:[6.90397429]\n",
      " Epoch:3 - Alpha:0.046 - Batch 49.0/50.0 - Min Loss:[2.84 - Loss:[6.75909776]\n",
      " Epoch:3 - Alpha:0.046 - Batch 50.0/50.0 - Min Loss:[2.84 - Loss:[6.59514661]\n",
      " Epoch:4 - Alpha:0.045 - Batch 1.0/50.0 - Min Loss:[2.84 - Loss:[64.02452018]\n",
      " Epoch:4 - Alpha:0.045 - Batch 2.0/50.0 - Min Loss:[2.84 - Loss:[146.88704834]\n",
      " Epoch:4 - Alpha:0.045 - Batch 3.0/50.0 - Min Loss:[2.84 - Loss:[120.89093002]\n",
      " Epoch:4 - Alpha:0.045 - Batch 4.0/50.0 - Min Loss:[2.84 - Loss:[45.53758256]\n",
      " Epoch:4 - Alpha:0.045 - Batch 5.0/50.0 - Min Loss:[2.84 - Loss:[23.1573294]\n",
      " Epoch:4 - Alpha:0.045 - Batch 6.0/50.0 - Min Loss:[2.84 - Loss:[14.91242024]\n",
      " Epoch:4 - Alpha:0.045 - Batch 7.0/50.0 - Min Loss:[2.84 - Loss:[14.82065901]\n",
      " Epoch:4 - Alpha:0.045 - Batch 8.0/50.0 - Min Loss:[2.84 - Loss:[12.50947532]\n",
      " Epoch:4 - Alpha:0.045 - Batch 9.0/50.0 - Min Loss:[2.84 - Loss:[12.75966137]\n",
      " Epoch:4 - Alpha:0.045 - Batch 10.0/50.0 - Min Loss:[2.84 - Loss:[10.83860077]\n",
      " Epoch:4 - Alpha:0.045 - Batch 11.0/50.0 - Min Loss:[2.84 - Loss:[10.29056195]\n",
      " Epoch:4 - Alpha:0.045 - Batch 12.0/50.0 - Min Loss:[2.84 - Loss:[8.67713081]\n",
      " Epoch:4 - Alpha:0.045 - Batch 13.0/50.0 - Min Loss:[2.84 - Loss:[8.88663999]\n",
      " Epoch:4 - Alpha:0.045 - Batch 14.0/50.0 - Min Loss:[2.84 - Loss:[8.70018398]\n",
      " Epoch:4 - Alpha:0.045 - Batch 15.0/50.0 - Min Loss:[2.84 - Loss:[7.88033407]\n",
      " Epoch:4 - Alpha:0.045 - Batch 16.0/50.0 - Min Loss:[2.84 - Loss:[8.28251069]\n",
      " Epoch:4 - Alpha:0.045 - Batch 17.0/50.0 - Min Loss:[2.84 - Loss:[7.94390474]\n",
      " Epoch:4 - Alpha:0.045 - Batch 18.0/50.0 - Min Loss:[2.84 - Loss:[7.77765505]\n",
      " Epoch:4 - Alpha:0.045 - Batch 19.0/50.0 - Min Loss:[2.84 - Loss:[7.88484516]\n",
      " Epoch:4 - Alpha:0.045 - Batch 20.0/50.0 - Min Loss:[2.84 - Loss:[8.75101912]\n",
      " Epoch:4 - Alpha:0.045 - Batch 21.0/50.0 - Min Loss:[2.84 - Loss:[8.54826487]\n",
      " Epoch:4 - Alpha:0.045 - Batch 22.0/50.0 - Min Loss:[2.84 - Loss:[7.92165456]\n",
      " Epoch:4 - Alpha:0.045 - Batch 23.0/50.0 - Min Loss:[2.84 - Loss:[7.85654239]\n",
      " Epoch:4 - Alpha:0.045 - Batch 24.0/50.0 - Min Loss:[2.84 - Loss:[7.53327676]\n",
      " Epoch:4 - Alpha:0.045 - Batch 25.0/50.0 - Min Loss:[2.84 - Loss:[7.70827435]\n",
      " Epoch:4 - Alpha:0.045 - Batch 26.0/50.0 - Min Loss:[2.84 - Loss:[7.50471824]\n",
      " Epoch:4 - Alpha:0.045 - Batch 27.0/50.0 - Min Loss:[2.84 - Loss:[7.24268594]\n",
      " Epoch:4 - Alpha:0.045 - Batch 28.0/50.0 - Min Loss:[2.84 - Loss:[6.97059853]\n",
      " Epoch:4 - Alpha:0.045 - Batch 29.0/50.0 - Min Loss:[2.84 - Loss:[7.0603959]\n",
      " Epoch:4 - Alpha:0.045 - Batch 30.0/50.0 - Min Loss:[2.84 - Loss:[6.80055029]\n",
      " Epoch:4 - Alpha:0.045 - Batch 31.0/50.0 - Min Loss:[2.84 - Loss:[6.96759373]\n",
      " Epoch:4 - Alpha:0.045 - Batch 32.0/50.0 - Min Loss:[2.84 - Loss:[7.03155572]\n",
      " Epoch:4 - Alpha:0.045 - Batch 33.0/50.0 - Min Loss:[2.84 - Loss:[6.90648932]\n",
      " Epoch:4 - Alpha:0.045 - Batch 34.0/50.0 - Min Loss:[2.84 - Loss:[6.83920252]\n",
      " Epoch:4 - Alpha:0.045 - Batch 35.0/50.0 - Min Loss:[2.84 - Loss:[6.86715804]\n",
      " Epoch:4 - Alpha:0.045 - Batch 36.0/50.0 - Min Loss:[2.84 - Loss:[6.60035152]\n",
      " Epoch:4 - Alpha:0.045 - Batch 37.0/50.0 - Min Loss:[2.84 - Loss:[6.48190284]\n",
      " Epoch:4 - Alpha:0.045 - Batch 38.0/50.0 - Min Loss:[2.84 - Loss:[6.58451238]\n",
      " Epoch:4 - Alpha:0.045 - Batch 39.0/50.0 - Min Loss:[2.84 - Loss:[6.54639352]\n",
      " Epoch:4 - Alpha:0.045 - Batch 40.0/50.0 - Min Loss:[2.84 - Loss:[6.45315337]\n",
      " Epoch:4 - Alpha:0.045 - Batch 41.0/50.0 - Min Loss:[2.84 - Loss:[6.74505152]\n",
      " Epoch:4 - Alpha:0.045 - Batch 42.0/50.0 - Min Loss:[2.84 - Loss:[6.84748076]\n",
      " Epoch:4 - Alpha:0.045 - Batch 43.0/50.0 - Min Loss:[2.84 - Loss:[6.66320514]\n",
      " Epoch:4 - Alpha:0.045 - Batch 44.0/50.0 - Min Loss:[2.84 - Loss:[7.09683047]\n",
      " Epoch:4 - Alpha:0.045 - Batch 45.0/50.0 - Min Loss:[2.84 - Loss:[6.90450726]\n",
      " Epoch:4 - Alpha:0.045 - Batch 46.0/50.0 - Min Loss:[2.84 - Loss:[6.93652353]\n",
      " Epoch:4 - Alpha:0.045 - Batch 47.0/50.0 - Min Loss:[2.84 - Loss:[6.95933393]\n",
      " Epoch:4 - Alpha:0.045 - Batch 48.0/50.0 - Min Loss:[2.84 - Loss:[6.91550897]\n",
      " Epoch:4 - Alpha:0.045 - Batch 49.0/50.0 - Min Loss:[2.84 - Loss:[6.76244057]\n",
      " Epoch:4 - Alpha:0.045 - Batch 50.0/50.0 - Min Loss:[2.84 - Loss:[6.59609693]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "iterations = 5\n",
    "seq_len = 23\n",
    "min_loss = 1000000\n",
    "for epoch in range(iterations):\n",
    "        total_loss = 0\n",
    "        n_loss = 0\n",
    "\n",
    "        hidden = model.init_hidden(batch_size=batch_size)\n",
    "\n",
    "        for index in range(0,800,batch_size):\n",
    "\n",
    "            hidden = (Tensor(hidden[0].data, autograd=True), Tensor(hidden[1].data, autograd=True))\n",
    "\n",
    "            losses = list()\n",
    "            for t in range(seq_len):\n",
    "                lstm_input = Tensor(X_train[index:min(index+batch_size,X_train.shape[0]),t].reshape(-1,1), autograd=True)\n",
    "\n",
    "                output, hidden = model.forward(input=lstm_input, hidden=hidden)\n",
    "\n",
    "                target = Tensor(y_train[index:min(index+batch_size,X_train.shape[0])].reshape(-1,1), autograd=True)  \n",
    "                batch_loss = criterion.forward(output, target)\n",
    "\n",
    "                if(t == 0):\n",
    "                    losses.append(batch_loss)\n",
    "                else:\n",
    "                    losses.append(batch_loss + losses[-1])\n",
    "\n",
    "            loss = losses[-1]\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total_loss += loss.data / seq_len\n",
    "\n",
    "            epoch_loss = np.exp(total_loss / (index/batch_size+1))\n",
    "            if(epoch_loss < min_loss):\n",
    "                min_loss = epoch_loss\n",
    "                print()\n",
    "\n",
    "            log = \"\\r Epoch:\" + str(epoch)\n",
    "            log += \" - Alpha:\" + str(optim.alpha)[0:5]\n",
    "            log += \" - Batch \"+str(index/batch_size+1)+\"/\"+str(800/batch_size)\n",
    "            log += \" - Min Loss:\" + str(min_loss)[0:5]\n",
    "            log += \" - Loss:\" + str(epoch_loss)\n",
    "            if(index % 1 == 0):\n",
    "                print(log)\n",
    "        optim.alpha *= 0.99\n",
    "    #     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.69047336]\n",
      "Pearson's R: 0.814424621177041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10896562d88>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden = model.init_hidden(batch_size=1)\n",
    "\n",
    "for i in range(seq_len):\n",
    "    lstm_input = Tensor(X_test[:,t].reshape(-1,1), autograd=True) \n",
    "    output, hidden = model.forward(input=lstm_input, hidden=hidden)\n",
    "\n",
    "    \n",
    "target = Tensor(y_test.reshape(-1,1), autograd=True)    \n",
    "loss = criterion.forward(output, target)    \n",
    "print(loss)\n",
    "pear = scipy.stats.pearsonr(target.data.ravel(),output.data.ravel())\n",
    "print(\"Pearson's R:\",pear[0])\n",
    "df = pd.DataFrame({'X_Axis': X_test[:, 0], 'y_test': target.data.ravel(), 'y_pred':output.data.ravel()})\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.scatterplot(x=\"y_test\", y=\"y_pred\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource for generating AutoRegressive (AR) data and LSTM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/jessicayung/blog-code-snippets/blob/master/lstm-pytorch/lstm-baseline.py\n",
    "#https://github.com/jessicayung/blog-code-snippets/blob/master/lstm-pytorch/generate_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Code to generate autoregressive data.\n",
    "# Blog post: http://www.jessicayung.com/generating-autoregressive-data-for-experiments=\n",
    "# Author: Jessiac Yung\n",
    "# Sept 2018\n",
    "# \"\"\"\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# class TimeSeriesData:\n",
    "#     def __init__(self, num_datapoints, test_size=0.2, max_t=20, num_prev=1,\n",
    "#                  noise_var=1):\n",
    "#         \"\"\"\n",
    "#         Template class for generating time series data.\n",
    "#         :param test_size: in (0,1), data to be used in test set as a fraction of all data generated.\n",
    "#         \"\"\"\n",
    "#         self.num_datapoints = num_datapoints\n",
    "#         self.test_size = test_size\n",
    "#         self.num_prev = num_prev\n",
    "#         self.max_t = max_t\n",
    "#         self.data = None\n",
    "#         self.noise_var = noise_var\n",
    "#         self.y = np.zeros(num_datapoints + num_prev*4) # TODO: check this\n",
    "#         self.bayes_preds = np.copy(self.y)\n",
    "\n",
    "#         # Generate data and reshape data\n",
    "#         self.create_data()\n",
    "\n",
    "#         # Split into training and test sets\n",
    "#         self.train_test_split()\n",
    "\n",
    "#     def create_data(self):\n",
    "#         self.generate_data()\n",
    "#         self.reshape_data()\n",
    "\n",
    "#     def generate_data(self):\n",
    "#         \"\"\"Generates data in self.y, may take as implicit input timesteps self.t.\n",
    "#         May also generate Bayes predictions.\"\"\"\n",
    "#         raise NotImplementedError(\"Generate data method not implemented.\")\n",
    "\n",
    "#     def reshape_data(self):\n",
    "#         self.x = np.reshape([self.y[i:i + self.num_prev] for i in range(\n",
    "#             self.num_datapoints)], (-1, self.num_prev))\n",
    "#         self.y = np.copy(self.y[self.num_prev:])\n",
    "#         self.bayes_preds = np.copy(self.bayes_preds[self.num_prev:])\n",
    "\n",
    "#     def train_test_split(self):\n",
    "#         test_size = int(len(self.y) * self.test_size)\n",
    "#         self.data = [self.X_train, self.X_test, self.y_train,\n",
    "#                      self.y_test] = \\\n",
    "#                     self.x[:-test_size], self.x[-test_size:], \\\n",
    "#                     self.y[:-test_size], self.y[-test_size:]\n",
    "#         self.bayes_preds = [self.bayes_train_preds, self.bayes_test_preds] = self.bayes_preds[:-test_size], self.bayes_preds[-test_size:]\n",
    "\n",
    "#     def return_data(self):\n",
    "#         return self.data\n",
    "\n",
    "#     def return_train_test(self):\n",
    "#         return self.X_train, self.y_train, self.X_test, self.y_test\n",
    "\n",
    "# class ARData(TimeSeriesData):\n",
    "#     \"\"\"Class to generate autoregressive data.\"\"\"\n",
    "\n",
    "#     def __init__(self, *args, coeffs=None, **kwargs):\n",
    "#         self.given_coeffs = coeffs\n",
    "#         super(ARData, self).__init__(*args, **kwargs)\n",
    "\n",
    "#         if coeffs is not None:\n",
    "#             self.num_prev = len(coeffs) - 1\n",
    "\n",
    "#     def generate_data(self):\n",
    "#         self.generate_coefficients()\n",
    "#         self.generate_initial_points()\n",
    "\n",
    "#         # + 3*self.num_prev because we want to cut first (3*self.num_prev) datapoints later\n",
    "#         # so dist is more stationary (else initial num_prev datapoints will stand out as diff dist)\n",
    "#         for i in range(self.num_datapoints+3*self.num_prev):\n",
    "#             # Generate y value if there was no noise\n",
    "#             # (equivalent to Bayes predictions: predictions from oracle that knows true parameters (coefficients))\n",
    "#             self.bayes_preds[i + self.num_prev] = np.dot(self.y[i:self.num_prev+i][::-1], self.coeffs)\n",
    "#             # Add noise\n",
    "#             self.y[i + self.num_prev] = self.bayes_preds[i + self.num_prev] + self.noise()\n",
    "\n",
    "#         # Cut first 20 points so dist is roughly stationary\n",
    "#         self.bayes_preds = self.bayes_preds[3*self.num_prev:]\n",
    "#         self.y = self.y[3*self.num_prev:]\n",
    "\n",
    "#     def generate_coefficients(self):\n",
    "#         if self.given_coeffs is not None:\n",
    "#             self.coeffs = self.given_coeffs\n",
    "#         else:\n",
    "#             filter_stable = False\n",
    "#             # Keep generating coefficients until we come across a set of coefficients\n",
    "#             # that correspond to stable poles\n",
    "#             while not filter_stable:\n",
    "#                 true_theta = np.random.random(self.num_prev) - 0.5\n",
    "#                 coefficients = np.append(1, -true_theta)\n",
    "#                 # check if magnitude of all poles is less than one\n",
    "#                 if np.max(np.abs(np.roots(coefficients))) < 1:\n",
    "#                     filter_stable = True\n",
    "#             self.coeffs = true_theta\n",
    "\n",
    "#     def generate_initial_points(self):\n",
    "#         # Initial datapoints distributed as N(0,1)\n",
    "#         self.y[:self.num_prev] = np.random.randn(self.num_prev)\n",
    "\n",
    "#     def noise(self):\n",
    "#         # Noise distributed as N(0, self.noise_var)\n",
    "#         return self.noise_var * np.random.randn()\n",
    "\n",
    "# # A set of coefficients that are stable (to produce replicable plots, experiments)\n",
    "# fixed_ar_coefficients = {2: [ 0.46152873, -0.29890739],\n",
    "#     5: [ 0.02519834, -0.24396899,  0.2785921,   0.14682383,  0.39390468],\n",
    "#                         10: [-0.10958935, -0.34564819,  0.3682048,   0.3134046,  -0.21553732,  0.34613629,\n",
    "#   0.41916508,  0.0165352,   0.14163503, -0.38844378],\n",
    "#                          20: [ 0.1937815,   0.01201026,  0.00464018, -0.21887467, -0.20113385, -0.02322278,\n",
    "#   0.34285319, -0.21069086,  0.06604683, -0.22377364,  0.11714593, -0.07122126,\n",
    "#  -0.16346554,  0.03174824,  0.308584,    0.06881604,  0.24840789, -0.32735569,\n",
    "#   0.21939492, 0.3996207 ]}\n",
    "\n",
    "# \"\"\"\n",
    "# Example of using fixed coefficients (consistency across tests of different models)\n",
    "# data = ARData(100, coeffs=fixed_ar_coefficients[5], num_prev=5)\n",
    "# plt.plot(data.y_train)\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from generate_data import *\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# #####################\n",
    "# # Set parameters\n",
    "# #####################\n",
    "\n",
    "# # Data params\n",
    "# noise_var = 0\n",
    "# num_datapoints = 100\n",
    "# test_size = 0.2\n",
    "# num_train = int((1-test_size) * num_datapoints)\n",
    "\n",
    "# # Network params\n",
    "# input_size = 20\n",
    "# # If `per_element` is True, then LSTM reads in one timestep at a time.\n",
    "# per_element = True\n",
    "# if per_element:\n",
    "#     lstm_input_size = 1\n",
    "# else:\n",
    "#     lstm_input_size = input_size\n",
    "# # size of hidden layers\n",
    "# h1 = 32\n",
    "# output_dim = 1\n",
    "# num_layers = 2\n",
    "# learning_rate = 1e-3\n",
    "# num_epochs = 500\n",
    "# dtype = torch.float\n",
    "\n",
    "# #####################\n",
    "# # Generate data\n",
    "# #####################\n",
    "# data = ARData(num_datapoints, num_prev=input_size, test_size=test_size, noise_var=noise_var, coeffs=fixed_ar_coefficients[input_size])\n",
    "\n",
    "# # make training and test sets in torch\n",
    "# X_train = torch.from_numpy(data.X_train).type(torch.Tensor)\n",
    "# X_test = torch.from_numpy(data.X_test).type(torch.Tensor)\n",
    "# y_train = torch.from_numpy(data.y_train).type(torch.Tensor).view(-1)\n",
    "# y_test = torch.from_numpy(data.y_test).type(torch.Tensor).view(-1)\n",
    "\n",
    "# X_train = X_train.view([input_size, -1, 1])\n",
    "# X_test = X_test.view([input_size, -1, 1])\n",
    "\n",
    "# #####################\n",
    "# # Build model\n",
    "# #####################\n",
    "\n",
    "# # Here we define our model as a class\n",
    "# class LSTM(nn.Module):\n",
    "\n",
    "#     def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,\n",
    "#                     num_layers=2):\n",
    "#         super(LSTM, self).__init__()\n",
    "#         self.input_dim = input_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.batch_size = batch_size\n",
    "#         self.num_layers = num_layers\n",
    "\n",
    "#         # Define the LSTM layer\n",
    "#         self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "#         # Define the output layer\n",
    "#         self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "#     def init_hidden(self):\n",
    "#         # This is what we'll initialise our hidden state as\n",
    "#         return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "#                 torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         # Forward pass through LSTM layer\n",
    "#         # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "#         # shape of self.hidden: (a, b), where a and b both \n",
    "#         # have shape (num_layers, batch_size, hidden_dim).\n",
    "#         lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        \n",
    "#         # Only take the output from the final timetep\n",
    "#         # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "#         y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "#         return y_pred.view(-1)\n",
    "\n",
    "# model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "# loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "# optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# #####################\n",
    "# # Train model\n",
    "# #####################\n",
    "\n",
    "# hist = np.zeros(num_epochs)\n",
    "\n",
    "# for t in range(num_epochs):\n",
    "#     # Initialise hidden state\n",
    "#     # Don't do this if you want your LSTM to be stateful\n",
    "#     model.hidden = model.init_hidden()\n",
    "    \n",
    "#     # Forward pass\n",
    "#     y_pred = model(X_train)\n",
    "\n",
    "#     loss = loss_fn(y_pred, y_train)\n",
    "#     if t % 100 == 0:\n",
    "#         print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "#     hist[t] = loss.item()\n",
    "\n",
    "#     # Zero out gradient, else they will accumulate between epochs\n",
    "#     optimiser.zero_grad()\n",
    "\n",
    "#     # Backward pass\n",
    "#     loss.backward()\n",
    "\n",
    "#     # Update parameters\n",
    "#     optimiser.step()\n",
    "\n",
    "# #####################\n",
    "# # Plot preds and performance\n",
    "# #####################\n",
    "\n",
    "# plt.plot(y_pred.detach().numpy(), label=\"Preds\")\n",
    "# plt.plot(y_train.detach().numpy(), label=\"Data\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(hist, label=\"Training loss\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
